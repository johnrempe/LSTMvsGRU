{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NDsJYBRwdfh"
      },
      "source": [
        "## **Step 1: Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fFLotkK_3hlx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import datetime as dt\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7riKtNWT5pl",
        "outputId": "7b312f1e-4bf3-45bb-f395-2310c7c667a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRbBSDdIeacz"
      },
      "outputs": [],
      "source": [
        "\n",
        "output_dir_path = '/content/drive/My Drive/DSC_201/Results/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03ea9420"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/DSC_201/REM.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "w6Su9vxu28HO",
        "outputId": "88b419a9-c8a2-44c2-f18b-316c833c1f0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Date       Close        High         Low        Open  Volume  \\\n",
              "0  2007-12-03  150.369995  151.539993  148.589996  151.539993       0   \n",
              "1  2007-12-04  146.330002  150.279999  146.220001  150.279999       0   \n",
              "2  2007-12-05  151.690002  151.740005  146.389999  146.389999       0   \n",
              "3  2007-12-06  156.660004  156.690002  150.940002  151.630005       0   \n",
              "4  2007-12-07  155.509995  158.240005  155.139999  156.600006       0   \n",
              "\n",
              "       MACD       ATR    MFI        RSI  ...        VIX       USDX  EFFR  \\\n",
              "0  3.552184  4.679423  100.0  53.361877  ...  23.610001  75.930000  4.52   \n",
              "1  3.470452  4.641606  100.0  44.320134  ...  23.790001  75.690002  4.50   \n",
              "2  2.939289  4.696492  100.0  55.788225  ...  22.530001  76.410004  4.31   \n",
              "3  2.093172  4.771743  100.0  63.771526  ...  20.959999  76.379997  4.49   \n",
              "4  1.498145  4.652333  100.0  60.838501  ...  20.850000  76.290001  4.41   \n",
              "\n",
              "   UNRATE  UMCSENT      CPI       IPI      HPI    MR   BY10  \n",
              "0     5.0     75.5  211.445  102.3074  173.339  6.10  3.895  \n",
              "1     5.0     75.5  211.445  102.3074  173.339  6.10  3.889  \n",
              "2     5.0     75.5  211.445  102.3074  173.339  6.10  3.911  \n",
              "3     5.0     75.5  211.445  102.3074  173.339  5.96  3.998  \n",
              "4     5.0     75.5  211.445  102.3074  173.339  5.96  4.120  \n",
              "\n",
              "[5 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-742a50d8-2ad5-4866-a1e0-5d7899bde60a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MACD</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MFI</th>\n",
              "      <th>RSI</th>\n",
              "      <th>...</th>\n",
              "      <th>VIX</th>\n",
              "      <th>USDX</th>\n",
              "      <th>EFFR</th>\n",
              "      <th>UNRATE</th>\n",
              "      <th>UMCSENT</th>\n",
              "      <th>CPI</th>\n",
              "      <th>IPI</th>\n",
              "      <th>HPI</th>\n",
              "      <th>MR</th>\n",
              "      <th>BY10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2007-12-03</td>\n",
              "      <td>150.369995</td>\n",
              "      <td>151.539993</td>\n",
              "      <td>148.589996</td>\n",
              "      <td>151.539993</td>\n",
              "      <td>0</td>\n",
              "      <td>3.552184</td>\n",
              "      <td>4.679423</td>\n",
              "      <td>100.0</td>\n",
              "      <td>53.361877</td>\n",
              "      <td>...</td>\n",
              "      <td>23.610001</td>\n",
              "      <td>75.930000</td>\n",
              "      <td>4.52</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>6.10</td>\n",
              "      <td>3.895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2007-12-04</td>\n",
              "      <td>146.330002</td>\n",
              "      <td>150.279999</td>\n",
              "      <td>146.220001</td>\n",
              "      <td>150.279999</td>\n",
              "      <td>0</td>\n",
              "      <td>3.470452</td>\n",
              "      <td>4.641606</td>\n",
              "      <td>100.0</td>\n",
              "      <td>44.320134</td>\n",
              "      <td>...</td>\n",
              "      <td>23.790001</td>\n",
              "      <td>75.690002</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>6.10</td>\n",
              "      <td>3.889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2007-12-05</td>\n",
              "      <td>151.690002</td>\n",
              "      <td>151.740005</td>\n",
              "      <td>146.389999</td>\n",
              "      <td>146.389999</td>\n",
              "      <td>0</td>\n",
              "      <td>2.939289</td>\n",
              "      <td>4.696492</td>\n",
              "      <td>100.0</td>\n",
              "      <td>55.788225</td>\n",
              "      <td>...</td>\n",
              "      <td>22.530001</td>\n",
              "      <td>76.410004</td>\n",
              "      <td>4.31</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>6.10</td>\n",
              "      <td>3.911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2007-12-06</td>\n",
              "      <td>156.660004</td>\n",
              "      <td>156.690002</td>\n",
              "      <td>150.940002</td>\n",
              "      <td>151.630005</td>\n",
              "      <td>0</td>\n",
              "      <td>2.093172</td>\n",
              "      <td>4.771743</td>\n",
              "      <td>100.0</td>\n",
              "      <td>63.771526</td>\n",
              "      <td>...</td>\n",
              "      <td>20.959999</td>\n",
              "      <td>76.379997</td>\n",
              "      <td>4.49</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>5.96</td>\n",
              "      <td>3.998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2007-12-07</td>\n",
              "      <td>155.509995</td>\n",
              "      <td>158.240005</td>\n",
              "      <td>155.139999</td>\n",
              "      <td>156.600006</td>\n",
              "      <td>0</td>\n",
              "      <td>1.498145</td>\n",
              "      <td>4.652333</td>\n",
              "      <td>100.0</td>\n",
              "      <td>60.838501</td>\n",
              "      <td>...</td>\n",
              "      <td>20.850000</td>\n",
              "      <td>76.290001</td>\n",
              "      <td>4.41</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>5.96</td>\n",
              "      <td>4.120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 24 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-742a50d8-2ad5-4866-a1e0-5d7899bde60a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-742a50d8-2ad5-4866-a1e0-5d7899bde60a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-742a50d8-2ad5-4866-a1e0-5d7899bde60a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-12e6b3ec-3bb8-4ccf-b3f7-ed0e78e11649\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-12e6b3ec-3bb8-4ccf-b3f7-ed0e78e11649')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-12e6b3ec-3bb8-4ccf-b3f7-ed0e78e11649 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-1ElMrSprzg"
      },
      "outputs": [],
      "source": [
        "# Convert the 'Date' column to a datetime format\n",
        "data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "4EIAsEPnQ-4T",
        "outputId": "c7824a22-d05b-4006-a826-6f5c34520cc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 Close        High         Low        Open    Volume  \\\n",
              "Date                                                                   \n",
              "2007-12-03  150.369995  151.539993  148.589996  151.539993         0   \n",
              "2007-12-04  146.330002  150.279999  146.220001  150.279999         0   \n",
              "2007-12-05  151.690002  151.740005  146.389999  146.389999         0   \n",
              "2007-12-06  156.660004  156.690002  150.940002  151.630005         0   \n",
              "2007-12-07  155.509995  158.240005  155.139999  156.600006         0   \n",
              "...                ...         ...         ...         ...       ...   \n",
              "2022-08-01  275.019989  276.850006  274.070007  276.410004  57354900   \n",
              "2022-08-02  271.440002  275.869995  271.260010  274.910004  71356000   \n",
              "2022-08-03  272.549988  275.109985  272.500000  273.010010  70311100   \n",
              "2022-08-04  272.890015  273.869995  271.190002  273.010010  61532100   \n",
              "2022-08-05  273.750000  273.850006  269.850006  270.709991  52332600   \n",
              "\n",
              "                MACD       ATR         MFI        RSI        MA10  ...  \\\n",
              "Date                                                               ...   \n",
              "2007-12-03  3.552184  4.679423  100.000000  53.361877  145.901003  ...   \n",
              "2007-12-04  3.470452  4.641606  100.000000  44.320134  145.862003  ...   \n",
              "2007-12-05  2.939289  4.696492  100.000000  55.788225  146.660002  ...   \n",
              "2007-12-06  2.093172  4.771743  100.000000  63.771526  148.038002  ...   \n",
              "2007-12-07  1.498145  4.652333  100.000000  60.838501  148.961002  ...   \n",
              "...              ...       ...         ...        ...         ...  ...   \n",
              "2022-08-01 -3.554793  4.988096   67.466224  73.884200  267.449997  ...   \n",
              "2022-08-02 -3.604843  4.961088   66.731670  61.447368  268.462997  ...   \n",
              "2022-08-03 -3.691521  4.868866   73.280430  63.637145  269.725995  ...   \n",
              "2022-08-04 -3.744487  4.712518   65.319963  64.352819  270.759998  ...   \n",
              "2022-08-05 -3.811915  4.661624   65.939696  66.289035  271.672998  ...   \n",
              "\n",
              "                  VIX        USDX  EFFR  UNRATE  UMCSENT      CPI       IPI  \\\n",
              "Date                                                                          \n",
              "2007-12-03  23.610001   75.930000  4.52     5.0     75.5  211.445  102.3074   \n",
              "2007-12-04  23.790001   75.690002  4.50     5.0     75.5  211.445  102.3074   \n",
              "2007-12-05  22.530001   76.410004  4.31     5.0     75.5  211.445  102.3074   \n",
              "2007-12-06  20.959999   76.379997  4.49     5.0     75.5  211.445  102.3074   \n",
              "2007-12-07  20.850000   76.290001  4.41     5.0     75.5  211.445  102.3074   \n",
              "...               ...         ...   ...     ...      ...      ...       ...   \n",
              "2022-08-01  22.840000  105.449997  2.33     3.7     58.2  295.620  104.6544   \n",
              "2022-08-02  23.930000  106.239998  2.33     3.7     58.2  295.620  104.6544   \n",
              "2022-08-03  21.950001  106.510002  2.33     3.7     58.2  295.620  104.6544   \n",
              "2022-08-04  21.440001  105.690002  2.33     3.7     58.2  295.620  104.6544   \n",
              "2022-08-05  21.150000  106.620003  2.33     3.7     58.2  295.620  104.6544   \n",
              "\n",
              "                HPI    MR   BY10  \n",
              "Date                              \n",
              "2007-12-03  173.339  6.10  3.895  \n",
              "2007-12-04  173.339  6.10  3.889  \n",
              "2007-12-05  173.339  6.10  3.911  \n",
              "2007-12-06  173.339  5.96  3.998  \n",
              "2007-12-07  173.339  5.96  4.120  \n",
              "...             ...   ...    ...  \n",
              "2022-08-01  303.472  5.30  2.606  \n",
              "2022-08-02  303.472  5.30  2.741  \n",
              "2022-08-03  303.472  5.30  2.748  \n",
              "2022-08-04  303.472  4.99  2.676  \n",
              "2022-08-05  303.472  4.99  2.840  \n",
              "\n",
              "[3567 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6117bd9b-fe55-41f8-8591-feb1a026aba0\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MACD</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MFI</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MA10</th>\n",
              "      <th>...</th>\n",
              "      <th>VIX</th>\n",
              "      <th>USDX</th>\n",
              "      <th>EFFR</th>\n",
              "      <th>UNRATE</th>\n",
              "      <th>UMCSENT</th>\n",
              "      <th>CPI</th>\n",
              "      <th>IPI</th>\n",
              "      <th>HPI</th>\n",
              "      <th>MR</th>\n",
              "      <th>BY10</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2007-12-03</th>\n",
              "      <td>150.369995</td>\n",
              "      <td>151.539993</td>\n",
              "      <td>148.589996</td>\n",
              "      <td>151.539993</td>\n",
              "      <td>0</td>\n",
              "      <td>3.552184</td>\n",
              "      <td>4.679423</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>53.361877</td>\n",
              "      <td>145.901003</td>\n",
              "      <td>...</td>\n",
              "      <td>23.610001</td>\n",
              "      <td>75.930000</td>\n",
              "      <td>4.52</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>6.10</td>\n",
              "      <td>3.895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-12-04</th>\n",
              "      <td>146.330002</td>\n",
              "      <td>150.279999</td>\n",
              "      <td>146.220001</td>\n",
              "      <td>150.279999</td>\n",
              "      <td>0</td>\n",
              "      <td>3.470452</td>\n",
              "      <td>4.641606</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>44.320134</td>\n",
              "      <td>145.862003</td>\n",
              "      <td>...</td>\n",
              "      <td>23.790001</td>\n",
              "      <td>75.690002</td>\n",
              "      <td>4.50</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>6.10</td>\n",
              "      <td>3.889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-12-05</th>\n",
              "      <td>151.690002</td>\n",
              "      <td>151.740005</td>\n",
              "      <td>146.389999</td>\n",
              "      <td>146.389999</td>\n",
              "      <td>0</td>\n",
              "      <td>2.939289</td>\n",
              "      <td>4.696492</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>55.788225</td>\n",
              "      <td>146.660002</td>\n",
              "      <td>...</td>\n",
              "      <td>22.530001</td>\n",
              "      <td>76.410004</td>\n",
              "      <td>4.31</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>6.10</td>\n",
              "      <td>3.911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-12-06</th>\n",
              "      <td>156.660004</td>\n",
              "      <td>156.690002</td>\n",
              "      <td>150.940002</td>\n",
              "      <td>151.630005</td>\n",
              "      <td>0</td>\n",
              "      <td>2.093172</td>\n",
              "      <td>4.771743</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>63.771526</td>\n",
              "      <td>148.038002</td>\n",
              "      <td>...</td>\n",
              "      <td>20.959999</td>\n",
              "      <td>76.379997</td>\n",
              "      <td>4.49</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>5.96</td>\n",
              "      <td>3.998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2007-12-07</th>\n",
              "      <td>155.509995</td>\n",
              "      <td>158.240005</td>\n",
              "      <td>155.139999</td>\n",
              "      <td>156.600006</td>\n",
              "      <td>0</td>\n",
              "      <td>1.498145</td>\n",
              "      <td>4.652333</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>60.838501</td>\n",
              "      <td>148.961002</td>\n",
              "      <td>...</td>\n",
              "      <td>20.850000</td>\n",
              "      <td>76.290001</td>\n",
              "      <td>4.41</td>\n",
              "      <td>5.0</td>\n",
              "      <td>75.5</td>\n",
              "      <td>211.445</td>\n",
              "      <td>102.3074</td>\n",
              "      <td>173.339</td>\n",
              "      <td>5.96</td>\n",
              "      <td>4.120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-01</th>\n",
              "      <td>275.019989</td>\n",
              "      <td>276.850006</td>\n",
              "      <td>274.070007</td>\n",
              "      <td>276.410004</td>\n",
              "      <td>57354900</td>\n",
              "      <td>-3.554793</td>\n",
              "      <td>4.988096</td>\n",
              "      <td>67.466224</td>\n",
              "      <td>73.884200</td>\n",
              "      <td>267.449997</td>\n",
              "      <td>...</td>\n",
              "      <td>22.840000</td>\n",
              "      <td>105.449997</td>\n",
              "      <td>2.33</td>\n",
              "      <td>3.7</td>\n",
              "      <td>58.2</td>\n",
              "      <td>295.620</td>\n",
              "      <td>104.6544</td>\n",
              "      <td>303.472</td>\n",
              "      <td>5.30</td>\n",
              "      <td>2.606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-02</th>\n",
              "      <td>271.440002</td>\n",
              "      <td>275.869995</td>\n",
              "      <td>271.260010</td>\n",
              "      <td>274.910004</td>\n",
              "      <td>71356000</td>\n",
              "      <td>-3.604843</td>\n",
              "      <td>4.961088</td>\n",
              "      <td>66.731670</td>\n",
              "      <td>61.447368</td>\n",
              "      <td>268.462997</td>\n",
              "      <td>...</td>\n",
              "      <td>23.930000</td>\n",
              "      <td>106.239998</td>\n",
              "      <td>2.33</td>\n",
              "      <td>3.7</td>\n",
              "      <td>58.2</td>\n",
              "      <td>295.620</td>\n",
              "      <td>104.6544</td>\n",
              "      <td>303.472</td>\n",
              "      <td>5.30</td>\n",
              "      <td>2.741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-03</th>\n",
              "      <td>272.549988</td>\n",
              "      <td>275.109985</td>\n",
              "      <td>272.500000</td>\n",
              "      <td>273.010010</td>\n",
              "      <td>70311100</td>\n",
              "      <td>-3.691521</td>\n",
              "      <td>4.868866</td>\n",
              "      <td>73.280430</td>\n",
              "      <td>63.637145</td>\n",
              "      <td>269.725995</td>\n",
              "      <td>...</td>\n",
              "      <td>21.950001</td>\n",
              "      <td>106.510002</td>\n",
              "      <td>2.33</td>\n",
              "      <td>3.7</td>\n",
              "      <td>58.2</td>\n",
              "      <td>295.620</td>\n",
              "      <td>104.6544</td>\n",
              "      <td>303.472</td>\n",
              "      <td>5.30</td>\n",
              "      <td>2.748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-04</th>\n",
              "      <td>272.890015</td>\n",
              "      <td>273.869995</td>\n",
              "      <td>271.190002</td>\n",
              "      <td>273.010010</td>\n",
              "      <td>61532100</td>\n",
              "      <td>-3.744487</td>\n",
              "      <td>4.712518</td>\n",
              "      <td>65.319963</td>\n",
              "      <td>64.352819</td>\n",
              "      <td>270.759998</td>\n",
              "      <td>...</td>\n",
              "      <td>21.440001</td>\n",
              "      <td>105.690002</td>\n",
              "      <td>2.33</td>\n",
              "      <td>3.7</td>\n",
              "      <td>58.2</td>\n",
              "      <td>295.620</td>\n",
              "      <td>104.6544</td>\n",
              "      <td>303.472</td>\n",
              "      <td>4.99</td>\n",
              "      <td>2.676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2022-08-05</th>\n",
              "      <td>273.750000</td>\n",
              "      <td>273.850006</td>\n",
              "      <td>269.850006</td>\n",
              "      <td>270.709991</td>\n",
              "      <td>52332600</td>\n",
              "      <td>-3.811915</td>\n",
              "      <td>4.661624</td>\n",
              "      <td>65.939696</td>\n",
              "      <td>66.289035</td>\n",
              "      <td>271.672998</td>\n",
              "      <td>...</td>\n",
              "      <td>21.150000</td>\n",
              "      <td>106.620003</td>\n",
              "      <td>2.33</td>\n",
              "      <td>3.7</td>\n",
              "      <td>58.2</td>\n",
              "      <td>295.620</td>\n",
              "      <td>104.6544</td>\n",
              "      <td>303.472</td>\n",
              "      <td>4.99</td>\n",
              "      <td>2.840</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3567 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6117bd9b-fe55-41f8-8591-feb1a026aba0')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6117bd9b-fe55-41f8-8591-feb1a026aba0 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6117bd9b-fe55-41f8-8591-feb1a026aba0');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3b64731b-1a6d-4ec4-b57c-d86d7d8496ec\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3b64731b-1a6d-4ec4-b57c-d86d7d8496ec')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3b64731b-1a6d-4ec4-b57c-d86d7d8496ec button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_32976e13-dc33-4a64-bafd-5f3ac94cc062\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data1')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_32976e13-dc33-4a64-bafd-5f3ac94cc062 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data1');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data1"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data1 = data.set_index('Date')\n",
        "data1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhcK9qa0wPsK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5EWNJs65Ecs"
      },
      "source": [
        "## **Step 2: Data Exploration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-G4OLa-V3zv9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# sns.set_theme(style=\"whitegrid\")\n",
        "# plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "EIVKYEZm5Di2",
        "outputId": "c7779c17-018e-4e8f-e885-46fd54e5c32d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "df = data1.copy()\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "\n",
        "# Set both figure and axes background to white\n",
        "fig.patch.set_facecolor('white')\n",
        "ax.set_facecolor('white')\n",
        "\n",
        "# Plot the data\n",
        "data1['Close'].plot(ax=ax, color='blue', linewidth=1.5)\n",
        "\n",
        "# Enable grid lines\n",
        "ax.grid(True, which='both',\n",
        "        color='k',\n",
        "        linestyle='--',\n",
        "        linewidth=0.5)\n",
        "\n",
        "# Customize plot\n",
        "plt.legend(['Daily Close Price'], loc='best')\n",
        "plt.xlabel('Date', color='k')\n",
        "plt.ylabel('Close Price', color='k')\n",
        "plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "plt.rcParams[\"axes.linewidth\"] = 1.5\n",
        "plt.rc('xtick', labelsize=10, color='k')\n",
        "plt.rc('ytick', labelsize=10, color='k')\n",
        "\n",
        "# Save the figure\n",
        "# fig.savefig(output_dir_path + \"original_Passengers_data.png\",\n",
        "#             dpi=600, facecolor='white')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jXW5PVTeSibd"
      },
      "outputs": [],
      "source": [
        "X = data1.drop('Close', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        },
        "id": "nE0aZr7aSK68",
        "outputId": "41eadc87-3bed-413f-b672-5fa726c5f477"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#plot lower triangular correlation heatmap for X with two decimal values\n",
        "plt.figure(figsize=(12, 8))\n",
        "# sns.heatmap(X.corr().round(decimals=2), annot=True, cmap='coolwarm')\n",
        "# remove grid\n",
        "plt.grid(False)\n",
        "# make background color white\n",
        "plt.rcParams[\"axes.facecolor\"] = \"white\"\n",
        "# remove box\n",
        "plt.box(False)\n",
        "mask=np.triu(np.ones_like(X.corr()))\n",
        "sns.heatmap(X.corr().round(decimals=2), annot=True, cmap='coolwarm', mask=mask)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGvEDWTTCAb5"
      },
      "source": [
        "### **Descriptive Statistics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "lpHdLNaUvDja",
        "outputId": "fd1d5999-0b73-4f74-b3eb-40cc3f0b03ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             Close         High          Low         Open        Volume  \\\n",
              "count  3567.000000  3567.000000  3567.000000  3567.000000  3.567000e+03   \n",
              "mean    174.974354   176.370886   173.425697   174.971862  3.239631e+07   \n",
              "std      57.766173    57.836603    57.694692    57.766702  3.713372e+07   \n",
              "min      42.950001    43.450001    40.470001    42.950001  0.000000e+00   \n",
              "25%     136.644997   137.945000   134.794998   136.570000  0.000000e+00   \n",
              "50%     177.410004   178.800003   175.940002   177.339996  2.655520e+07   \n",
              "75%     207.724998   208.915001   206.474998   207.555000  5.461140e+07   \n",
              "max     324.750000   326.970001   323.859985   325.429993  2.315290e+08   \n",
              "\n",
              "              MACD          ATR          MFI          RSI         MA10  ...  \\\n",
              "count  3567.000000  3567.000000  3567.000000  3567.000000  3567.000000  ...   \n",
              "mean     -0.213231     3.111129    74.194426    53.500230   174.812136  ...   \n",
              "std       2.610380     1.699256    25.839340    15.203483    57.574976  ...   \n",
              "min      -7.191297     0.806594    12.228054     6.042427    46.569001  ...   \n",
              "25%      -1.737864     2.032761    50.592216    42.596780   136.697000  ...   \n",
              "50%      -0.569587     2.597558    72.860414    53.777562   177.477000  ...   \n",
              "75%       0.827156     3.686547   100.000000    64.784552   207.056000  ...   \n",
              "max      20.392969    13.191450   100.000000    92.682279   319.348001  ...   \n",
              "\n",
              "               VIX         USDX         EFFR       UNRATE      UMCSENT  \\\n",
              "count  3567.000000  3567.000000  3567.000000  3567.000000  3567.000000   \n",
              "mean     20.678778    87.949078     0.617903     6.437903    80.208102   \n",
              "std       9.591658     8.800241     0.856881     2.234536    12.970719   \n",
              "min       9.140000    71.330002     0.040000     3.500000    50.000000   \n",
              "25%      14.240000    80.110001     0.090000     4.700000    70.800000   \n",
              "50%      18.010000    89.309998     0.150000     6.000000    79.300000   \n",
              "75%      23.925000    96.084999     0.910000     8.200000    92.000000   \n",
              "max      82.690002   108.540001     4.520000    14.700000   101.400000   \n",
              "\n",
              "               CPI          IPI          HPI           MR         BY10  \n",
              "count  3567.000000  3567.000000  3567.000000  3567.000000  3567.000000  \n",
              "mean    239.632623    98.043131   182.710138     4.179282     2.380623  \n",
              "std      19.566756     4.848964    41.929439     0.835244     0.815440  \n",
              "min     211.398000    84.727700   133.997000     2.650000     0.499000  \n",
              "25%     224.806000    95.745500   147.938000     3.600000     1.789000  \n",
              "50%     237.231000    99.078200   169.193000     4.060000     2.347000  \n",
              "75%     252.862000   101.763200   205.387000     4.660000     2.924500  \n",
              "max     295.620000   104.757700   308.422000     6.630000     4.281000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-03b8761d-4e19-4bce-9716-d0b638545469\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Open</th>\n",
              "      <th>Volume</th>\n",
              "      <th>MACD</th>\n",
              "      <th>ATR</th>\n",
              "      <th>MFI</th>\n",
              "      <th>RSI</th>\n",
              "      <th>MA10</th>\n",
              "      <th>...</th>\n",
              "      <th>VIX</th>\n",
              "      <th>USDX</th>\n",
              "      <th>EFFR</th>\n",
              "      <th>UNRATE</th>\n",
              "      <th>UMCSENT</th>\n",
              "      <th>CPI</th>\n",
              "      <th>IPI</th>\n",
              "      <th>HPI</th>\n",
              "      <th>MR</th>\n",
              "      <th>BY10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3.567000e+03</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "      <td>3567.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>174.974354</td>\n",
              "      <td>176.370886</td>\n",
              "      <td>173.425697</td>\n",
              "      <td>174.971862</td>\n",
              "      <td>3.239631e+07</td>\n",
              "      <td>-0.213231</td>\n",
              "      <td>3.111129</td>\n",
              "      <td>74.194426</td>\n",
              "      <td>53.500230</td>\n",
              "      <td>174.812136</td>\n",
              "      <td>...</td>\n",
              "      <td>20.678778</td>\n",
              "      <td>87.949078</td>\n",
              "      <td>0.617903</td>\n",
              "      <td>6.437903</td>\n",
              "      <td>80.208102</td>\n",
              "      <td>239.632623</td>\n",
              "      <td>98.043131</td>\n",
              "      <td>182.710138</td>\n",
              "      <td>4.179282</td>\n",
              "      <td>2.380623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>57.766173</td>\n",
              "      <td>57.836603</td>\n",
              "      <td>57.694692</td>\n",
              "      <td>57.766702</td>\n",
              "      <td>3.713372e+07</td>\n",
              "      <td>2.610380</td>\n",
              "      <td>1.699256</td>\n",
              "      <td>25.839340</td>\n",
              "      <td>15.203483</td>\n",
              "      <td>57.574976</td>\n",
              "      <td>...</td>\n",
              "      <td>9.591658</td>\n",
              "      <td>8.800241</td>\n",
              "      <td>0.856881</td>\n",
              "      <td>2.234536</td>\n",
              "      <td>12.970719</td>\n",
              "      <td>19.566756</td>\n",
              "      <td>4.848964</td>\n",
              "      <td>41.929439</td>\n",
              "      <td>0.835244</td>\n",
              "      <td>0.815440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>42.950001</td>\n",
              "      <td>43.450001</td>\n",
              "      <td>40.470001</td>\n",
              "      <td>42.950001</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-7.191297</td>\n",
              "      <td>0.806594</td>\n",
              "      <td>12.228054</td>\n",
              "      <td>6.042427</td>\n",
              "      <td>46.569001</td>\n",
              "      <td>...</td>\n",
              "      <td>9.140000</td>\n",
              "      <td>71.330002</td>\n",
              "      <td>0.040000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>50.000000</td>\n",
              "      <td>211.398000</td>\n",
              "      <td>84.727700</td>\n",
              "      <td>133.997000</td>\n",
              "      <td>2.650000</td>\n",
              "      <td>0.499000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>136.644997</td>\n",
              "      <td>137.945000</td>\n",
              "      <td>134.794998</td>\n",
              "      <td>136.570000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>-1.737864</td>\n",
              "      <td>2.032761</td>\n",
              "      <td>50.592216</td>\n",
              "      <td>42.596780</td>\n",
              "      <td>136.697000</td>\n",
              "      <td>...</td>\n",
              "      <td>14.240000</td>\n",
              "      <td>80.110001</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>4.700000</td>\n",
              "      <td>70.800000</td>\n",
              "      <td>224.806000</td>\n",
              "      <td>95.745500</td>\n",
              "      <td>147.938000</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>1.789000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>177.410004</td>\n",
              "      <td>178.800003</td>\n",
              "      <td>175.940002</td>\n",
              "      <td>177.339996</td>\n",
              "      <td>2.655520e+07</td>\n",
              "      <td>-0.569587</td>\n",
              "      <td>2.597558</td>\n",
              "      <td>72.860414</td>\n",
              "      <td>53.777562</td>\n",
              "      <td>177.477000</td>\n",
              "      <td>...</td>\n",
              "      <td>18.010000</td>\n",
              "      <td>89.309998</td>\n",
              "      <td>0.150000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>79.300000</td>\n",
              "      <td>237.231000</td>\n",
              "      <td>99.078200</td>\n",
              "      <td>169.193000</td>\n",
              "      <td>4.060000</td>\n",
              "      <td>2.347000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>207.724998</td>\n",
              "      <td>208.915001</td>\n",
              "      <td>206.474998</td>\n",
              "      <td>207.555000</td>\n",
              "      <td>5.461140e+07</td>\n",
              "      <td>0.827156</td>\n",
              "      <td>3.686547</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>64.784552</td>\n",
              "      <td>207.056000</td>\n",
              "      <td>...</td>\n",
              "      <td>23.925000</td>\n",
              "      <td>96.084999</td>\n",
              "      <td>0.910000</td>\n",
              "      <td>8.200000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>252.862000</td>\n",
              "      <td>101.763200</td>\n",
              "      <td>205.387000</td>\n",
              "      <td>4.660000</td>\n",
              "      <td>2.924500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>324.750000</td>\n",
              "      <td>326.970001</td>\n",
              "      <td>323.859985</td>\n",
              "      <td>325.429993</td>\n",
              "      <td>2.315290e+08</td>\n",
              "      <td>20.392969</td>\n",
              "      <td>13.191450</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>92.682279</td>\n",
              "      <td>319.348001</td>\n",
              "      <td>...</td>\n",
              "      <td>82.690002</td>\n",
              "      <td>108.540001</td>\n",
              "      <td>4.520000</td>\n",
              "      <td>14.700000</td>\n",
              "      <td>101.400000</td>\n",
              "      <td>295.620000</td>\n",
              "      <td>104.757700</td>\n",
              "      <td>308.422000</td>\n",
              "      <td>6.630000</td>\n",
              "      <td>4.281000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-03b8761d-4e19-4bce-9716-d0b638545469')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-03b8761d-4e19-4bce-9716-d0b638545469 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-03b8761d-4e19-4bce-9716-d0b638545469');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-584c3350-93e7-4284-afd8-f20533d4d15e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-584c3350-93e7-4284-afd8-f20533d4d15e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-584c3350-93e7-4284-afd8-f20533d4d15e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data1.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifiXXSC7KluW"
      },
      "source": [
        "## **Step 3: Writing Supporting functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPgx2IiHyIYR"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import r2_score\n",
        "import time\n",
        "import math\n",
        "import ast"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd_t4yRncDkY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oneb2jd0cRlg"
      },
      "outputs": [],
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    return (np.mean(np.abs((y_true - y_pred)/(y_true))*100))\n",
        "\n",
        "def calculate_scores(y_true, y_pred):\n",
        "  rmse = math.sqrt(mean_squared_error(y_true, y_pred))\n",
        "  #R2_score = r2_score(y_true, y_pred)\n",
        "  R = np.corrcoef(y_true, y_pred)\n",
        "  #mae = mean_absolute_error(y_true, y_pred)\n",
        "  mape = mean_absolute_percentage_error(y_true, y_pred)\n",
        "  #dic = {'rmse':rmse, 'R2_score': R2_score, 'R':R[0,1], 'mae': mae, 'mape': mape}\n",
        "  dic = {'rmse':rmse, 'R': R[0,1], 'mape': mape}\n",
        "  return (dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rFUv9FXB9n1z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRyKcPKEcbmZ"
      },
      "outputs": [],
      "source": [
        "def data_split(data, split = 0.2):\n",
        "\n",
        "  # creating training and test data\n",
        "  l1   = int(len(data) * (1- split))\n",
        "  l2    = len(data) - l1\n",
        "  train  = data[0:l1]\n",
        "  test   = data[l1:len(data)]\n",
        "  return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltpWXpCgcfmC"
      },
      "outputs": [],
      "source": [
        "def min_max_transform(data, feature_range=(0, 1)):\n",
        "   scaler = MinMaxScaler(feature_range)\n",
        "   return scaler.fit_transform(data)\n",
        "\n",
        "def min_max_inverse_transform(data_scaled, min_original, max_original):\n",
        "    return min_original +  data_scaled*(max_original - min_original)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yeru5kOg-knu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DTJsyFTcW3d"
      },
      "outputs": [],
      "source": [
        "## returns the X and Y data\n",
        "def DatasetCreation(X, y, time_step = 5):\n",
        "   DataX, DataY = [], []\n",
        "   for i in range(len(X)- time_step -1):\n",
        "         a = X[i:(i+ time_step)]\n",
        "         DataX.append(a)\n",
        "         DataY.append(y[i + time_step])\n",
        "\n",
        "   return np.array(DataX), np.array(DataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OzDTAFGwF0u"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zafo1tocpXY"
      },
      "outputs": [],
      "source": [
        "def write_dic_to_file(dic_name, file_name):\n",
        "  file = open(file_name, 'w')\n",
        "  file.write(str(dic_name))\n",
        "  file.close()\n",
        "\n",
        "\n",
        "\n",
        "def read_dic_from_file(file_name):\n",
        "  file = open(file_name, \"r\")\n",
        "  contents = file.read()\n",
        "  dictionary = ast.literal_eval(contents)\n",
        "  file.close()\n",
        "  return dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikplCNqpJ8CN"
      },
      "outputs": [],
      "source": [
        "def loss_plot(model_output, file_name):\n",
        "\n",
        "  loss =  model_output.history['loss']\n",
        "  val_loss = model_output.history['val_loss']\n",
        "\n",
        "  epochs = model_output.epoch\n",
        "  fig = plt.figure(figsize = (8,5))\n",
        "  plt.subplot(111)\n",
        "  plt.plot(epochs, loss, color = 'red', marker = \"s\")\n",
        "  plt.plot(epochs, val_loss, color = 'blue', marker = \"^\")\n",
        "  plt.legend([\"loss\", \"validation loss\"], loc=\"best\")\n",
        "  plt.xlabel(\"epoch\")\n",
        "  plt.ylabel(\"loss\")\n",
        "  plt.title(\"Training and Validation Loss\")\n",
        "\n",
        "  fig.savefig(file_name, dpi = 600)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htx8uH9O2epV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJrVjJgcBx8B"
      },
      "source": [
        "## **Step 4: Input Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHvodwEDXiGE"
      },
      "outputs": [],
      "source": [
        "X= data1\n",
        "y = data1['Close']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4E253Ksr9YTW"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=0.99)\n",
        "X_pca = pca.fit_transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4o0Vdv9X9ew0",
        "outputId": "c0f42118-c917-4a8d-ec1e-8f321c2e282a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3567, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "X_pca.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6uaYQmN9q-N"
      },
      "outputs": [],
      "source": [
        "X_train, X_test = data_split(X_pca, split=0.2)\n",
        "y_train, y_test = data_split(y, split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NqDhuRHG_eih"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(y_train).reshape(-1, 1)\n",
        "y_test = np.array(y_test).reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J-75Tszm_1mR",
        "outputId": "d67717d8-8d4f-446b-ffc0-c0e1c3bb1737"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2853, 1), (714, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCL4F8MiDduY"
      },
      "outputs": [],
      "source": [
        "y_train_min, y_train_max = y_train.min(), y_train.max()\n",
        "y_test_min, y_test_max = y_test.min(), y_test.max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDeQnxZO9q5g",
        "outputId": "f576c2cd-e9cd-407b-f854-f9fd62d22b1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2853, 1), (714, 1), (2853, 1), (714, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5symyrr-rGs",
        "outputId": "6608a5fb-ccd5-4eb8-bd5e-8ec6beebbaba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-32396313.09316635],\n",
              "       [-32396313.09317774],\n",
              "       [-32396313.09314707],\n",
              "       ...,\n",
              "       [ 24522486.90870075],\n",
              "       [ 24468386.90872825],\n",
              "       [ 13586586.90880062]])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYHg9Q4QC3AD"
      },
      "source": [
        "### **Normalize Train and Test Data Separately**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_BKDBbH-H6x"
      },
      "outputs": [],
      "source": [
        "X_train_scaled = min_max_transform(X_train)\n",
        "X_test_scaled = min_max_transform(X_test)\n",
        "\n",
        "y_train_scaled = min_max_transform(y_train)\n",
        "y_test_scaled = min_max_transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7czdTUm5Gdip"
      },
      "source": [
        "### **Inverse Trainsform of the y data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xcLxoIAcDaDP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ppom4Q_Bh2E"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_train_original = min_max_inverse_transform(y_train_scaled, y_train.min(), y_train.max())\n",
        "y_test_original = min_max_inverse_transform(y_test_scaled, y_test.min(), y_test.max())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIem57uVExKK"
      },
      "source": [
        "### **Creating X and y data for supervised learning**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPbzlWyYcIdS"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = DatasetCreation(X_train_scaled, y_train_scaled, time_step = 5)\n",
        "X_test, y_test = DatasetCreation(X_test_scaled, y_test_scaled, time_step = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifbUOPZIADL9",
        "outputId": "2225d6b7-946d-4ccc-cf52-3af58484326e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2847, 5, 1), (708, 5, 1), (2847, 1), (708, 1))"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPRO5zhxA5xM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERHc2WGxA5jd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkWqyAurG1Sr"
      },
      "source": [
        "### **Making Sure the input-output shpae for the Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSqc60ezG-C4",
        "outputId": "095009ba-7958-4864-efa9-3320b367c95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2847, 5, 1)\n",
            "(708, 5, 1)\n",
            "(2847, 1)\n",
            "(708, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape )# must be in (num_observations, time_step, number_features)\n",
        "print(X_test.shape )# must be in (num_observations, time_step, number_features)\n",
        "print(y_train.shape )# must be 1-D array of lentgh = num_observations\n",
        "print(y_test.shape )# must be 1-D array of lentgh = num_observations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOkwQxnGHjws",
        "outputId": "b080db21-74d9-4a0d-f177-b09b518d3dc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.78455037e-12],\n",
              "       [2.73533973e-12],\n",
              "       [2.86778934e-12],\n",
              "       [2.98489011e-12],\n",
              "       [2.95871661e-12]])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# a 2D array(matrix) of shape:  (time_step, num_features)\n",
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d53NzCxFH_i4",
        "outputId": "d9182e1a-9191-414c-97b7-ec5f658a369e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.56896552])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFioIufGUClb"
      },
      "source": [
        "## **Step 5: Building LSTM and GRU Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrGsqnse60nu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GdWByoUQ-4y"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, Dense, Input, BatchNormalization, Dropout\n",
        "from keras import optimizers\n",
        "from keras.optimizers.schedules import ExponentialDecay\n",
        "from keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2_S23AAyoku"
      },
      "source": [
        "### **LSTM Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08hOR7gfQ-4y"
      },
      "outputs": [],
      "source": [
        "def Build_LSTM_Model(layers,\n",
        "                    time_step,\n",
        "                    num_features,\n",
        "                    optimizer='Adam',\n",
        "                    initial_learning_rate=0.01,\n",
        "                    decay_steps=5,\n",
        "                    decay_rate=0.95):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(time_step, num_features)))\n",
        "\n",
        "    for i, units in enumerate(layers):  # Use enumerate for index and value\n",
        "        return_sequences = (i < len(layers) - 1)  # return True/False, if True, proceeds\n",
        "\n",
        "        model.add(LSTM(units, return_sequences=return_sequences))\n",
        "\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    learning_rate = ExponentialDecay(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        decay_steps=decay_steps,\n",
        "        decay_rate=decay_rate,\n",
        "        staircase=True\n",
        "    )\n",
        "\n",
        "    # Optimizer selection\n",
        "    optimizer_mapping = {\n",
        "        'Adam': optimizers.Adam,\n",
        "        'Adagrad': optimizers.Adagrad,\n",
        "        'Nadam': optimizers.Nadam,\n",
        "        'Adadelta': optimizers.Adadelta,\n",
        "        'RMSprop': optimizers.RMSprop\n",
        "    }\n",
        "\n",
        "    if optimizer in optimizer_mapping:\n",
        "        opt = optimizer_mapping[optimizer](learning_rate=learning_rate)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported optimizer: {optimizer}. Choose from: {list(optimizer_mapping.keys())}\")  # Raise error for unsupported optimizers\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08c7XEsZR-VM"
      },
      "outputs": [],
      "source": [
        "# Sample code to run the model:\n",
        "optimizers_names = ['Adam']\n",
        "time_step = 5\n",
        "num_features = 1\n",
        "layers = [16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uT8zBcT-4A5t"
      },
      "outputs": [],
      "source": [
        "# Build and compile the model\n",
        "model = Build_LSTM_Model(\n",
        "    layers,\n",
        "    time_step,\n",
        "    num_features,\n",
        "    optimizer=optimizers_names[0]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "c2N0u93J4lwl",
        "outputId": "07968a1a-a53a-4e47-e6c2-961c117d9675"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m1,152\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,169\u001b[0m (4.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,169</span> (4.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,169\u001b[0m (4.57 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,169</span> (4.57 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbeA_YnsQ-4z"
      },
      "outputs": [],
      "source": [
        "#Note make sure the data is the training data only!\n",
        "# X_train = X_train_scaled\n",
        "# y_train is not the scaled one\n",
        "\n",
        "def LSTM_Hyper_Parameter_Tuning(layers,\n",
        "                                X_train,\n",
        "                                y_train,\n",
        "                                time_step,\n",
        "                                split,\n",
        "                                optimizers_names,\n",
        "                                initial_learning_rate,\n",
        "                                batch_sizes,\n",
        "                                epochs,\n",
        "                                num_replicates=2):\n",
        "    # Data Preparation\n",
        "    y_train_min, y_train_max = y_train.min(), y_train.max()\n",
        "\n",
        "\n",
        "    # X_train_scaled = min_max_transform(X_train)\n",
        "    y_train_scaled = min_max_transform(y_train)\n",
        "\n",
        "\n",
        "\n",
        "    X_train1, X_val = data_split(X_train, split)\n",
        "    y_train, y_val = data_split(y_train_scaled, split)\n",
        "\n",
        "    num_features = X_train.shape[1]\n",
        "\n",
        "\n",
        "    # Hyperparameter Tuning\n",
        "    best_avg_rmse = float('inf')  # Use infinity to start\n",
        "    all_avg_rmse = np.zeros((len(optimizers_names), len(batch_sizes)))\n",
        "    best_hyper_parameters = {\"model\": layers, \"optimizer\": None, \"batch_size\": None, \"best_avg_rmse\": None}\n",
        "\n",
        "    for opt_idx, optimizer_name in enumerate(optimizers_names):\n",
        "        for bs_idx, batch_size in enumerate(batch_sizes):\n",
        "            collect_rmse = []\n",
        "\n",
        "            for i in range(num_replicates):\n",
        "                print(f\"Running for optimizer {optimizer_name}, batch size {batch_size}, replicate {i + 1}\")\n",
        "\n",
        "                model = Build_LSTM_Model(layers,\n",
        "                                         time_step,\n",
        "                                         num_features,\n",
        "                                         optimizer_name,\n",
        "                                         initial_learning_rate=initial_learning_rate)\n",
        "\n",
        "                callback = EarlyStopping(monitor='val_loss', patience=5)\n",
        "                history = model.fit(X_train1, y_train,\n",
        "                                    batch_size=batch_size,\n",
        "                                    epochs=epochs,\n",
        "                                    validation_data=(X_val, y_val),\n",
        "                                    callbacks=[callback],\n",
        "                                    verbose=1)\n",
        "\n",
        "                val_pred = model.predict(X_val).ravel()\n",
        "                # min_val, max_val = y_train.min(), train_data[target_var].max()\n",
        "\n",
        "                val_pred_original = min_max_inverse_transform(val_pred, y_train_min, y_train_max)\n",
        "                y_val_original = min_max_inverse_transform(y_val, y_train_min, y_train_max)\n",
        "                collect_rmse.append(math.sqrt(mean_squared_error(y_val_original, val_pred_original)))\n",
        "\n",
        "            avg_rmse = np.mean(np.array(collect_rmse))\n",
        "            all_avg_rmse[opt_idx][bs_idx] = avg_rmse\n",
        "\n",
        "            if avg_rmse < best_avg_rmse:\n",
        "                best_avg_rmse = avg_rmse\n",
        "                best_hyper_parameters = {\n",
        "                    \"model\": layers, \"optimizer\": optimizer_name, \"batch_size\": batch_size, \"best_avg_rmse\": best_avg_rmse\n",
        "                }\n",
        "\n",
        "    # Output and Results\n",
        "    file_name = output_dir_path + \"lstm-\" + str(layers[0]) + \"N-hyperparameter_tuning__results\" + \".txt\"\n",
        "    write_dic_to_file(best_hyper_parameters, file_name)  # Just write best_hyper_parameters\n",
        "\n",
        "    print(\"Best hyperparameters (LSTM): \\n\", best_hyper_parameters)\n",
        "    print(\"All average RMSE (LSTM): \\n\", all_avg_rmse)\n",
        "\n",
        "    return best_hyper_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWbfzXzkQ-40"
      },
      "outputs": [],
      "source": [
        "#these are fixed\n",
        "time_step = 5\n",
        "test_split = 0.2\n",
        "val_split =  0.15\n",
        "optimizers_names = ['Adam', 'Nadam', 'Adagrad']\n",
        "batch_sizes =  [8, 16, 32]\n",
        "initial_learning_rate=0.01\n",
        "epochs = 30\n",
        "num_replicates = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xEs_J6jVIOy5"
      },
      "outputs": [],
      "source": [
        "layers = [8]\n",
        "lstm_N8_best_hyper_parameters = LSTM_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(lstm_N8_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwmaX56gLLEg"
      },
      "outputs": [],
      "source": [
        "#{'model': [8], 'optimizer': 'Nadam', 'batch_size': 16, 'best_avg_rmse': 0.2868527052986293}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rr4BCqzVQ-41",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "layers = [16]\n",
        "lstm_N16_best_hyper_parameters = LSTM_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(lstm_N16_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-bHVxv_JxGG"
      },
      "outputs": [],
      "source": [
        "# {'model': [16], 'optimizer': 'Nadam', 'batch_size': 8, 'best_avg_rmse': 0.2876010740540223}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4YjQl09jCq4"
      },
      "outputs": [],
      "source": [
        "layers = [32]\n",
        "lstm_N32_best_hyper_parameters = LSTM_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(lstm_N32_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aL4hLJDJrFu"
      },
      "outputs": [],
      "source": [
        "#{'model': [32], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.2873680136019986}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFwNGTeb2Bs3"
      },
      "outputs": [],
      "source": [
        "layers = [64]\n",
        "lstm_N64_best_hyper_parameters = LSTM_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(lstm_N64_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRcKi_vgJi9u"
      },
      "outputs": [],
      "source": [
        "#{'model': [64], 'optimizer': 'Nadam', 'batch_size': 32, 'best_avg_rmse': 0.2873803673683729}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZ_rj66i2F17"
      },
      "outputs": [],
      "source": [
        "layers = [128]\n",
        "lstm_N128_best_hyper_parameters = LSTM_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(lstm_N128_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ex6jFziKrVy"
      },
      "outputs": [],
      "source": [
        "#{'model': [128], 'optimizer': 'Nadam', 'batch_size': 32, 'best_avg_rmse': 0.2877799091395421}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_itbZsu6Oa9O"
      },
      "outputs": [],
      "source": [
        "lstm_best_hyper_parameters =  [ ['Nadam', 16],\n",
        "                                ['Nadam', 8],\n",
        "                                ['Adam', 8],\n",
        "                                ['Nadam', 32],\n",
        "                                ['Nadam', 32]\n",
        "                                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrjRNptBPULF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFaQQnq7vral"
      },
      "outputs": [],
      "source": [
        "def LSTM_Model_Implementation(layers,\n",
        "                             hyper_parameters,\n",
        "                             data,\n",
        "                             time_step = 5,\n",
        "                             test_split = 0.2,\n",
        "                             initial_learning_rate=0.01,\n",
        "                             epochs = 5,\n",
        "                             num_replicates = 2):\n",
        "    # data transformation\n",
        "    print(\"Progress: Performing data preparation steps.......\\n\")\n",
        "\n",
        "    # creating training and test data\n",
        "    X= data\n",
        "    y = data['Close']\n",
        "\n",
        "    pca = PCA(n_components=0.99)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "\n",
        "    X_train, X_test = data_split(X_pca, split=0.2)\n",
        "    y_train0, y_test0 = data_split(y, split=0.2)\n",
        "\n",
        "    y_train_original = np.array(y_train0).reshape(-1, 1)\n",
        "    y_test_original = np.array(y_test0).reshape(-1, 1)\n",
        "\n",
        "    y_train_min, y_train_max = y_train_original.min(), y_train_original.max()\n",
        "    y_test_min, y_test_max = y_test_original.min(), y_test_original.max()\n",
        "\n",
        "    X_train_scaled = min_max_transform(X_train)\n",
        "    X_test_scaled = min_max_transform(X_test)\n",
        "\n",
        "    y_train_scaled = min_max_transform(y_train_original)\n",
        "    y_test_scaled = min_max_transform(y_test_original)\n",
        "\n",
        "    X_train, y_train = DatasetCreation(X_train_scaled, y_train_scaled, time_step = 5)\n",
        "    X_test, y_test = DatasetCreation(X_test_scaled, y_test_scaled, time_step = 5)\n",
        "\n",
        "    y_train_original = min_max_inverse_transform(y_train, y_train_min, y_train_max)\n",
        "    y_test_original = min_max_inverse_transform(y_test, y_test_min, y_test_max)\n",
        "\n",
        "    print(X_train.shape )# must be in (num_observations, time_step, number_features)\n",
        "    print(X_test.shape )# must be in (num_observations, time_step, number_features\n",
        "    print(y_train.shape )# must be 1-D array of lentgh = num_observations\n",
        "    print(y_test.shape )# must be 1-D array of lentgh = num_observations\n",
        "    print(y_test_original.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # train_data, test_data = data_split(data, test_split)\n",
        "\n",
        "    num_features = X_pca.shape[1]\n",
        "\n",
        "    # min_train, max_train  = train_data[target_var].min(), train_data[target_var].max()\n",
        "    # min_test, max_test   =    test_data[target_var].min(), test_data[target_var].max()\n",
        "\n",
        "\n",
        "    # train_data_scaled  =  min_max_transform(train_data)\n",
        "    # test_data_scaled   = min_max_transform(test_data)\n",
        "\n",
        "\n",
        "    # X_train, y_train  =   DatasetCreation(train_data_scaled, time_step)\n",
        "    # X_test, y_test    =   DatasetCreation(test_data_scaled, time_step)\n",
        "\n",
        "    # y_train_original  =  min_max_inverse_transform(y_train, min_train, max_train) #in original scale\n",
        "    # y_test_original  =  min_max_inverse_transform(y_test, min_test, max_test) #in original scale\n",
        "\n",
        "\n",
        "    # arrays for collecting test scores\n",
        "    rmse_array = np.zeros(num_replicates)\n",
        "    mape_array = np.zeros(num_replicates)\n",
        "    R_array    = np.zeros(num_replicates)\n",
        "    elapsed_time_array = np.zeros(num_replicates)\n",
        "\n",
        "    models_history = []\n",
        "    train_predictions = []\n",
        "    test_predictions = []\n",
        "\n",
        "    for i in range(num_replicates):\n",
        "\n",
        "      print(f'Program is running for {i} replicate\\n')\n",
        "\n",
        "      model =  Build_LSTM_Model(layers,\n",
        "                        time_step,\n",
        "                        num_features,\n",
        "                        optimizer = hyper_parameters[0],\n",
        "                        initial_learning_rate = initial_learning_rate)\n",
        "\n",
        "      callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience= 5)\n",
        "      # This callback will stop the training when there is no improvement in\n",
        "      # the loss for three consecutive epochs\n",
        "      start = time.time()\n",
        "      history = model.fit(X_train, y_train,\n",
        "                          batch_size = hyper_parameters[1],\n",
        "                          epochs= epochs, callbacks=[callback], verbose = 1)\n",
        "      end = time.time()\n",
        "      elapsed_time = end - start\n",
        "\n",
        "      models_history.append(history)\n",
        "\n",
        "\n",
        "      # Getting train and test prediction in original scales\n",
        "      train_pred   =  min_max_inverse_transform(model.predict(X_train).ravel(),\n",
        "                                                y_train_min, y_train_max).reshape(-1,1)\n",
        "      test_pred    =  min_max_inverse_transform(model.predict(X_test).ravel(),\n",
        "                                                y_test_min, y_test_max).reshape(-1,1)\n",
        "\n",
        "      print(f'train pred shape {train_pred.shape}')\n",
        "      print(test_pred.shape)\n",
        "\n",
        "      train_predictions.append(train_pred)\n",
        "      test_predictions.append(test_pred)\n",
        "\n",
        "      # Calculating performance scores\n",
        "\n",
        "      scores =   calculate_scores(y_test_original,test_pred)\n",
        "\n",
        "      rmse_array[i] =  scores['rmse']\n",
        "      mape_array[i] =  scores['mape']\n",
        "      R_array[i] = scores['R']\n",
        "      elapsed_time_array[i] = elapsed_time\n",
        "\n",
        "    min_index = rmse_array.argmin()\n",
        "    best_rmse = rmse_array[min_index]\n",
        "    mape_with_best_rmse = mape_array[min_index]\n",
        "    R_with_best_rmse =  R_array[min_index]\n",
        "    elapsed_time_with_best_rmse = elapsed_time_array[min_index]\n",
        "\n",
        "    train_predictions_with_best_rmse = train_predictions[min_index]\n",
        "    test_predictions_with_best_rmse = test_predictions[min_index]\n",
        "\n",
        "    loss_with_best_rmse = models_history[min_index].history['loss']\n",
        "\n",
        "    #val_loss_with_best_rmse = models_history[min_index].history['val_loss']\n",
        "\n",
        "    # Collecting important results\n",
        "    performance_metrics =  {\n",
        "\n",
        "                        'scores': {'rmse': rmse_array,\n",
        "                                    'mape': mape_array,\n",
        "                                    'R': R_array,\n",
        "                                    'elapsed_time': elapsed_time_array\n",
        "                                    },\n",
        "\n",
        "                        'minimums': {'rmse': np.min(rmse_array),\n",
        "                                      'mape': np.min(mape_array),\n",
        "                                      'R': np.min(R_array),\n",
        "                                      'elapsed_time': np.min(elapsed_time_array)\n",
        "                                      },\n",
        "\n",
        "                        'avg_scores':  {'rmse': np.mean(rmse_array),\n",
        "                                        'mape': np.mean(mape_array),\n",
        "                                        'R': np.mean(R_array),\n",
        "                                        'elapsed_time': np.mean(elapsed_time_array)\n",
        "                                        },\n",
        "\n",
        "                          'stds':      { 'rmse': np.std(rmse_array),\n",
        "                                          'mape': np.std(mape_array),\n",
        "                                          'R': np.std(R_array),\n",
        "                                          'elapsed_time': np.std(elapsed_time_array)\n",
        "                                        },\n",
        "\n",
        "                        'maximums': {'rmse': np.max(rmse_array),\n",
        "                                     'mape': np.max(mape_array),\n",
        "                                     'R': np.max(R_array),\n",
        "                                     'elapsed_time': np.max(elapsed_time_array)\n",
        "                                     }\n",
        "\n",
        "                  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model_with_best_rmse = {\n",
        "\n",
        "                            'replicate': min_index,\n",
        "                            'rmse': best_rmse,\n",
        "                            #'mae': mae_with_best_rmse,\n",
        "                            'mape': mape_with_best_rmse,\n",
        "                            #'R2': R2_with_best_rmse,\n",
        "                            'R':  R_with_best_rmse,\n",
        "                            'elapsed_time': elapsed_time_with_best_rmse,\n",
        "                            'train_predictions':train_predictions_with_best_rmse,\n",
        "                            'test_predictions': test_predictions_with_best_rmse,\n",
        "                            #'y_train':y_train_original,\n",
        "                            #'y_test': y_test_original,\n",
        "                            'loss':loss_with_best_rmse,\n",
        "                             #'val_loss': val_loss_with_best_rmse\n",
        "                            }\n",
        "\n",
        "     # Collecting hyperparameters\n",
        "    hyper_parameters = {'layers': layers,\n",
        "                        'model_specific_hyper_parameters': hyper_parameters,\n",
        "                       'epochs': epochs,\n",
        "                       'time_step':time_step,\n",
        "                       'num_replicates': num_replicates,\n",
        "                       'test_split':test_split\n",
        "                        }\n",
        "\n",
        "\n",
        "     # Collecting all the outputs together\n",
        "    output_dictionary = {'hyper_parameters': hyper_parameters,\n",
        "                        'performance_metrics': performance_metrics,\n",
        "                         'best_model': model_with_best_rmse,\n",
        "                       }\n",
        "\n",
        "\n",
        "    pd.DataFrame(y_train_original).to_csv(output_dir_path+'y_train.csv')\n",
        "    pd.DataFrame(y_test_original).to_csv(output_dir_path+'y_test.csv')\n",
        "\n",
        "    print(\"Progress: All works are done successfully, congratulations!!\\n\")\n",
        "    return output_dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "P9l7_ZPNwMOT",
        "outputId": "eef357f0-03f9-493a-b10d-c329256e352d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "(2847, 5, 1)\n",
            "(708, 5, 1)\n",
            "(2847, 1)\n",
            "(708, 1)\n",
            "(708, 1)\n",
            "Program is running for 0 replicate\n",
            "\n",
            "Epoch 1/3\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0752\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-23e7bfc918aa>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m lstm_output = LSTM_Model_Implementation(layers,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                       \u001b[0mhyper_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                       \u001b[0mdata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-83a3e2e1c253>\u001b[0m in \u001b[0;36mLSTM_Model_Implementation\u001b[0;34m(layers, hyper_parameters, data, time_step, test_split, initial_learning_rate, epochs, num_replicates)\u001b[0m\n\u001b[1;32m     91\u001b[0m       \u001b[0;31m# the loss for three consecutive epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m       \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m       history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m     94\u001b[0m                           \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyper_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m                           epochs= epochs, callbacks=[callback], verbose = 1)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/callbacks/callback_list.py\u001b[0m in \u001b[0;36mon_train_batch_begin\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "hyper_parameters = ['Adam', 16]\n",
        "layers = [16]\n",
        "initial_learning_rate =0.01\n",
        "\n",
        "\n",
        "lstm_output = LSTM_Model_Implementation(layers,\n",
        "                                      hyper_parameters,\n",
        "                                      data1,\n",
        "                                      time_step = 5,\n",
        "                                      test_split = 0.2,\n",
        "                                      epochs = 3,\n",
        "                                      initial_learning_rate=initial_learning_rate,\n",
        "                                      num_replicates = 2)\n",
        "\n",
        "lstm_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RsTH2SXiQ-44"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijHbKJZHw4-t"
      },
      "outputs": [],
      "source": [
        "def Multiple_LSTM_Models(hidden_layers,\n",
        "                        hyper_parameters,\n",
        "                        data,\n",
        "                        time_step = 12,\n",
        "                        test_split = 0.2,\n",
        "                        initial_learning_rate=0.01,\n",
        "                        epochs = 30,\n",
        "                        num_replicates = 2):\n",
        "\n",
        "  num_models = len(hidden_layers)\n",
        "\n",
        "  # collect all scores\n",
        "  rmse = []\n",
        "  mape = []\n",
        "  R = []\n",
        "  elapsed_time = []\n",
        "\n",
        "  # collect all avg scores\n",
        "  avg_rmse = []\n",
        "  avg_mape = []\n",
        "  avg_R = []\n",
        "  avg_elapsed_time = []\n",
        "\n",
        "  # iteratively update the best rmse and the corresponding model\n",
        "  best_avg_rmse = float('inf')\n",
        "  best_rmse = float('inf')\n",
        "  best_model_hidden_layers = None\n",
        "  best_model_output = None\n",
        "\n",
        "  for i in range(num_models):\n",
        "    print(\"Running model with hidden neurons: \", hidden_layers[i])\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Best Hyper_parameters used: \", hyper_parameters[i])\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    output = LSTM_Model_Implementation(hidden_layers[i],\n",
        "                                      hyper_parameters[i],\n",
        "                                      data,\n",
        "                                      time_step,\n",
        "                                      test_split,\n",
        "                                      initial_learning_rate,\n",
        "                                      epochs,\n",
        "                                      num_replicates)\n",
        "\n",
        "    rmse.append(output['performance_metrics']['scores']['rmse'])\n",
        "    mape.append(output['performance_metrics']['scores']['mape'])\n",
        "    R.append(output['performance_metrics']['scores']['R'])\n",
        "    elapsed_time.append(output['performance_metrics']['scores']['elapsed_time'])\n",
        "\n",
        "    avg_rmse.append(output['performance_metrics']['avg_scores']['rmse'])\n",
        "    avg_mape.append(output['performance_metrics']['avg_scores']['mape'])\n",
        "    avg_R.append(output['performance_metrics']['avg_scores']['R'])\n",
        "    avg_elapsed_time.append(output['performance_metrics']['avg_scores']['elapsed_time'])\n",
        "\n",
        "    if avg_rmse[i] < best_avg_rmse:\n",
        "      best_avg_rmse = avg_rmse[i]\n",
        "      best_rmse = output['best_model']['rmse']\n",
        "      best_model_hidden_layers = hidden_layers[i]\n",
        "      best_model_output = output\n",
        "\n",
        "\n",
        "  rmse = np.array(rmse)\n",
        "  mape = np.array(mape)\n",
        "  R =  np.array(R)\n",
        "\n",
        "  # Collecting all  scores\n",
        "\n",
        "  performance_metrics = {\n",
        "\n",
        "       'scores':  {'layers': hidden_layers,\n",
        "                   'rmse': rmse,\n",
        "                   'mape': mape,\n",
        "                   'R':R,\n",
        "                   'elapsed_time': elapsed_time },\n",
        "\n",
        "       'avg_scores':  pd.DataFrame({'layers': hidden_layers,\n",
        "                                    'rmse': np.array(avg_rmse),\n",
        "                                    'mape': np.array(avg_mape), 'R':np.array(avg_R),\n",
        "                                    'elapsed_time':np.array(avg_elapsed_time)}),\n",
        "\n",
        "       'stds':     pd.DataFrame({'layers': hidden_layers,\n",
        "                                 'rmse': np.std(rmse, axis = 1),\n",
        "                                 'mape': np.std(mape, axis = 1),\n",
        "                                 'R':  np.std(R, axis = 1 ),\n",
        "                                 'elapsed_time': np.std(elapsed_time, axis = 1 )}),\n",
        "       'minimums': pd.DataFrame({'layers': hidden_layers,\n",
        "                                'rmse': np.min(rmse, axis =1 ),\n",
        "                                'mape': np.min(mape, axis= 1),\n",
        "                                'R': np.min(R, axis =1),\n",
        "                                'elapsed_time': np.min(elapsed_time, axis =1)}),\n",
        "\n",
        "       'maximums': pd.DataFrame({'layers': hidden_layers,\n",
        "                                'rmse': np.max(rmse, axis =1),\n",
        "                                'mape': np.max(mape, axis =1),\n",
        "                                'R': np.max(R, axis =1),\n",
        "                                'elapsed_time': np.max(elapsed_time,axis =1)})\n",
        "    }\n",
        "\n",
        "\n",
        "  output_dictionary = {\n",
        "                     'hyper_parameters': hyper_parameters,\n",
        "                      'best_avg_rmse': best_avg_rmse,\n",
        "                      'best_rmse': best_rmse,\n",
        "                      'best_model_hidden_layers': best_model_hidden_layers,\n",
        "                      'best_model_output': best_model_output\n",
        "                      }\n",
        "\n",
        "  #Save all statistics:\n",
        "  performance_metrics['avg_scores'].to_csv(output_dir_path+'multiple_lstm_models_average_scores.csv')\n",
        "  performance_metrics['stds'].to_csv(output_dir_path+'multiple_lstm_models_stds.csv')\n",
        "  performance_metrics['minimums'].to_csv(output_dir_path+'multiple_lstm_models_minimums.csv')\n",
        "  performance_metrics['maximums'].to_csv(output_dir_path+'multiple_lstm_models_maximums.csv')\n",
        "\n",
        "\n",
        "  #Save all scores in the file for future analysis\n",
        "  pd.DataFrame(performance_metrics['scores']['rmse']).to_csv(output_dir_path+'multiple_lstm_models_all_rmse.csv')\n",
        "  pd.DataFrame(performance_metrics['scores']['mape']).to_csv(output_dir_path+'multiple_lstm_models_all_mape.csv')\n",
        "  pd.DataFrame(performance_metrics['scores']['R']).to_csv(output_dir_path+'multiple_lstm_models_all_R.csv')\n",
        "\n",
        "  #Save best model results\n",
        "  pd.DataFrame(best_model_output['best_model']['loss']).to_csv(output_dir_path+'best_lstm_model_loss.csv')\n",
        "  pd.DataFrame(best_model_output['best_model']['train_predictions']).to_csv(output_dir_path+'best_lstm_model_train_predictions.csv')\n",
        "  pd.DataFrame(best_model_output['best_model']['test_predictions']).to_csv(output_dir_path+'best_lstm_model_test_predictions.csv')\n",
        "  pd.DataFrame(best_model_output['performance_metrics']['scores']['rmse']).to_csv(output_dir_path+'best_lstm_model_all_rmse.csv')\n",
        "\n",
        "  # writing all result in the file\n",
        "  write_dic_to_file(output_dictionary, output_dir_path + \"multiple_lstm_models_full_results.txt\")\n",
        "\n",
        "  # Display some key results in the screen\n",
        "  print(\"\\nBest model and its avg rmse and minimum rmse):\\n\", best_model_hidden_layers, best_avg_rmse, best_rmse)\n",
        "  print(\"Hyper_parameters:\\n\", hyper_parameters)\n",
        "  print('\\nAverage scores:\\n',  performance_metrics['avg_scores'])\n",
        "  print('\\nStandard_deviations:\\n',  performance_metrics['stds'])\n",
        "  print('\\nMinimums:\\n',  performance_metrics['minimums'])\n",
        "  print('\\nMaximums:\\n',  performance_metrics['maximums'])\n",
        "\n",
        "  print(\"Progress: All works are done successfully, congratulations!!\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3sSg1v30MAZ"
      },
      "source": [
        "#### **Running Multiple LSTM Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCg-lwZU0Oq4",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "initial_learning_rate= 0.01\n",
        "lstm_hidden_layers = [[8], [16], [32],  [64],  [128]]\n",
        "\n",
        "lstm_best_hyper_parameters =  [ ['Nadam', 16],\n",
        "                                ['Nadam', 8],\n",
        "                                ['Adam', 8],\n",
        "                                ['Nadam', 32],\n",
        "                                ['Nadam', 32]\n",
        "                                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0kyd1KiJQ-46",
        "outputId": "435f776d-50e4-493b-d822-10ae6bc7ebea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running model with hidden neurons:  [8]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Nadam', 16]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "(2847, 5, 1)\n",
            "(708, 5, 1)\n",
            "(2847, 1)\n",
            "(708, 1)\n",
            "(708, 1)\n",
            "Program is running for 0 replicate\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0742\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0172\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0194\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 1 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0685\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0197\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0164\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 2 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0732\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0202\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0174\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0160\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0167\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0196\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 3 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0708\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0171\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0156\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0162\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0184\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 4 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0859\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0158\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0179\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 5 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0747\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0166\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 6 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0717\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0164\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0164\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 7 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0751\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0162\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0200\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0162\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0171\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0169\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0204\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 8 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0694\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 9 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 10ms/step - loss: 0.0736\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0162\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0166\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0160\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0194\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0165\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0205\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 10 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0686\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0179\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0179\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0191\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0166\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0196\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0169\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0165\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0170\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 19/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 20/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 21/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 22/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 23/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 11 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0676\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0159\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0198\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0701\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 13 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 0.0724\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0194\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0175\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 14 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0770\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 15 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0716\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0194\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0161\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 16 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0765\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0165\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0199\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 19/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 17 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0717\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0162\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 19/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 20/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 18 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0732\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0167\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 19/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 19 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0819\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0182\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0193\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0196\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 20 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.0745\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0164\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0165\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0188\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 17ms/step - loss: 0.0173\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 19/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 21 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0754\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0178\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 22 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0738\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0206\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 23 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0647\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0164\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0208\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 24 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0655\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 25 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0653\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0160\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 19/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 26 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0664\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0189\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0206\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0161\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 27 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0687\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0209\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 19/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 28 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0728\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0162\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 29 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0664\n",
            "Epoch 2/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 3/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 5/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 6/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 7/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 8/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 9/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0192\n",
            "Epoch 10/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 11/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 12/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 13/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 14/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 15/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 16/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 17/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165\n",
            "Epoch 18/50\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n",
            "Running model with hidden neurons:  [16]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Nadam', 8]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "(2847, 5, 1)\n",
            "(708, 5, 1)\n",
            "(2847, 1)\n",
            "(708, 1)\n",
            "(708, 1)\n",
            "Program is running for 0 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0389\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 1 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0453\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 2 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0399\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 3 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0463\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 4 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0435\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0203\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 5 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0431\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0198\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0171\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0165\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 6 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 6ms/step - loss: 0.0430\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0199\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0199\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0184\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0169\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 7 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0448\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0168\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 8 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0416\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0200\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0164\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0170\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0199\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 18/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 19/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0186\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 9 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0419\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0168\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0199\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0165\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0168\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0175\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0161\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 10 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0449\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 11 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0436\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0163\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0154\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0442\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0161\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 13 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0421\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0161\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 14 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0403\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0166\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 15 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0472\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0167\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0189\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 16 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0440\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0196\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 17 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0407\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0205\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0203\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0171\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 18 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 0.0428\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0202\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0165\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 18/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 19/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 20/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 19 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0422\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0161\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 20 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0480\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0165\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 21 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0430\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0164\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0170\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 22 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0373\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0159\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 23 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0384\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0168\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 24 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0480\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0204\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0167\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 25 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0436\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0207\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0160\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 26 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0415\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0161\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 27 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0466\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 18/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 28 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0426\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0163\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0200\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 29 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0461\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0205\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0153\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 18/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 19/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 20/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n",
            "Running model with hidden neurons:  [32]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Adam', 8]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "(2847, 5, 1)\n",
            "(708, 5, 1)\n",
            "(2847, 1)\n",
            "(708, 1)\n",
            "(708, 1)\n",
            "Program is running for 0 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0421\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 1 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0429\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0160\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0167\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 2 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0444\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0193\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 3 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0413\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0166\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0203\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0196\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 4 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0354\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0204\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0171\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0173\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0189\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0169\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 5 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0420\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0173\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0195\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 6 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0356\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0164\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0175\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 7 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0432\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0166\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 8 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0434\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0170\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - loss: 0.0191\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0174\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0175\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 9 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0409\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0196\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0169\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 18/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 19/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 20/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 10 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0398\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0172\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 11 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0490\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0174\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0198\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0424\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 13 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0480\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 14 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0550\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0184\n",
            "Epoch 18/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0162\n",
            "Epoch 19/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 15 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0474\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0194\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 16 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0409\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0205\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0166\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0203\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 17 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0418\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0201\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0167\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 18 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0383\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0189\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 19 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0416\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0166\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0162\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 20 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0388\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 21 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0389\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0162\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 22 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0395\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 23 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0404\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 16/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 17/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 18/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 24 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0441\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0161\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 25 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0463\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0162\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0168\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 26 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0358\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0171\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0171\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 27 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0504\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0161\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 28 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0433\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 14/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 15/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 29 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0429\n",
            "Epoch 2/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 3/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 4/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 5/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 6/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 8/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 10/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 11/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0166\n",
            "Epoch 12/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0200\n",
            "Epoch 13/50\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n",
            "Running model with hidden neurons:  [64]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Nadam', 32]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "(2847, 5, 1)\n",
            "(708, 5, 1)\n",
            "(2847, 1)\n",
            "(708, 1)\n",
            "(708, 1)\n",
            "Program is running for 0 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0663\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0162\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0192\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0166\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0191\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0191\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 1 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0591\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0158\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0206\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0189\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0204\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0189\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 2 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0672\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0172\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0170\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 3 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0568\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0174\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0199\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0153\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0166\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 4 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0635\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0205\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0170\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0194\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0164\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0172\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0202\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 5 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0668\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0207\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0201\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 6 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0626\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0167\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0201\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 28/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 29/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 7 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0597\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0165\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0187\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0176\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0174\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0198\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 8 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0621\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0189\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0179\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0197\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0171\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 9 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0636\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0198\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0166\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0203\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0161\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0189\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 10 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0666\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0165\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0184\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0189\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0172\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0196\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 11 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0662\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0198\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0162\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0180\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0172\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0200\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0599\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0181\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0166\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0204\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0170\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 13 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0588\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0196\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0170\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0196\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0157\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0199\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 14 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - loss: 0.0677\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0197\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0197\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0162\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0171\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0174\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0182\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0178\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0203\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0169\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 15 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0612\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0174\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0191\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0176\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0165\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0149\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0174\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0165\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0167\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0198\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0176\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0185\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0176\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0182\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0188\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 16 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0645\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0205\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0166\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0197\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0172\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0173\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0170\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0197\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0178\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0200\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0196\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0166\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0193\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0171\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0168\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 28/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 17 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0659\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0163\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 18 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0692\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0205\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0167\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0175\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0174\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0158\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0199\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0172\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0165\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0183\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 19 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0631\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0191\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0186\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0166\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0160\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0185\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0195\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0192\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0175\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0177\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0169\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 20 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - loss: 0.0641\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0170\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0194\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0167\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0164\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0177\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0176\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0165\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 21 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0618\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0195\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0189\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0175\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0187\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0162\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0196\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0202\n",
            "Epoch 28/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 29/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0160\n",
            "Epoch 30/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0188\n",
            "Epoch 31/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0167\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 22 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0676\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0184\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0194\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0178\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0172\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0167\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0197\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0198\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0192\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 23 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0631\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0200\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0184\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0168\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0178\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0172\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0205\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0167\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0170\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0202\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 24 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0577\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0191\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0162\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0168\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0167\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0172\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 25 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0595\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0204\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0174\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0162\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 26 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0603\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0167\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0199\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0190\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0177\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0185\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0176\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0170\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0169\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0164\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0164\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 27 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0606\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0202\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0169\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0183\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0193\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0166\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0203\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 28 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0636\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0171\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0181\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0189\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0167\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0193\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0159\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0208\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 28/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 29/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 30/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 29 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0636\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0208\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0172\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0171\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0197\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0174\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0175\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0169\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0196\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n",
            "Running model with hidden neurons:  [128]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Nadam', 32]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "(2847, 5, 1)\n",
            "(708, 5, 1)\n",
            "(2847, 1)\n",
            "(708, 1)\n",
            "(708, 1)\n",
            "Program is running for 0 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0699\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0177\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0178\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0192\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0168\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0186\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0177\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0171\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0184\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0173\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0177\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0193\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0195\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0177\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0176\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0178\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0181\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0183\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0168\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0184\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0173\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0171\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 1 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.0665\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0175\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0184\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0192\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0190\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0191\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0169\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0201\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0166\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0193\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0181\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0171\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0175\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0177\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0182\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0191\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0176\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0188\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0185\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0176\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0175\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0173\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 2 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0652\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0190\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0192\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0174\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0183\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0169\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0182\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0189\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0172\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0176\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0189\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0177\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0168\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0166\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0185\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0167\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0192\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0189\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0194\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0187\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0173\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 3 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0678\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0180\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0206\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0176\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0185\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0194\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0188\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0166\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0177\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0176\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0188\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0190\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0181\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0187\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0180\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0173\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0184\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0190\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0191\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0172\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0164\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0175\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0179\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0173\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0177\n",
            "Epoch 28/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 4 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0655\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0196\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0176\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0170\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0177\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0174\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0168\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0174\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0188\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0188\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0193\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0200\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0177\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0162\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0173\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0189\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 5 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - loss: 0.0587\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0200\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0176\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0190\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0185\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0187\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0169\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0174\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0192\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0171\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0178\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0197\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0195\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0177\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0179\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0171\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0175\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0190\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0175\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0172\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 6 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0674\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0184\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0173\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0165\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0194\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0191\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0212\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0184\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0173\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0188\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0174\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0174\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0189\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0192\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0190\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0192\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0195\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0180\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0186\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0192\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0179\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0178\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 7 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0595\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0164\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0184\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0169\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0182\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0211\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0173\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0178\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0191\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0186\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0164\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0162\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0200\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0175\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0186\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0178\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0197\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0175\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0177\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0172\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0164\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0192\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0194\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0174\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0182\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0189\n",
            "Epoch 28/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 8 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0866\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0179\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0186\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0193\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0178\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0177\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0183\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0199\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0190\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0176\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0179\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0198\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0169\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0194\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0169\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0171\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0176\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0183\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0182\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0200\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0179\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0166\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 9 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - loss: 0.0706\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0176\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0185\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0196\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0182\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0185\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0193\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0168\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0162\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0172\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0178\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0187\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0184\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0176\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0169\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0184\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0175\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0183\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0175\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0170\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0187\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0195\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 10 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0704\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0193\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0196\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0170\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0190\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0166\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0184\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0174\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0173\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0183\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0185\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0187\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0176\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0179\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0172\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0177\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0190\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0176\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0190\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0164\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0176\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0190\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0174\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 11 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0732\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0200\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0191\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0193\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0185\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0173\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0185\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0180\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0176\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0181\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0192\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0171\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0180\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0172\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0184\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0182\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0180\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0173\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0191\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0208\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 0.0750\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0183\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0172\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0173\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0177\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0177\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0180\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0175\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0166\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0184\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0202\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0175\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0180\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0174\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0171\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - loss: 0.0198\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0199\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0166\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0177\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0175\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 13 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.0686\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0196\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0192\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0171\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0168\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0187\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0172\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0169\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0177\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0167\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0180\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0179\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0163\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0197\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0188\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0189\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0177\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0188\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0179\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0194\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0181\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0191\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0177\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 14 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0598\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0168\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0192\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0180\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0175\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0192\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0177\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0202\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0195\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0175\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0192\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0170\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0183\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0188\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0167\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0175\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0195\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0186\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0194\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0181\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0184\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0183\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0185\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0192\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0171\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0166\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0184\n",
            "Epoch 28/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 15 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - loss: 0.0676\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0193\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0163\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0183\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 25ms/step - loss: 0.0186\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0169\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0173\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0196\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0199\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0182\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0171\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0180\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0189\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0180\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0189\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0167\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0171\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 16 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0698\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0197\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0173\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0179\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0180\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0188\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0174\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0178\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0179\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0185\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0174\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0189\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0185\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0183\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0173\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0177\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0191\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0183\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0173\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0182\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 17 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - loss: 0.0669\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0171\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0181\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0201\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0166\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0186\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0161\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0175\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0177\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0177\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0165\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0180\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0162\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0171\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0167\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0185\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - loss: 0.0181\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 18 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - loss: 0.0571\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0174\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0187\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0195\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0210\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0192\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0171\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0196\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0169\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0189\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0173\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0175\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0184\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0181\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0177\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0196\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0183\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0183\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0176\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0186\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0196\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 19 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - loss: 0.0662\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0185\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0182\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0183\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0178\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0169\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0194\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0197\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0177\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0190\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - loss: 0.0196\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0192\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0175\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0175\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0176\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0182\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0183\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0196\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0180\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0182\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0176\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 20 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0651\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0199\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0193\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0171\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0185\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0184\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0169\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0171\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0194\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0202\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0168\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0200\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0192\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0191\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0179\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0181\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0189\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0179\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0176\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - loss: 0.0168\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - loss: 0.0173\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0187\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0160\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0176\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 28/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 21 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - loss: 0.0657\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0189\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0176\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0177\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0185\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0176\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0184\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0182\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0197\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0167\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0174\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0184\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0175\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 16ms/step - loss: 0.0188\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0171\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0189\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0171\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0172\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0178\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0175\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0180\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 22 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0699\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0188\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0189\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0189\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0191\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0177\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0193\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0192\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0191\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0192\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0197\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0187\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0191\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0180\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0179\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0179\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0183\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0183\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0190\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0172\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0171\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 23 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0723\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 23ms/step - loss: 0.0190\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0168\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0195\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0189\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0194\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0172\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0178\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0189\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0188\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0174\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0183\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0169\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0184\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0174\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0173\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0179\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0202\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0200\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0164\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0187\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0176\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0193\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0170\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0181\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0170\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 24 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 21ms/step - loss: 0.0629\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0174\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0181\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0176\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0199\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0179\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0176\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0175\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0169\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0166\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0173\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0186\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0174\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0170\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0174\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0185\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0173\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0172\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0177\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0179\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0155\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0183\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 25 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 18ms/step - loss: 0.0581\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0186\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0189\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0167\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0171\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0189\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0189\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0173\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0188\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0170\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0185\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0165\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0190\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0190\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0187\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0178\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0195\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0188\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 26 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - loss: 0.0617\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0159\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0188\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0175\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0184\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0180\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0179\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0174\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0173\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0203\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 21ms/step - loss: 0.0171\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0190\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0180\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0206\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0171\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0180\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0181\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0184\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0184\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0155\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0186\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - loss: 0.0169\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0171\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 27 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.0587\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0186\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0201\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0201\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - loss: 0.0182\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0191\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0192\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0173\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0191\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0195\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0202\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0199\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0182\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0185\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0197\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0181\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0185\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0180\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0192\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0187\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 28 replicate\n",
            "\n",
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - loss: 0.0614\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0195\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0172\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0182\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0187\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0186\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0169\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0191\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 22ms/step - loss: 0.0177\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - loss: 0.0192\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0172\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0186\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0168\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0173\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0179\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0175\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0175\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - loss: 0.0176\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0162\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - loss: 0.0173\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0167\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0193\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0180\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0181\n",
            "Epoch 25/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0182\n",
            "Epoch 26/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0167\n",
            "Epoch 27/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0160\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Program is running for 29 replicate\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - loss: 0.0650\n",
            "Epoch 2/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0181\n",
            "Epoch 3/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0175\n",
            "Epoch 4/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0201\n",
            "Epoch 5/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0185\n",
            "Epoch 6/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0181\n",
            "Epoch 7/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 8/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - loss: 0.0177\n",
            "Epoch 9/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - loss: 0.0185\n",
            "Epoch 10/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - loss: 0.0206\n",
            "Epoch 11/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0183\n",
            "Epoch 12/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 13/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 14/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0202\n",
            "Epoch 15/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0179\n",
            "Epoch 16/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0183\n",
            "Epoch 17/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: 0.0169\n",
            "Epoch 18/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.0172\n",
            "Epoch 19/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0185\n",
            "Epoch 20/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0180\n",
            "Epoch 21/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 22/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0171\n",
            "Epoch 23/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0179\n",
            "Epoch 24/50\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0188\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "train pred shape (2847, 1)\n",
            "(708, 1)\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Best model and its avg rmse and minimum rmse):\n",
            " [32] 44.58021038023392 43.79930685230439\n",
            "Hyper_parameters:\n",
            " [['Nadam', 16], ['Nadam', 8], ['Adam', 8], ['Nadam', 32], ['Nadam', 32]]\n",
            "\n",
            "Average scores:\n",
            "   layers       rmse       mape   R  elapsed_time\n",
            "0    [8]  44.729022  13.434020 NaN     24.807604\n",
            "1   [16]  44.709630  13.410421 NaN     33.374883\n",
            "2   [32]  44.580210  13.368728 NaN     34.542016\n",
            "3   [64]  44.909537  13.451575 NaN     23.622589\n",
            "4  [128]  44.869850  13.440864 NaN     45.208976\n",
            "\n",
            "Standard_deviations:\n",
            "   layers      rmse      mape   R  elapsed_time\n",
            "0    [8]  0.166476  0.055772 NaN      6.441963\n",
            "1   [16]  0.337077  0.144771 NaN      8.115647\n",
            "2   [32]  0.323427  0.144401 NaN      7.874157\n",
            "3   [64]  0.074637  0.027942 NaN      3.974916\n",
            "4  [128]  0.138287  0.045502 NaN      5.635702\n",
            "\n",
            "Minimums:\n",
            "   layers       rmse       mape   R  elapsed_time\n",
            "0    [8]  44.406877  13.342905 NaN     16.461380\n",
            "1   [16]  44.125359  13.149973 NaN     21.764086\n",
            "2   [32]  43.799307  13.038018 NaN     24.538701\n",
            "3   [64]  44.796007  13.410017 NaN     18.331655\n",
            "4  [128]  44.562566  13.344057 NaN     33.683151\n",
            "\n",
            "Maximums:\n",
            "   layers       rmse       mape   R  elapsed_time\n",
            "0    [8]  45.126035  13.570123 NaN     44.176704\n",
            "1   [16]  45.452968  13.715406 NaN     50.846262\n",
            "2   [32]  45.098703  13.557346 NaN     55.331795\n",
            "3   [64]  45.081685  13.518247 NaN     35.902107\n",
            "4  [128]  45.058105  13.505979 NaN     55.677182\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Multiple_LSTM_Models(lstm_hidden_layers,\n",
        "                    lstm_best_hyper_parameters,\n",
        "                    data1,\n",
        "                    time_step = 5,\n",
        "                    test_split = 0.1518,\n",
        "                    initial_learning_rate=initial_learning_rate,\n",
        "                    epochs = 50,\n",
        "                    num_replicates = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aA-QrPrLjaR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiPWUSMlLjVN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHze4bCCUMYp"
      },
      "source": [
        "### **GRU Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjpDKe5LTALL"
      },
      "outputs": [],
      "source": [
        "def Build_GRU_Model(layers,\n",
        "                    time_step,\n",
        "                    num_features,\n",
        "                    optimizer='Adam',\n",
        "                    initial_learning_rate=0.01,\n",
        "                    decay_steps=5,\n",
        "                    decay_rate=0.95):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=(time_step, num_features)))\n",
        "\n",
        "    for i, units in enumerate(layers):  # Use enumerate for index and value\n",
        "        return_sequences = (i < len(layers) - 1)  # return True/False, if True, proceeds\n",
        "\n",
        "        model.add(GRU(units, return_sequences=return_sequences))\n",
        "\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    learning_rate = ExponentialDecay(\n",
        "        initial_learning_rate=initial_learning_rate,\n",
        "        decay_steps=decay_steps,\n",
        "        decay_rate=decay_rate,\n",
        "        staircase=True\n",
        "    )\n",
        "\n",
        "    # Optimizer selection\n",
        "    optimizer_mapping = {\n",
        "        'Adam': optimizers.Adam,\n",
        "        'Adagrad': optimizers.Adagrad,\n",
        "        'Nadam': optimizers.Nadam,\n",
        "        'Adadelta': optimizers.Adadelta,\n",
        "        'RMSprop': optimizers.RMSprop\n",
        "    }\n",
        "\n",
        "    if optimizer in optimizer_mapping:\n",
        "        opt = optimizer_mapping[optimizer](learning_rate=learning_rate)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported optimizer: {optimizer}. Choose from: {list(optimizer_mapping.keys())}\")\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer=opt)\n",
        "\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANdTN9Tt-Wm1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8C0sHoUMTto6"
      },
      "outputs": [],
      "source": [
        "# Sample code to run the model:\n",
        "optimizers_names = ['Adam']\n",
        "time_step = 5\n",
        "num_features = 1\n",
        "verbose = 1\n",
        "layers = [16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhdI3mdDTto8"
      },
      "outputs": [],
      "source": [
        "# Build and compile the model (updated call)\n",
        "model = Build_GRU_Model(\n",
        "    layers,\n",
        "    time_step,\n",
        "    num_features,\n",
        "    optimizer=optimizers_names[0]  # Pass the optimizer name directly\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "xzRlpCsR5yaU",
        "outputId": "6fa6b7b1-977b-4372-cbde-bc0c47c04252"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │             \u001b[38;5;34m912\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m17\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">912</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m929\u001b[0m (3.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">929</span> (3.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m929\u001b[0m (3.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">929</span> (3.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T_ovngs_0eGW"
      },
      "outputs": [],
      "source": [
        "def GRU_Hyper_Parameter_Tuning(layers,\n",
        "                                X_train,\n",
        "                                y_train,\n",
        "                                time_step,\n",
        "                                split,\n",
        "                                optimizers_names,\n",
        "                                initial_learning_rate,\n",
        "                                batch_sizes,\n",
        "                                epochs,\n",
        "                                num_replicates=2):\n",
        "    # Data Preparation\n",
        "    y_train_min, y_train_max = y_train.min(), y_train.max()\n",
        "\n",
        "\n",
        "    # X_train_scaled = min_max_transform(X_train)\n",
        "    y_train_scaled = min_max_transform(y_train)\n",
        "\n",
        "\n",
        "\n",
        "    X_train1, X_val = data_split(X_train, split)\n",
        "    y_train, y_val = data_split(y_train_scaled, split)\n",
        "\n",
        "    num_features = X_train.shape[1]\n",
        "\n",
        "\n",
        "    # Hyperparameter Tuning\n",
        "    best_avg_rmse = float('inf')  # Use infinity to start\n",
        "    all_avg_rmse = np.zeros((len(optimizers_names), len(batch_sizes)))\n",
        "    best_hyper_parameters = {\"model\": layers, \"optimizer\": None, \"batch_size\": None, \"best_avg_rmse\": None}\n",
        "\n",
        "    for opt_idx, optimizer_name in enumerate(optimizers_names):\n",
        "        for bs_idx, batch_size in enumerate(batch_sizes):\n",
        "            collect_rmse = []\n",
        "\n",
        "            for i in range(num_replicates):\n",
        "                print(f\"Running for optimizer {optimizer_name}, batch size {batch_size}, replicate {i + 1}\")\n",
        "\n",
        "                model = Build_GRU_Model(layers,\n",
        "                                         time_step,\n",
        "                                         num_features,\n",
        "                                         optimizer_name,\n",
        "                                         initial_learning_rate=initial_learning_rate)\n",
        "\n",
        "                callback = EarlyStopping(monitor='val_loss', patience=5)\n",
        "                history = model.fit(X_train1, y_train,\n",
        "                                    batch_size=batch_size,\n",
        "                                    epochs=epochs,\n",
        "                                    validation_data=(X_val, y_val),\n",
        "                                    callbacks=[callback],\n",
        "                                    verbose=1)\n",
        "\n",
        "                val_pred = model.predict(X_val).ravel()\n",
        "                # min_val, max_val = y_train.min(), train_data[target_var].max()\n",
        "\n",
        "                val_pred_original = min_max_inverse_transform(val_pred, y_train_min, y_train_max)\n",
        "                y_val_original = min_max_inverse_transform(y_val, y_train_min, y_train_max)\n",
        "                collect_rmse.append(math.sqrt(mean_squared_error(y_val_original, val_pred_original)))\n",
        "\n",
        "            avg_rmse = np.mean(np.array(collect_rmse))\n",
        "            all_avg_rmse[opt_idx][bs_idx] = avg_rmse\n",
        "\n",
        "            if avg_rmse < best_avg_rmse:\n",
        "                best_avg_rmse = avg_rmse\n",
        "                best_hyper_parameters = {\n",
        "                    \"model\": layers, \"optimizer\": optimizer_name, \"batch_size\": batch_size, \"best_avg_rmse\": best_avg_rmse\n",
        "                }\n",
        "\n",
        "    # Output and Results\n",
        "    file_name = output_dir_path + \"gru-\" + str(layers[0]) + \"N-hyperparameter_tuning__results\" + \".txt\"\n",
        "    write_dic_to_file(best_hyper_parameters, file_name)  # Just write best_hyper_parameters\n",
        "\n",
        "    print(\"Best hyperparameters (GRU): \\n\", best_hyper_parameters)\n",
        "    print(\"All average RMSE (GRU): \\n\", all_avg_rmse)\n",
        "\n",
        "    return best_hyper_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wg23OhFJTto-"
      },
      "outputs": [],
      "source": [
        "#these are fixed\n",
        "time_step = 5\n",
        "test_split = 0.1518\n",
        "val_split = 0.1518\n",
        "optimizers_names = ['Adam', 'Nadam', 'Adagrad']\n",
        "batch_sizes =  [8, 16, 32]\n",
        "initial_learning_rate=0.01\n",
        "epochs = 30\n",
        "num_replicates = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "2Kc-HgEKTto-",
        "outputId": "038e5681-d6a7-4f07-c4f4-5aea1b4fcb40",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running for optimizer Adam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0557 - val_loss: 0.0783\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0815\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0814\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0807\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0811\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0811\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0802 - val_loss: 0.0782\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0815\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0818\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.0806\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0817\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0329 - val_loss: 0.0779\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0814\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0814\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0805\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0810\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0812\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0822\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0825\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0361 - val_loss: 0.0848\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0095 - val_loss: 0.0811\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0097 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0811\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0811\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0811\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0811\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0627 - val_loss: 0.0829\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0098 - val_loss: 0.0822\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0098 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0819\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0819\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0098 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0182 - val_loss: 0.0803\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0379 - val_loss: 0.0874\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0831\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0810\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0815\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0815\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0411 - val_loss: 0.0782\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0830\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0414 - val_loss: 0.0880\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0815\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0800\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0816\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0815\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0142 - val_loss: 0.0805\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0781\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0227 - val_loss: 0.0840\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0800\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0808\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0808\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0809\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0810\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0809\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1444 - val_loss: 0.0879\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0114 - val_loss: 0.0821\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0097 - val_loss: 0.0818\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0095 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0814\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0814\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: 0.0814\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0814\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0814\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0814\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1225 - val_loss: 0.0860\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0827\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0831\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0817\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0817\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0817\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0817\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0817\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0571 - val_loss: 0.0770\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0785\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0808\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0097 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0420 - val_loss: 0.0829\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0097 - val_loss: 0.0798\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0805\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0812\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.0908\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0775\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0838\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0794 - val_loss: 0.0742\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0104 - val_loss: 0.0815\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0790\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0834\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2449 - val_loss: 0.0834\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0124 - val_loss: 0.0824\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0103 - val_loss: 0.0816\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0834\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0102 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: 0.0815\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: 0.0817\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0099 - val_loss: 0.0816\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0102 - val_loss: 0.0815\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0098 - val_loss: 0.0815\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0097 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0538 - val_loss: 0.0879\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0848\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0789\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0786\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0807\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0816\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0815\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0273 - val_loss: 0.0846\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0102 - val_loss: 0.0767\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0854\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0859\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0809\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0810\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0895 - val_loss: 0.0808\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0097 - val_loss: 0.0837\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0095 - val_loss: 0.0836\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0099 - val_loss: 0.0824\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0091 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0793 - val_loss: 0.0832\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - val_loss: 0.0852\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0801\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0816\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0704 - val_loss: 0.0856\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0758\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0794\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0817\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.2201 - val_loss: 0.0963\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0155 - val_loss: 0.0804\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0100 - val_loss: 0.0838\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0099 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0806\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0808\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0328 - val_loss: 0.0795\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0097 - val_loss: 0.0800\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0808\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0809\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0584 - val_loss: 0.0861\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0834\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0810\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0090 - val_loss: 0.0808\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0816\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0820\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0814\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0088 - val_loss: 0.0814\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0818\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0820\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0817\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0605 - val_loss: 0.0765\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0822\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0823\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0822\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0499 - val_loss: 0.0784\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0815\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0088 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0774\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0814\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.0860\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0824\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0820\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0820\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0820\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0820\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0820\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0256 - val_loss: 0.0807\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0816\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0567 - val_loss: 0.0813\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0809\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0815\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0470 - val_loss: 0.0807\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0817\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0816\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0088 - val_loss: 0.0816\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0816\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: 0.0823\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0829\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0819\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0541 - val_loss: 0.0787\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0096 - val_loss: 0.0809\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0098 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0811\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0180 - val_loss: 0.0779\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0821\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0797\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0451 - val_loss: 0.0835\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0838\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0807\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0820\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0820\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0393 - val_loss: 0.0873\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0827\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0796\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0810\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0811\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0811\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0811\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0200 - val_loss: 0.0778\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0804\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0083 - val_loss: 0.0798\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0810\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0445 - val_loss: 0.0768\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0811\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0806\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0619 - val_loss: 0.0848\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0789\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0832\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0827\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0827\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0826\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0826\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0660 - val_loss: 0.0766\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0813\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0082 - val_loss: 0.0816\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0476 - val_loss: 0.0822\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0751\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0801\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0809\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0098 - val_loss: 0.0810\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0093 - val_loss: 0.0810\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0245 - val_loss: 0.0803\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0849\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0807\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1294 - val_loss: 0.0838\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0097 - val_loss: 0.0818\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0810\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0811\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0811\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0811\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0246 - val_loss: 0.0897\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0820\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0757\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0808\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0810\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0816\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1337 - val_loss: 0.0811\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0831\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0829\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0807\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0815\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0813\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0818\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0816\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0714 - val_loss: 0.0818\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0792\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0785\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0810\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0817\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0814\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - loss: 0.1878 - val_loss: 0.0838\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0090 - val_loss: 0.0789\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0857\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0865\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1725 - val_loss: 0.0870\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0829\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0803\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0098 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0818\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0817\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0816\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0228 - val_loss: 0.0891\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0090 - val_loss: 0.0765\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0781\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0804\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0839\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0789 - val_loss: 0.0735\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0803\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0795\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0828\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0810\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0801\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1787 - val_loss: 0.0844\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0099 - val_loss: 0.0814\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0807\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0810\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0813\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0813\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0815\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.1481 - val_loss: 0.0932\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0118 - val_loss: 0.0843\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0097 - val_loss: 0.0796\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0799\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0804\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0812\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0965 - val_loss: 0.0820\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0791\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0832\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0803\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0807\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0944\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0216 - val_loss: 0.0943\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0206 - val_loss: 0.0943\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0212 - val_loss: 0.0943\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0943\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0207 - val_loss: 0.0943\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0943\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0943\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0394 - val_loss: 0.1022\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.1020\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0298 - val_loss: 0.1019\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.1019\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.1019\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0308 - val_loss: 0.1019\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.1019\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.1019\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0502 - val_loss: 0.0961\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0957\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0209 - val_loss: 0.0957\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0957\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0957\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0957\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0957\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0957\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0957\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1365 - val_loss: 0.1169\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.1146\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0295 - val_loss: 0.1145\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0300 - val_loss: 0.1145\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0303 - val_loss: 0.1145\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.1145\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.1145\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - val_loss: 0.1145\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.1145\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1570 - val_loss: 0.1335\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0380 - val_loss: 0.1305\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0373 - val_loss: 0.1304\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0380 - val_loss: 0.1304\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0374 - val_loss: 0.1304\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0366 - val_loss: 0.1304\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.1304\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0372 - val_loss: 0.1304\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - val_loss: 0.1304\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0356 - val_loss: 0.1304\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.1255 - val_loss: 0.1423\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0579 - val_loss: 0.1400\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0606 - val_loss: 0.1400\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0589 - val_loss: 0.1400\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.1400\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0553 - val_loss: 0.1400\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0602 - val_loss: 0.1400\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0614 - val_loss: 0.1400\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0648 - val_loss: 0.1400\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0592 - val_loss: 0.1400\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0909 - val_loss: 0.1246\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0329 - val_loss: 0.1225\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0322 - val_loss: 0.1224\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0333 - val_loss: 0.1224\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.1224\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.1224\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.1224\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0325 - val_loss: 0.1224\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0333 - val_loss: 0.1224\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0366 - val_loss: 0.0929\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0934\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0935\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0935\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0935\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0935\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0486 - val_loss: 0.0952\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0954\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0954\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0954\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0234 - val_loss: 0.0954\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0232 - val_loss: 0.0954\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1373 - val_loss: 0.1543\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0580 - val_loss: 0.1513\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0570 - val_loss: 0.1512\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0594 - val_loss: 0.1512\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0605 - val_loss: 0.1512\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0615 - val_loss: 0.1512\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0604 - val_loss: 0.1512\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0596 - val_loss: 0.1512\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0590 - val_loss: 0.1512\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0330 - val_loss: 0.0918\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0900\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0897\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0897\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0897\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0897\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0897\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0897\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0897\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1032 - val_loss: 0.1191\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0487 - val_loss: 0.1151\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0478 - val_loss: 0.1149\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0480 - val_loss: 0.1147\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0466 - val_loss: 0.1147\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0469 - val_loss: 0.1146\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0470 - val_loss: 0.1146\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0476 - val_loss: 0.1146\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0455 - val_loss: 0.1146\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0457 - val_loss: 0.1146\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0455 - val_loss: 0.1146\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0450 - val_loss: 0.1146\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0463 - val_loss: 0.1146\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0469 - val_loss: 0.1082\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0336 - val_loss: 0.1045\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0331 - val_loss: 0.1042\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.1041\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - val_loss: 0.1040\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.1040\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.1040\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0333 - val_loss: 0.1040\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.1040\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - val_loss: 0.1040\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.1040\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.1040\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.1040\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0291 - val_loss: 0.0888\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0887\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0885\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0163 - val_loss: 0.0884\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0884\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0159 - val_loss: 0.0884\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0884\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0884\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171 - val_loss: 0.0884\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0884\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0162 - val_loss: 0.0884\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0674 - val_loss: 0.1004\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0234 - val_loss: 0.0984\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0980\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0979\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - val_loss: 0.0979\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - val_loss: 0.0979\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0979\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0979\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0222 - val_loss: 0.0979\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0979\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0979\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0979\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0979\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.2572 - val_loss: 0.1398\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0410 - val_loss: 0.1243\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.1220\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0380 - val_loss: 0.1215\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0363 - val_loss: 0.1214\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0365 - val_loss: 0.1214\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.1214\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.1214\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.1214\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - val_loss: 0.1214\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0362 - val_loss: 0.1214\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0376 - val_loss: 0.1214\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0371 - val_loss: 0.1214\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1356 - val_loss: 0.1212\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.1098\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.1082\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.1079\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.1078\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.1078\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.1078\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0221 - val_loss: 0.1078\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: 0.1078\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0215 - val_loss: 0.1078\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0218 - val_loss: 0.1078\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.1078\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0232 - val_loss: 0.1078\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0460 - val_loss: 0.1036\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.1015\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.1012\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.1011\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.1011\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0280 - val_loss: 0.1011\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: 0.1011\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.1011\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.1011\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0292 - val_loss: 0.1011\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0270 - val_loss: 0.1011\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.1011\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0286 - val_loss: 0.1011\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1219 - val_loss: 0.1069\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0994\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0982\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0980\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0980\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172 - val_loss: 0.0980\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0980\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0980\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0980\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0980\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0980\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0980\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0980\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0466 - val_loss: 0.0964\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0219 - val_loss: 0.0948\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0948\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0947\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0947\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0947\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: 0.0947\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0947\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0947\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0947\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0205 - val_loss: 0.0947\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0206 - val_loss: 0.0947\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0823 - val_loss: 0.1087\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.1018\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0274 - val_loss: 0.0999\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0280 - val_loss: 0.0994\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0991\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0254 - val_loss: 0.0990\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0256 - val_loss: 0.0990\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0260 - val_loss: 0.0989\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0267 - val_loss: 0.0989\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0258 - val_loss: 0.0989\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0264 - val_loss: 0.0989\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0252 - val_loss: 0.0989\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0989\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0989\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0989\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0989\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0989\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0989\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0989\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1006 - val_loss: 0.1067\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0988\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0971\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0964\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0962\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0961\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0960\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0960\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0960\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0960\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0960\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0960\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0236 - val_loss: 0.0960\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0222 - val_loss: 0.0960\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0220 - val_loss: 0.0960\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0220 - val_loss: 0.0960\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0223 - val_loss: 0.0960\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0231 - val_loss: 0.0960\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0225 - val_loss: 0.0960\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0223 - val_loss: 0.0960\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0857 - val_loss: 0.1216\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0612 - val_loss: 0.1220\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0572 - val_loss: 0.1208\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0549 - val_loss: 0.1205\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0571 - val_loss: 0.1203\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0558 - val_loss: 0.1202\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0543 - val_loss: 0.1201\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0525 - val_loss: 0.1201\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0541 - val_loss: 0.1201\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0545 - val_loss: 0.1201\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0546 - val_loss: 0.1201\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0551 - val_loss: 0.1201\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0556 - val_loss: 0.1201\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0554 - val_loss: 0.1201\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0537 - val_loss: 0.1201\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0551 - val_loss: 0.1201\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0548 - val_loss: 0.1201\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0545 - val_loss: 0.1201\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0551 - val_loss: 0.1201\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0566 - val_loss: 0.1201\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.2933 - val_loss: 0.2483\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0772 - val_loss: 0.1901\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0669 - val_loss: 0.1745\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0619 - val_loss: 0.1687\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0618 - val_loss: 0.1663\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0628 - val_loss: 0.1653\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0614 - val_loss: 0.1648\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0626 - val_loss: 0.1646\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0603 - val_loss: 0.1645\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0642 - val_loss: 0.1645\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0619 - val_loss: 0.1645\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0628 - val_loss: 0.1645\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0628 - val_loss: 0.1645\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0627 - val_loss: 0.1645\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0602 - val_loss: 0.1645\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0618 - val_loss: 0.1645\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0627 - val_loss: 0.1645\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0635 - val_loss: 0.1645\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0615 - val_loss: 0.1645\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0632 - val_loss: 0.1645\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0612 - val_loss: 0.1645\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1387 - val_loss: 0.1391\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0336 - val_loss: 0.1149\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.1095\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0295 - val_loss: 0.1078\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.1071\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.1067\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.1066\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0293 - val_loss: 0.1065\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.1065\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.1065\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.1065\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.1065\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.1065\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0304 - val_loss: 0.1065\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.1065\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.1065\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0302 - val_loss: 0.1065\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0291 - val_loss: 0.1065\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.1065\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0294 - val_loss: 0.1065\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0744 - val_loss: 0.1258\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0597 - val_loss: 0.1205\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0551 - val_loss: 0.1189\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0498 - val_loss: 0.1186\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0511 - val_loss: 0.1184\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0517 - val_loss: 0.1185\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0503 - val_loss: 0.1184\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0508 - val_loss: 0.1184\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0515 - val_loss: 0.1184\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0499 - val_loss: 0.1184\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0501 - val_loss: 0.1184\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0516 - val_loss: 0.1184\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0506 - val_loss: 0.1184\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0497 - val_loss: 0.1184\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0514 - val_loss: 0.1184\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0493 - val_loss: 0.1184\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0515 - val_loss: 0.1184\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0502 - val_loss: 0.1184\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0512 - val_loss: 0.1184\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.4259 - val_loss: 0.2234\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0667 - val_loss: 0.1573\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0544 - val_loss: 0.1429\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0513 - val_loss: 0.1382\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0505 - val_loss: 0.1362\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0508 - val_loss: 0.1353\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0507 - val_loss: 0.1350\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0504 - val_loss: 0.1348\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0507 - val_loss: 0.1347\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0511 - val_loss: 0.1347\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0494 - val_loss: 0.1347\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0513 - val_loss: 0.1347\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0500 - val_loss: 0.1347\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0510 - val_loss: 0.1347\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0491 - val_loss: 0.1347\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0497 - val_loss: 0.1347\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0491 - val_loss: 0.1347\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0520 - val_loss: 0.1347\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0499 - val_loss: 0.1347\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0500 - val_loss: 0.1347\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0493 - val_loss: 0.1347\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0518 - val_loss: 0.0963\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0922\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0917\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0915\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0914\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0913\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0913\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0913\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0913\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0913\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0913\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0913\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0193 - val_loss: 0.0913\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0188 - val_loss: 0.0913\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185 - val_loss: 0.0913\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0194 - val_loss: 0.0913\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0199 - val_loss: 0.0913\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187 - val_loss: 0.0913\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188 - val_loss: 0.0913\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0186 - val_loss: 0.0913\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.6073 - val_loss: 0.4237\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1248 - val_loss: 0.2924\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0751 - val_loss: 0.2549\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0658 - val_loss: 0.2409\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0618 - val_loss: 0.2351\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0615 - val_loss: 0.2326\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0599 - val_loss: 0.2315\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0604 - val_loss: 0.2311\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0584 - val_loss: 0.2308\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0586 - val_loss: 0.2308\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0590 - val_loss: 0.2307\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0595 - val_loss: 0.2307\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.2307\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0606 - val_loss: 0.2307\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0597 - val_loss: 0.2307\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0602 - val_loss: 0.2307\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0610 - val_loss: 0.2307\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0605 - val_loss: 0.2307\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0579 - val_loss: 0.2307\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0607 - val_loss: 0.2307\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0604 - val_loss: 0.2307\n",
            "Epoch 22/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0597 - val_loss: 0.2307\n",
            "Epoch 23/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0590 - val_loss: 0.2307\n",
            "Epoch 24/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0599 - val_loss: 0.2307\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1554 - val_loss: 0.1493\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0412 - val_loss: 0.1221\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0376 - val_loss: 0.1161\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0375 - val_loss: 0.1141\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0377 - val_loss: 0.1133\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0358 - val_loss: 0.1129\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0357 - val_loss: 0.1128\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0367 - val_loss: 0.1127\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0361 - val_loss: 0.1127\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.1127\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0352 - val_loss: 0.1126\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0349 - val_loss: 0.1126\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.1126\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.1126\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0359 - val_loss: 0.1126\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - val_loss: 0.1126\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.1126\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0359 - val_loss: 0.1126\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0357 - val_loss: 0.1126\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0353 - val_loss: 0.1126\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Best hyperparameters (GRU): \n",
            " {'model': [8], 'optimizer': 'Adam', 'batch_size': 32, 'best_avg_rmse': 0.28513213918501157}\n",
            "All average RMSE (GRU): \n",
            " [[0.2856805  0.28552996 0.28513214]\n",
            " [0.28574886 0.28567733 0.28539949]\n",
            " [0.33625577 0.31862983 0.35318334]]\n",
            "{'model': [8], 'optimizer': 'Adam', 'batch_size': 32, 'best_avg_rmse': 0.28513213918501157}\n"
          ]
        }
      ],
      "source": [
        "layers = [8]\n",
        "gru_N8_best_hyper_parameters = GRU_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(gru_N8_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MBqMGdhTto_"
      },
      "outputs": [],
      "source": [
        "#{'model': [8], 'optimizer': 'Adam', 'batch_size': 32, 'best_avg_rmse': 0.28513213918501157}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nkuQiHhdTto_",
        "outputId": "0b37d999-3713-482c-aa7e-6dff6efcfaf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running for optimizer Adam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0175 - val_loss: 0.0796\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0825\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0827\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0828\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0821\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0821\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0821\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.0795\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0816\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0498 - val_loss: 0.0826\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0808\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0810\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0810\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0810\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0810\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0810\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0633 - val_loss: 0.0766\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0817\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0776\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0805\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0807\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0807\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0807\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0807\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0209 - val_loss: 0.0802\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0812\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0816\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0816\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0816\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0321 - val_loss: 0.0834\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0808\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0810\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0810\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0810\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0810\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0195 - val_loss: 0.0813\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0813\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0818\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.0799\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0816\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0225 - val_loss: 0.0813\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0794\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0801\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0813\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0090 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0493 - val_loss: 0.0807\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0821\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0823\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0292 - val_loss: 0.0862\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0789\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0810\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0816\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0814\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1143 - val_loss: 0.0859\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0830\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0814\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0813\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0813\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0813\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0813\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0820 - val_loss: 0.0790\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0807\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0826\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0816\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0962 - val_loss: 0.0847\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0810\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0801\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0807\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0808\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0809\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0809\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0809\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0581 - val_loss: 0.0804\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0807\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0226 - val_loss: 0.0853\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0779\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0841\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0390 - val_loss: 0.0811\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0828\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0831\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0816\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0350 - val_loss: 0.0764\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0090 - val_loss: 0.0807\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0876 - val_loss: 0.0777\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0095 - val_loss: 0.0766\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0775\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0810\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0813\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0320 - val_loss: 0.0862\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0866\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0798\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0771\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0817\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0297 - val_loss: 0.0909\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0860\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0826\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0824\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0837\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0826\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0825\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0820\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0818\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0819\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0819\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0257 - val_loss: 0.0754\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0887\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0818\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0856\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0832\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0971 - val_loss: 0.0818\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0755\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0856\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0827\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0806\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0812\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0887 - val_loss: 0.0803\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0096 - val_loss: 0.0806\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0840\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0826\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0807\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0443 - val_loss: 0.0783\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0092 - val_loss: 0.0869\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0870\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0833\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0796\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.1242 - val_loss: 0.0821\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0829\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0838\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0806\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0802\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0813\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0813\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0816\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0815\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0281 - val_loss: 0.0854\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0742\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0827\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0827\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0805\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0830\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1012 - val_loss: 0.0790\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0803\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0790\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0089 - val_loss: 0.0804\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0799\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0486 - val_loss: 0.0826\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0818\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0840\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0818\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0818\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0157 - val_loss: 0.0793\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0818\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0230 - val_loss: 0.0765\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0093 - val_loss: 0.0809\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0091 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0164 - val_loss: 0.0757\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0808\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0238 - val_loss: 0.0753\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0820\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0820\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0252 - val_loss: 0.0839\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0806\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0812\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175 - val_loss: 0.0854\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0828\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0824\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0168 - val_loss: 0.0823\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0833\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0139 - val_loss: 0.0825\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0810\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0814\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0814\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186 - val_loss: 0.0786\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0785\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0807\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0818\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0722 - val_loss: 0.0793\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0819\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0851\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0825\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0555 - val_loss: 0.0810\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0841\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0806\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0814\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0814\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0409 - val_loss: 0.0840\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0830\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0792\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0818\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0409 - val_loss: 0.0854\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0830\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0827\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0820\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0820\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172 - val_loss: 0.0684\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0827\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0855\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0217 - val_loss: 0.0786\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0795\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0827\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0168 - val_loss: 0.0835\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0859\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0816\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0819\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0819\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0899 - val_loss: 0.0901\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0788\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.1040 - val_loss: 0.0792\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0792\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0800\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0809\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0813\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0085 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.1197 - val_loss: 0.0822\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0826\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0798\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0803\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0812\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0326 - val_loss: 0.0801\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0769\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0869\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0856\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0802\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0834\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0414 - val_loss: 0.0832\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0829\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0808\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0804\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0811\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0818\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0817\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0183 - val_loss: 0.0825\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0822\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0829\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0779\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0806\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0825\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0078 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0801 - val_loss: 0.0788\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0096 - val_loss: 0.0779\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0767\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0804\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0820\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0810\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0243 - val_loss: 0.0876\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0855\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0845\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0752\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0793\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0808\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0816\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0742 - val_loss: 0.0766\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0088 - val_loss: 0.0821\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0795\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0800\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0805\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.1603 - val_loss: 0.0771\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0832\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0808\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0090 - val_loss: 0.0810\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0804\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0585 - val_loss: 0.0855\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0094 - val_loss: 0.0827\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0847\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0797\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0821\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0819\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1142 - val_loss: 0.0825\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0831\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0846\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0816\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0818\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0818\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0819\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0574 - val_loss: 0.1026\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - val_loss: 0.1020\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.1019\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0320 - val_loss: 0.1019\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0319 - val_loss: 0.1019\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0319 - val_loss: 0.1019\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0319 - val_loss: 0.1019\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0328 - val_loss: 0.1019\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.1019\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.1019\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0946\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0945\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0207 - val_loss: 0.0945\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0211 - val_loss: 0.0945\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0945\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - val_loss: 0.0945\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0945\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0945\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0945\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0757 - val_loss: 0.1063\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0331 - val_loss: 0.1054\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.1054\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0316 - val_loss: 0.1054\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.1054\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.1054\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0307 - val_loss: 0.1054\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.1054\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.1054\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.1054\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.1091 - val_loss: 0.1071\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0299 - val_loss: 0.1055\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0295 - val_loss: 0.1054\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0287 - val_loss: 0.1054\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.1054\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.1054\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.1054\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0301 - val_loss: 0.1054\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - val_loss: 0.1054\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0784 - val_loss: 0.0966\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0957\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0957\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0957\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0957\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0957\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0957\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0232 - val_loss: 0.0957\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0957\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0813 - val_loss: 0.1083\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0365 - val_loss: 0.1075\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.1075\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0373 - val_loss: 0.1075\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0376 - val_loss: 0.1075\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0381 - val_loss: 0.1075\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0345 - val_loss: 0.1075\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0356 - val_loss: 0.1075\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0357 - val_loss: 0.1075\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0897 - val_loss: 0.1025\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.1018\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.1018\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.1018\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.1018\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.1018\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.1018\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.1018\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0279 - val_loss: 0.1018\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0916\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202 - val_loss: 0.0913\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0913\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0913\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0913\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0913\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0913\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0913\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0709 - val_loss: 0.1059\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0348 - val_loss: 0.1055\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0330 - val_loss: 0.1055\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0347 - val_loss: 0.1055\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0325 - val_loss: 0.1055\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - val_loss: 0.1055\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0336 - val_loss: 0.1055\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0335 - val_loss: 0.1055\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0332 - val_loss: 0.1055\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0340 - val_loss: 0.1055\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0997 - val_loss: 0.1153\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0419 - val_loss: 0.1143\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0389 - val_loss: 0.1142\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0386 - val_loss: 0.1142\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.1142\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0407 - val_loss: 0.1142\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0399 - val_loss: 0.1142\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.1142\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0396 - val_loss: 0.1142\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0406 - val_loss: 0.1142\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1012 - val_loss: 0.1196\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0492 - val_loss: 0.1176\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0468 - val_loss: 0.1171\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0446 - val_loss: 0.1170\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0458 - val_loss: 0.1170\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0457 - val_loss: 0.1170\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0456 - val_loss: 0.1170\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0470 - val_loss: 0.1170\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0453 - val_loss: 0.1170\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0456 - val_loss: 0.1170\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0457 - val_loss: 0.1170\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0465 - val_loss: 0.1170\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0482 - val_loss: 0.1170\n",
            "Epoch 14/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0459 - val_loss: 0.1170\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0572 - val_loss: 0.1111\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0362 - val_loss: 0.1054\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0332 - val_loss: 0.1049\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0332 - val_loss: 0.1047\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0337 - val_loss: 0.1047\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0340 - val_loss: 0.1047\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0337 - val_loss: 0.1047\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0333 - val_loss: 0.1047\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0342 - val_loss: 0.1047\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0277 - val_loss: 0.0905\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0174 - val_loss: 0.0894\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174 - val_loss: 0.0892\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0892\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0892\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0169 - val_loss: 0.0892\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168 - val_loss: 0.0892\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167 - val_loss: 0.0892\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0463 - val_loss: 0.0981\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0972\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0970\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0969\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0969\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0232 - val_loss: 0.0969\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0969\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0969\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0969\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0969\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0969\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1032 - val_loss: 0.1078\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0303 - val_loss: 0.1039\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.1034\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0293 - val_loss: 0.1033\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.1033\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0307 - val_loss: 0.1033\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.1033\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.1033\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.1033\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.1033\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0299 - val_loss: 0.1033\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.1033\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.1033\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0890 - val_loss: 0.0991\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0970\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0967\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0966\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0248 - val_loss: 0.0966\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - val_loss: 0.0966\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0239 - val_loss: 0.0966\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0244 - val_loss: 0.0966\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0238 - val_loss: 0.0966\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0247 - val_loss: 0.0966\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - val_loss: 0.0966\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0966\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0966\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.1328 - val_loss: 0.1054\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.1019\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.1012\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.1011\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.1011\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.1011\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.1011\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0280 - val_loss: 0.1011\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0282 - val_loss: 0.1011\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0275 - val_loss: 0.1011\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0277 - val_loss: 0.1011\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0285 - val_loss: 0.1011\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.1011\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0687 - val_loss: 0.0985\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0993\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.0993\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0991\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0991\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0991\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0963 - val_loss: 0.1046\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.1016\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0301 - val_loss: 0.1014\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0291 - val_loss: 0.1013\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0284 - val_loss: 0.1013\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0280 - val_loss: 0.1013\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.1013\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.1013\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.1013\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.1013\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.1013\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.1013\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0291 - val_loss: 0.1013\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0326 - val_loss: 0.0943\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0945\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0943\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0943\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0943\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: 0.0943\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1009 - val_loss: 0.1106\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0421 - val_loss: 0.1068\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0397 - val_loss: 0.1062\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0371 - val_loss: 0.1056\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0384 - val_loss: 0.1053\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0359 - val_loss: 0.1053\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0391 - val_loss: 0.1052\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0366 - val_loss: 0.1052\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0358 - val_loss: 0.1052\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0374 - val_loss: 0.1052\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0388 - val_loss: 0.1052\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0363 - val_loss: 0.1052\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.1052\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0378 - val_loss: 0.1052\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0374 - val_loss: 0.1052\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0365 - val_loss: 0.1052\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0369 - val_loss: 0.1052\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0370 - val_loss: 0.1052\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.3101 - val_loss: 0.1785\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0572 - val_loss: 0.1387\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0509 - val_loss: 0.1302\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0505 - val_loss: 0.1274\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0448 - val_loss: 0.1263\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0480 - val_loss: 0.1257\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0464 - val_loss: 0.1255\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0461 - val_loss: 0.1254\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0471 - val_loss: 0.1254\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0460 - val_loss: 0.1254\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0458 - val_loss: 0.1254\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0482 - val_loss: 0.1253\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0482 - val_loss: 0.1253\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0477 - val_loss: 0.1253\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0475 - val_loss: 0.1253\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0466 - val_loss: 0.1253\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0470 - val_loss: 0.1253\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0465 - val_loss: 0.1253\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0482 - val_loss: 0.1253\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0466 - val_loss: 0.1253\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.1246 - val_loss: 0.1064\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0216 - val_loss: 0.0962\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0205 - val_loss: 0.0944\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0204 - val_loss: 0.0938\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0934\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0933\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196 - val_loss: 0.0933\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0195 - val_loss: 0.0933\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0201 - val_loss: 0.0932\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194 - val_loss: 0.0932\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194 - val_loss: 0.0932\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0198 - val_loss: 0.0932\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0195 - val_loss: 0.0932\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190 - val_loss: 0.0932\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0932\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0932\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0932\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191 - val_loss: 0.0932\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0932\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192 - val_loss: 0.0932\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0204 - val_loss: 0.0932\n",
            "Epoch 22/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191 - val_loss: 0.0932\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0373 - val_loss: 0.1019\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0954\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0953\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0951\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0950\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0949\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0948\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0948\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0230 - val_loss: 0.0948\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0227 - val_loss: 0.0948\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0224 - val_loss: 0.0948\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0212 - val_loss: 0.0948\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0223 - val_loss: 0.0948\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0225 - val_loss: 0.0948\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0225 - val_loss: 0.0948\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0228 - val_loss: 0.0948\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0223 - val_loss: 0.0948\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0221 - val_loss: 0.0948\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0230 - val_loss: 0.0948\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0948\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0222 - val_loss: 0.0948\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0819 - val_loss: 0.1093\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0420 - val_loss: 0.1091\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.1082\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0398 - val_loss: 0.1076\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0370 - val_loss: 0.1072\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0392 - val_loss: 0.1071\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0372 - val_loss: 0.1071\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.1071\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0372 - val_loss: 0.1070\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0372 - val_loss: 0.1070\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0385 - val_loss: 0.1070\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0380 - val_loss: 0.1070\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0387 - val_loss: 0.1070\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0382 - val_loss: 0.1070\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0391 - val_loss: 0.1070\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0378 - val_loss: 0.1070\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0373 - val_loss: 0.1070\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0379 - val_loss: 0.1070\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1516 - val_loss: 0.1333\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0569 - val_loss: 0.1231\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0554 - val_loss: 0.1202\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0526 - val_loss: 0.1193\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0516 - val_loss: 0.1188\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0500 - val_loss: 0.1186\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0495 - val_loss: 0.1184\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0517 - val_loss: 0.1184\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0506 - val_loss: 0.1184\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0531 - val_loss: 0.1184\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0514 - val_loss: 0.1184\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0517 - val_loss: 0.1184\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0528 - val_loss: 0.1184\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0527 - val_loss: 0.1184\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0532 - val_loss: 0.1184\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0536 - val_loss: 0.1184\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0531 - val_loss: 0.1184\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0528 - val_loss: 0.1184\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0510 - val_loss: 0.1184\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0541 - val_loss: 0.1184\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0519 - val_loss: 0.1184\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0784 - val_loss: 0.1041\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0300 - val_loss: 0.0992\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0279 - val_loss: 0.0988\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0272 - val_loss: 0.0984\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0264 - val_loss: 0.0983\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0982\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0276 - val_loss: 0.0982\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0982\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0982\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0982\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0982\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0982\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0982\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0982\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0255 - val_loss: 0.0982\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0265 - val_loss: 0.0982\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0261 - val_loss: 0.0982\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0275 - val_loss: 0.0982\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0263 - val_loss: 0.0982\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0982\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1490 - val_loss: 0.1193\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0293 - val_loss: 0.1041\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0285 - val_loss: 0.1018\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0265 - val_loss: 0.1009\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0280 - val_loss: 0.1005\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0259 - val_loss: 0.1004\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0264 - val_loss: 0.1004\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0252 - val_loss: 0.1003\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0273 - val_loss: 0.1003\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0259 - val_loss: 0.1003\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.1003\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.1003\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0256 - val_loss: 0.1003\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.1003\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.1003\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.1003\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.1003\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.1003\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.1003\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0267 - val_loss: 0.1003\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0259 - val_loss: 0.1003\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.2728 - val_loss: 0.1678\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0410 - val_loss: 0.1262\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0343 - val_loss: 0.1175\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0327 - val_loss: 0.1146\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0338 - val_loss: 0.1135\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0335 - val_loss: 0.1130\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0316 - val_loss: 0.1127\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0336 - val_loss: 0.1126\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0315 - val_loss: 0.1126\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0324 - val_loss: 0.1126\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0317 - val_loss: 0.1126\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0323 - val_loss: 0.1125\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0328 - val_loss: 0.1125\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0328 - val_loss: 0.1125\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0319 - val_loss: 0.1125\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.1125\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.1125\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.1125\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0328 - val_loss: 0.1125\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.1125\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.1125\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1579 - val_loss: 0.1325\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0477 - val_loss: 0.1180\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0441 - val_loss: 0.1144\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0431 - val_loss: 0.1134\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0406 - val_loss: 0.1128\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0431 - val_loss: 0.1126\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0432 - val_loss: 0.1125\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0425 - val_loss: 0.1125\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0431 - val_loss: 0.1124\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0423 - val_loss: 0.1124\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0430 - val_loss: 0.1124\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0431 - val_loss: 0.1124\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0418 - val_loss: 0.1124\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0416 - val_loss: 0.1124\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0429 - val_loss: 0.1124\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0418 - val_loss: 0.1124\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0425 - val_loss: 0.1124\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0426 - val_loss: 0.1124\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0414 - val_loss: 0.1124\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0432 - val_loss: 0.1124\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0427 - val_loss: 0.1124\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Best hyperparameters (GRU): \n",
            " {'model': [16], 'optimizer': 'Adam', 'batch_size': 16, 'best_avg_rmse': 0.2853408325543388}\n",
            "All average RMSE (GRU): \n",
            " [[0.28547599 0.28534083 0.28599541]\n",
            " [0.28588171 0.28607666 0.28605546]\n",
            " [0.31972569 0.31658469 0.32636374]]\n",
            "{'model': [16], 'optimizer': 'Adam', 'batch_size': 16, 'best_avg_rmse': 0.2853408325543388}\n"
          ]
        }
      ],
      "source": [
        "layers = [16]\n",
        "gru_N16_best_hyper_parameters = GRU_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(gru_N16_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyeLfKVDTtpA"
      },
      "outputs": [],
      "source": [
        "# {'model': [16], 'optimizer': 'Adam', 'batch_size': 16, 'best_avg_rmse': 0.2853408325543388}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "vYLr4_v_TtpA",
        "outputId": "4e667a52-0e83-4c15-e352-535fe4a152d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running for optimizer Adam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0802\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0806\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0814\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0427 - val_loss: 0.0847\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0805\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0811\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0811\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0554 - val_loss: 0.0840\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0806\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0811\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0811\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0160 - val_loss: 0.0770\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0821\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0338 - val_loss: 0.0816\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0806\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0809\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0810\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0810\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0810\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0810\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0834\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0822\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0814\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0814\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0814\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0814\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0248 - val_loss: 0.0807\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0822\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0222 - val_loss: 0.0788\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0818\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0818\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0813\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0828\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0745\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0813\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0437 - val_loss: 0.0801\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0842\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0828\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0389 - val_loss: 0.0780\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0790\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0816\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0366 - val_loss: 0.0802\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0845\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0816\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0156 - val_loss: 0.0815\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0863\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0803\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0820\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0820\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0391 - val_loss: 0.0804\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0855\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0290 - val_loss: 0.0773\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0820\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0822\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0822\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0313 - val_loss: 0.0845\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0864\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0820\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0819\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0466 - val_loss: 0.0946\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0779\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0812\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0812\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0534 - val_loss: 0.0966\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0089 - val_loss: 0.0850\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0838\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0818\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0568 - val_loss: 0.0775\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0818\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0810\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0469 - val_loss: 0.0882\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0811\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0810\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0815\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0826\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0825\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0696 - val_loss: 0.0766\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0094 - val_loss: 0.0777\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0802\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0812\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0807\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0285 - val_loss: 0.0708\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0810\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0850\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0853\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0832\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0479 - val_loss: 0.0725\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0809\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0833\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0796\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0812\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0434 - val_loss: 0.0720\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0845\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0869\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0828\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0797\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0779 - val_loss: 0.0889\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0772\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0755\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0786\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0832\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0825\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0815\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0461 - val_loss: 0.0863\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0093 - val_loss: 0.0750\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0832\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0831\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0658 - val_loss: 0.0843\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0796\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0848\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0826\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0851\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0812\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0646 - val_loss: 0.0885\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0092 - val_loss: 0.0828\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0865\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0808\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0806\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0816\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0816\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0817\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0522 - val_loss: 0.0889\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0803\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0853\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0789\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0830\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0816\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0818\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0130 - val_loss: 0.0815\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0811\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0814\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0814\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0854\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0827\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0817\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0194 - val_loss: 0.0778\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0834\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0827\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0163 - val_loss: 0.0818\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0824\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0202 - val_loss: 0.0762\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0807\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0810\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0811\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0168 - val_loss: 0.0786\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0812\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0146 - val_loss: 0.0865\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0836\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0822\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0821\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0821\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0802\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0815\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0823\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0823\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0189 - val_loss: 0.0749\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0819\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0470 - val_loss: 0.0781\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0826\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0819\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0165 - val_loss: 0.0873\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0811\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0216 - val_loss: 0.0845\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0854\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0852\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0832\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0828\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0827\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0827\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0379 - val_loss: 0.0716\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0782\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0835\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0320 - val_loss: 0.0824\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0763\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0808\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0822\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0266 - val_loss: 0.0953\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0890\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0229 - val_loss: 0.0803\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0837\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0816\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0510 - val_loss: 0.0767\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0842\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0798\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0816\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0378 - val_loss: 0.0834\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0807\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0797\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0352 - val_loss: 0.0796\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0830\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0794\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0819\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0270 - val_loss: 0.0857\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0793\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0810\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0451 - val_loss: 0.0879\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0723\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0854\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0799\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0799\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - loss: 0.1061 - val_loss: 0.0858\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0769\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0762\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0838\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0807\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0817\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0831\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0890 - val_loss: 0.0769\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0749\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0808\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0802\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0825\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0798\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0374 - val_loss: 0.0684\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0091 - val_loss: 0.0726\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0851\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0806\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0802\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0550 - val_loss: 0.0703\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0089 - val_loss: 0.0855\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0770\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0786\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0798\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0839\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0301 - val_loss: 0.0804\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0883\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0875\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0809\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0078 - val_loss: 0.0816\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0429 - val_loss: 0.0808\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0857\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0850\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0807\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0828\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0823\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0823\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0822\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0377 - val_loss: 0.0698\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0825\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0837\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0806\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.1079 - val_loss: 0.0809\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0087 - val_loss: 0.0782\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0808\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0833\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0799\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0826\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0511 - val_loss: 0.0833\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0812\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0771\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0801\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0787\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0844\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0826\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0416 - val_loss: 0.1030\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0304 - val_loss: 0.1017\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.1017\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0313 - val_loss: 0.1017\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0318 - val_loss: 0.1017\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.1017\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0303 - val_loss: 0.1017\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.1017\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0292 - val_loss: 0.0905\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0159 - val_loss: 0.0898\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0161 - val_loss: 0.0898\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0156 - val_loss: 0.0898\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0158 - val_loss: 0.0898\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0157 - val_loss: 0.0898\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0164 - val_loss: 0.0898\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0163 - val_loss: 0.0898\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165 - val_loss: 0.0898\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0898\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0306 - val_loss: 0.0949\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0207 - val_loss: 0.0941\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0941\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0204 - val_loss: 0.0941\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0941\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0941\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0941\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0941\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0941\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0204 - val_loss: 0.0941\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0595 - val_loss: 0.0955\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0937\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0205 - val_loss: 0.0937\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0937\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0937\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0937\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0206 - val_loss: 0.0937\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0553 - val_loss: 0.0991\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0300 - val_loss: 0.0992\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0993\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0287 - val_loss: 0.0993\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.0993\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0993\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0336 - val_loss: 0.0977\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0966\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0965\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0965\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0212 - val_loss: 0.0965\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0965\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0965\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0965\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.0917\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0917\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0917\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193 - val_loss: 0.0917\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - val_loss: 0.0917\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187 - val_loss: 0.0917\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0600 - val_loss: 0.1039\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0298 - val_loss: 0.1033\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.1033\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.1033\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.1033\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0292 - val_loss: 0.1033\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0280 - val_loss: 0.1033\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0294 - val_loss: 0.1033\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.1033\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0505 - val_loss: 0.1007\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.1006\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0296 - val_loss: 0.1006\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0308 - val_loss: 0.1006\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.1006\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.1006\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0317 - val_loss: 0.1006\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0472 - val_loss: 0.1043\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.1029\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.1029\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0316 - val_loss: 0.1029\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.1029\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0319 - val_loss: 0.1029\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.1029\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0311 - val_loss: 0.1029\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.1029\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0669 - val_loss: 0.0930\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0929\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203 - val_loss: 0.0926\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0925\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0194 - val_loss: 0.0925\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0200 - val_loss: 0.0925\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0201 - val_loss: 0.0925\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0201 - val_loss: 0.0925\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0925\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0925\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0206 - val_loss: 0.0925\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0925\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203 - val_loss: 0.0925\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0600 - val_loss: 0.0949\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0961\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0960\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0961\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0961\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0238 - val_loss: 0.0960\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0900 - val_loss: 0.0968\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0962\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0957\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0957\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0957\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0957\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0957\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - val_loss: 0.0957\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0957\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0957\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0759 - val_loss: 0.0966\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0954\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0950\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0950\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0228 - val_loss: 0.0950\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0230 - val_loss: 0.0950\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0950\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0230 - val_loss: 0.0950\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0491 - val_loss: 0.0979\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0948\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0941\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0204 - val_loss: 0.0940\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0940\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0940\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0940\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0940\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0940\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0940\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0940\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0940\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0740 - val_loss: 0.1114\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.1064\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0330 - val_loss: 0.1055\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0336 - val_loss: 0.1053\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0325 - val_loss: 0.1053\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0325 - val_loss: 0.1053\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.1053\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0320 - val_loss: 0.1053\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0331 - val_loss: 0.1053\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0332 - val_loss: 0.1053\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.1053\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0322 - val_loss: 0.1053\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.1053\n",
            "Epoch 14/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0334 - val_loss: 0.1053\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0853 - val_loss: 0.1028\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0353 - val_loss: 0.1048\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0337 - val_loss: 0.1045\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0336 - val_loss: 0.1044\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0335 - val_loss: 0.1044\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.1044\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0488 - val_loss: 0.0944\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0952\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0953\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0952\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0952\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0952\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0722 - val_loss: 0.0922\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0937\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0207 - val_loss: 0.0933\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0210 - val_loss: 0.0933\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0196 - val_loss: 0.0933\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0209 - val_loss: 0.0933\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0376 - val_loss: 0.0907\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176 - val_loss: 0.0896\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0896\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0896\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0896\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0896\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0896\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166 - val_loss: 0.0896\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0554 - val_loss: 0.0949\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0938\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0941\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0941\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0940\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0218 - val_loss: 0.0940\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0212 - val_loss: 0.0940\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.1324 - val_loss: 0.1191\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0413 - val_loss: 0.1086\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0392 - val_loss: 0.1066\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0360 - val_loss: 0.1059\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0353 - val_loss: 0.1055\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0342 - val_loss: 0.1053\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0330 - val_loss: 0.1052\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.1052\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0335 - val_loss: 0.1052\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.1052\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.1052\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0354 - val_loss: 0.1052\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0358 - val_loss: 0.1052\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0355 - val_loss: 0.1052\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0341 - val_loss: 0.1052\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.1052\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0350 - val_loss: 0.1052\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0364 - val_loss: 0.1052\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0345 - val_loss: 0.1052\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0351 - val_loss: 0.1052\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0348 - val_loss: 0.1052\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.1048 - val_loss: 0.0988\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0270 - val_loss: 0.0970\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0234 - val_loss: 0.0962\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0233 - val_loss: 0.0958\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0231 - val_loss: 0.0956\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0955\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0955\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0955\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0954\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0954\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0954\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0954\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0954\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0954\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0954\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0954\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0954\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0954\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0954\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0954\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0954\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0562 - val_loss: 0.1006\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0301 - val_loss: 0.0990\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0291 - val_loss: 0.0986\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0280 - val_loss: 0.0985\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0259 - val_loss: 0.0984\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0264 - val_loss: 0.0984\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0265 - val_loss: 0.0984\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0267 - val_loss: 0.0984\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0270 - val_loss: 0.0984\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0268 - val_loss: 0.0984\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0984\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0963 - val_loss: 0.1011\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0978\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0966\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0962\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0960\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0228 - val_loss: 0.0959\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0959\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0229 - val_loss: 0.0958\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0958\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0958\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0958\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0958\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0958\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0958\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0958\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0958\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0231 - val_loss: 0.0958\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0222 - val_loss: 0.0958\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0228 - val_loss: 0.0958\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0225 - val_loss: 0.0958\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0394 - val_loss: 0.0918\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0873\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0167 - val_loss: 0.0893\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0162 - val_loss: 0.0892\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0153 - val_loss: 0.0890\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0158 - val_loss: 0.0890\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0160 - val_loss: 0.0890\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0432 - val_loss: 0.0945\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0926\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0929\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0924\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194 - val_loss: 0.0923\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0923\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0922\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0922\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194 - val_loss: 0.0922\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189 - val_loss: 0.0922\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0195 - val_loss: 0.0922\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0198 - val_loss: 0.0922\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0192 - val_loss: 0.0922\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193 - val_loss: 0.0922\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0195 - val_loss: 0.0922\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1239 - val_loss: 0.1161\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0453 - val_loss: 0.1119\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0423 - val_loss: 0.1111\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0422 - val_loss: 0.1105\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0418 - val_loss: 0.1103\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0418 - val_loss: 0.1102\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0411 - val_loss: 0.1101\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0416 - val_loss: 0.1101\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0405 - val_loss: 0.1100\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0403 - val_loss: 0.1100\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0409 - val_loss: 0.1100\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0421 - val_loss: 0.1100\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0402 - val_loss: 0.1100\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0427 - val_loss: 0.1100\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0396 - val_loss: 0.1100\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0408 - val_loss: 0.1100\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0397 - val_loss: 0.1100\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0408 - val_loss: 0.1100\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0398 - val_loss: 0.1100\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0399 - val_loss: 0.1100\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0408 - val_loss: 0.1100\n",
            "Epoch 22/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0382 - val_loss: 0.1100\n",
            "Epoch 23/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0404 - val_loss: 0.1100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0951 - val_loss: 0.1016\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0941\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0937\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0934\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0206 - val_loss: 0.0933\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0207 - val_loss: 0.0933\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0933\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0933\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0933\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0932\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0932\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0205 - val_loss: 0.0932\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: 0.0932\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0932\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0209 - val_loss: 0.0932\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0932\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0932\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0212 - val_loss: 0.0932\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0211 - val_loss: 0.0932\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: 0.0932\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0206 - val_loss: 0.0932\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0869 - val_loss: 0.1089\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0332 - val_loss: 0.1007\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0303 - val_loss: 0.1004\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0296 - val_loss: 0.1002\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0280 - val_loss: 0.0999\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0999\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0998\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0998\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.0998\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0289 - val_loss: 0.0998\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0294 - val_loss: 0.0998\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.0998\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0282 - val_loss: 0.0998\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0291 - val_loss: 0.0998\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: 0.0998\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.0998\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0998\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.0998\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.0998\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0293 - val_loss: 0.0998\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0292 - val_loss: 0.0998\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Best hyperparameters (GRU): \n",
            " {'model': [32], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.2854283780678357}\n",
            "All average RMSE (GRU): \n",
            " [[0.28542838 0.28597115 0.28628414]\n",
            " [0.28606247 0.2865718  0.28668188]\n",
            " [0.31194206 0.30992032 0.31180495]]\n",
            "{'model': [32], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.2854283780678357}\n"
          ]
        }
      ],
      "source": [
        "layers = [32]\n",
        "gru_N32_best_hyper_parameters = GRU_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(gru_N32_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVx0JqGSTtpB"
      },
      "outputs": [],
      "source": [
        "# {'model': [32], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.2854283780678357}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "704epkvXTtpB",
        "outputId": "b6e75646-974b-463c-9bda-5eb144a57625"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running for optimizer Adam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0292 - val_loss: 0.0791\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0803\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0806\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0807\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0807\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0807\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0851\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0832\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0821\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0373 - val_loss: 0.0792\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0802\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0811\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0811\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0876\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0832\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0825\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0825\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0825\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0825\n",
            "Epoch 11/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0791\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0815\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0816\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0816\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0797\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0810\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0822\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0790\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0825\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0824\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0297 - val_loss: 0.0780\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0811\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0813\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.0824\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0806\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0815\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0815\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0812\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0814\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0264 - val_loss: 0.0862\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0837\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0827\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0827\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0825\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0825\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0278 - val_loss: 0.0676\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0833\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0826\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0822\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0346 - val_loss: 0.0848\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0869\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0800\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0820\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0322 - val_loss: 0.0837\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0791\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0838\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0818\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0819\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0232 - val_loss: 0.0781\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0816\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0795\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0312 - val_loss: 0.0780\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0828\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0346 - val_loss: 0.0845\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0759\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0833\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0308 - val_loss: 0.0862\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0854\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0807\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0815\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0816\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0816\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0450 - val_loss: 0.0752\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0810\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0815\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0333 - val_loss: 0.0776\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0887\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0534 - val_loss: 0.0749\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0092 - val_loss: 0.0799\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0787\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0832\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0551 - val_loss: 0.0896\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0885\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0823\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0823\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0338 - val_loss: 0.0799\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0890\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0786\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0851\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0808\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0825\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0474 - val_loss: 0.0869\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0091 - val_loss: 0.0834\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0749\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0800\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0807\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0828\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0478 - val_loss: 0.0831\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0826\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0870\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0822\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0845\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0826\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0826\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0527 - val_loss: 0.0769\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0824\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0087 - val_loss: 0.0799\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0882\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0795\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0396 - val_loss: 0.0764\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0765\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0834\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0803\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0809\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0533 - val_loss: 0.0715\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0830\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0782\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0804\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0859\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0831\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0422 - val_loss: 0.0825\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0862\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0812\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0832\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0828\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0452 - val_loss: 0.0900\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0754\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0785\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0830\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0848\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0836\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0826\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0199 - val_loss: 0.0832\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0810\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0180 - val_loss: 0.0819\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0830\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0826\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0826\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0826\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0826\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0188 - val_loss: 0.0749\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0825\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0830\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0830\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0830\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0882\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0813\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0823\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0178 - val_loss: 0.0819\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0820\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0820\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0167 - val_loss: 0.0797\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0817\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0822\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0220 - val_loss: 0.0869\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0850\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0830\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0829\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0829\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0829\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0829\n",
            "Epoch 11/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0182 - val_loss: 0.0800\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0822\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0205 - val_loss: 0.0927\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0830\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0828\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0828\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0828\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0828\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "Epoch 11/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0257 - val_loss: 0.0792\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0816\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0817\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0817\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0199 - val_loss: 0.0893\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0768\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0080 - val_loss: 0.0839\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0085 - val_loss: 0.0813\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0826\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0227 - val_loss: 0.0726\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0805\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0831\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0084 - val_loss: 0.0827\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0078 - val_loss: 0.0826\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0254 - val_loss: 0.0893\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0801\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0796\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0831\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0831\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0827\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0828\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0212 - val_loss: 0.0853\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0085 - val_loss: 0.0885\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0843\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0809\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0824\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0504 - val_loss: 0.0898\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0086 - val_loss: 0.0882\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0838\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0843\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0829\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0828\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0828\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0828\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - val_loss: 0.0750\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0896\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0830\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186 - val_loss: 0.0877\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0811\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0817\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0822\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0826\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0826\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0291 - val_loss: 0.0913\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0083 - val_loss: 0.0791\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0834\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0836\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0829\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0828\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0202 - val_loss: 0.0814\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0822\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0826\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0843\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0831\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0830\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0217 - val_loss: 0.0764\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0875\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0799\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0828\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0830\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0358 - val_loss: 0.0764\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0959\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0827\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0830\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0837\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0810\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0414 - val_loss: 0.0805\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0798\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0742\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0803\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0855\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0854\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0832\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0345 - val_loss: 0.0960\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0091 - val_loss: 0.0838\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0761\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0838\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0815\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0870\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0825\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0826\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0440 - val_loss: 0.0997\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0087 - val_loss: 0.0733\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0081 - val_loss: 0.0828\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0818\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0847\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0813\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0073 - val_loss: 0.0837\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0414 - val_loss: 0.0862\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0868\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0869\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0819\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0368 - val_loss: 0.0808\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0881\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0803\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0837\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0829\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0078 - val_loss: 0.0845\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0078 - val_loss: 0.0830\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0411 - val_loss: 0.0898\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0781\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0945\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0745\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0836\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0825\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0818\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0831\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0826\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0424 - val_loss: 0.0831\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0862\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0879\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0848\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0842\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0842\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - loss: 0.0283 - val_loss: 0.0805\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0084 - val_loss: 0.0957\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0084 - val_loss: 0.0859\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0839\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0874\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0482 - val_loss: 0.0773\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0814\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0871\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0854\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0818\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0409 - val_loss: 0.0926\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - val_loss: 0.0931\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0216 - val_loss: 0.0931\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0216 - val_loss: 0.0931\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0931\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0931\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0571 - val_loss: 0.0966\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0956\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0242 - val_loss: 0.0957\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0957\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0957\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0957\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0234 - val_loss: 0.0957\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0536 - val_loss: 0.0985\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 0.0262 - val_loss: 0.0983\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0252 - val_loss: 0.0983\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0256 - val_loss: 0.0983\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 7ms/step - loss: 0.0260 - val_loss: 0.0983\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0983\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0983\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0983\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0557 - val_loss: 0.1070\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0326 - val_loss: 0.1059\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0312 - val_loss: 0.1058\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0312 - val_loss: 0.1058\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0325 - val_loss: 0.1058\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0312 - val_loss: 0.1058\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0325 - val_loss: 0.1058\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0319 - val_loss: 0.1058\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0314 - val_loss: 0.1058\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0388 - val_loss: 0.0961\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0225 - val_loss: 0.0949\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0949\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0949\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0219 - val_loss: 0.0949\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0218 - val_loss: 0.0949\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0217 - val_loss: 0.0949\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0676 - val_loss: 0.1031\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.1012\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0284 - val_loss: 0.1012\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0291 - val_loss: 0.1012\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0273 - val_loss: 0.1012\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0281 - val_loss: 0.1012\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.1012\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0282 - val_loss: 0.1012\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.1012\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.1012\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0422 - val_loss: 0.0940\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0198 - val_loss: 0.0942\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0941\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197 - val_loss: 0.0941\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194 - val_loss: 0.0941\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0941\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0543 - val_loss: 0.1033\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0328 - val_loss: 0.1028\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0320 - val_loss: 0.1028\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0326 - val_loss: 0.1028\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.1028\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.1028\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.1028\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0317 - val_loss: 0.1028\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 0.0569 - val_loss: 0.0974\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0290 - val_loss: 0.0987\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0280 - val_loss: 0.0987\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0275 - val_loss: 0.0987\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0272 - val_loss: 0.0987\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0281 - val_loss: 0.0987\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0453 - val_loss: 0.0959\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0232 - val_loss: 0.0958\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0958\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0958\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0958\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0958\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0239 - val_loss: 0.0958\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0958\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0958\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0958\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0649 - val_loss: 0.0954\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0956\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - val_loss: 0.0959\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0957\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0235 - val_loss: 0.0957\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0237 - val_loss: 0.0957\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0708 - val_loss: 0.0990\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0296 - val_loss: 0.0997\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.0996\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0996\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0273 - val_loss: 0.0996\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - val_loss: 0.0996\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0684 - val_loss: 0.0956\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0935\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0200 - val_loss: 0.0931\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203 - val_loss: 0.0931\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0931\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0931\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0201 - val_loss: 0.0931\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0931\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0203 - val_loss: 0.0931\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202 - val_loss: 0.0931\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203 - val_loss: 0.0931\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0931\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0832 - val_loss: 0.1028\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0293 - val_loss: 0.1002\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0279 - val_loss: 0.0997\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.0997\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0282 - val_loss: 0.0997\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0997\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0997\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: 0.0997\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0276 - val_loss: 0.0997\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0286 - val_loss: 0.0997\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0285 - val_loss: 0.0997\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0284 - val_loss: 0.0997\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0572 - val_loss: 0.0905\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0929\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0926\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0927\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0927\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0927\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0483 - val_loss: 0.0916\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0220 - val_loss: 0.0947\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0945\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0944\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0944\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: 0.0944\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0621 - val_loss: 0.0944\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186 - val_loss: 0.0919\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183 - val_loss: 0.0916\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181 - val_loss: 0.0916\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0916\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0916\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181 - val_loss: 0.0916\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0916\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0916\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0916\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0916\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180 - val_loss: 0.0916\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0916\n",
            "Epoch 14/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179 - val_loss: 0.0916\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0696 - val_loss: 0.0938\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0952\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0240 - val_loss: 0.0952\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0239 - val_loss: 0.0952\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0241 - val_loss: 0.0951\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0240 - val_loss: 0.0951\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0455 - val_loss: 0.1006\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.0985\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0978\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0978\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0978\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0978\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0978\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - val_loss: 0.0978\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0978\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0978\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0978\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0978\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0663 - val_loss: 0.0999\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0965\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0962\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0232 - val_loss: 0.0962\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0962\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0962\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0962\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0962\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1083 - val_loss: 0.1064\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0310 - val_loss: 0.0997\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0278 - val_loss: 0.0989\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0980\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0976\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0975\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0249 - val_loss: 0.0974\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0974\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0974\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0974\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0974\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0974\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0974\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0247 - val_loss: 0.0974\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0254 - val_loss: 0.0974\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0255 - val_loss: 0.0974\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0245 - val_loss: 0.0974\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0254 - val_loss: 0.0974\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0245 - val_loss: 0.0974\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0256 - val_loss: 0.0974\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0257 - val_loss: 0.0974\n",
            "Epoch 22/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0974\n",
            "Epoch 23/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0974\n",
            "Epoch 24/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0974\n",
            "Epoch 25/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0974\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1121 - val_loss: 0.0990\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.1035\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0285 - val_loss: 0.1004\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0994\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0991\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0273 - val_loss: 0.0990\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1728 - val_loss: 0.1090\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.1015\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0297 - val_loss: 0.0999\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0269 - val_loss: 0.0992\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0988\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0261 - val_loss: 0.0987\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0263 - val_loss: 0.0987\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0269 - val_loss: 0.0987\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0266 - val_loss: 0.0987\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0274 - val_loss: 0.0987\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0267 - val_loss: 0.0987\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0261 - val_loss: 0.0987\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0987\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0987\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0987\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0987\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0987\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0987\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0987\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0987\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.1063 - val_loss: 0.0963\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0939\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0222 - val_loss: 0.0940\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0934\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0193 - val_loss: 0.0931\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0930\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0929\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0197 - val_loss: 0.0929\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0199 - val_loss: 0.0929\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196 - val_loss: 0.0929\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0200 - val_loss: 0.0929\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0193 - val_loss: 0.0929\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0202 - val_loss: 0.0929\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197 - val_loss: 0.0929\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0199 - val_loss: 0.0929\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0201 - val_loss: 0.0929\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0204 - val_loss: 0.0929\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0193 - val_loss: 0.0929\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0190 - val_loss: 0.0929\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192 - val_loss: 0.0929\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0569 - val_loss: 0.1045\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0298 - val_loss: 0.0997\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0983\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0974\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0970\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0968\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0968\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - val_loss: 0.0967\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0967\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0967\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0967\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0967\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0967\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0967\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0967\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0967\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0967\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0967\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0967\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0736 - val_loss: 0.1173\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0396 - val_loss: 0.1058\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0329 - val_loss: 0.1046\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0330 - val_loss: 0.1034\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0328 - val_loss: 0.1030\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0326 - val_loss: 0.1028\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.1028\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0323 - val_loss: 0.1027\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0324 - val_loss: 0.1027\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.1027\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0314 - val_loss: 0.1027\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.1027\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0329 - val_loss: 0.1027\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.1027\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0306 - val_loss: 0.1027\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0341 - val_loss: 0.1027\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0325 - val_loss: 0.1027\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0321 - val_loss: 0.1027\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0315 - val_loss: 0.1027\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0328 - val_loss: 0.1027\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0327 - val_loss: 0.1027\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0775 - val_loss: 0.1061\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.1009\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0282 - val_loss: 0.0987\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0269 - val_loss: 0.0985\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0269 - val_loss: 0.0982\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0267 - val_loss: 0.0981\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0265 - val_loss: 0.0981\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0267 - val_loss: 0.0981\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0251 - val_loss: 0.0981\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0265 - val_loss: 0.0981\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0273 - val_loss: 0.0981\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.0981\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0981\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0981\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0283 - val_loss: 0.0981\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0981\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0981\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0981\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0981\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0981\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0981\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0620 - val_loss: 0.1036\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0300 - val_loss: 0.0973\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0272 - val_loss: 0.0979\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0973\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0972\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0971\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0238 - val_loss: 0.0971\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0971\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0239 - val_loss: 0.0971\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0971\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0235 - val_loss: 0.0970\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0248 - val_loss: 0.0970\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0250 - val_loss: 0.0970\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0244 - val_loss: 0.0970\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0263 - val_loss: 0.0970\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0250 - val_loss: 0.0970\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0970\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0970\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0970\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0816 - val_loss: 0.1028\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0305 - val_loss: 0.1002\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0280 - val_loss: 0.0980\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0970\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0968\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0965\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0241 - val_loss: 0.0965\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0964\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0964\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0964\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0242 - val_loss: 0.0964\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0964\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0964\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0964\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0964\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0964\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0964\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0235 - val_loss: 0.0964\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0235 - val_loss: 0.0964\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0544 - val_loss: 0.0940\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0932\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195 - val_loss: 0.0920\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0917\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191 - val_loss: 0.0915\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182 - val_loss: 0.0914\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0914\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0914\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0183 - val_loss: 0.0914\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0186 - val_loss: 0.0914\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177 - val_loss: 0.0914\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0914\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0182 - val_loss: 0.0914\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0914\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189 - val_loss: 0.0914\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178 - val_loss: 0.0914\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0170 - val_loss: 0.0914\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0914\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0184 - val_loss: 0.0914\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0191 - val_loss: 0.0914\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Best hyperparameters (GRU): \n",
            " {'model': [64], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.28578444424523347}\n",
            "All average RMSE (GRU): \n",
            " [[0.28578444 0.28629348 0.28711949]\n",
            " [0.28696621 0.2876227  0.28731841]\n",
            " [0.31303758 0.30913413 0.31146141]]\n",
            "{'model': [64], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.28578444424523347}\n"
          ]
        }
      ],
      "source": [
        "layers = [64]\n",
        "gru_N64_best_hyper_parameters = GRU_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(gru_N64_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSfmE879TtpC"
      },
      "outputs": [],
      "source": [
        "#{'model': [64], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.28578444424523347}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Sq7LACAcTtpC",
        "outputId": "4dcd95f8-414c-4c1a-f9c5-99ba53f485e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running for optimizer Adam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0262 - val_loss: 0.0874\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0817\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0832\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0808\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0814\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0814\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0814\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0762\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0811\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0820\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0887\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0831\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0822\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0823\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0823\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0769\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0836\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0825\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0900\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0831\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0830\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0830\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0830\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0830\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0185 - val_loss: 0.0851\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0826\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0830\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0829\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0829\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0201 - val_loss: 0.0782\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0826\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0823\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0838\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0824\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0824\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - loss: 0.0200 - val_loss: 0.0862\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0823\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0823\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0823\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0823\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0823\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0257 - val_loss: 0.0826\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0086 - val_loss: 0.0865\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0853\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0828\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0825\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0825\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0825\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0245 - val_loss: 0.0873\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0728\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0814\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0830\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0826\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0827\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0279 - val_loss: 0.0823\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0831\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0826\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0833\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0826\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0891\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0797\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0848\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0840\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0832\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0075 - val_loss: 0.0832\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0831\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0307 - val_loss: 0.0752\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0824\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0863\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0835\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0829\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0832\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0914\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0882\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0829\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0830\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0830\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0830\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0917\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0089 - val_loss: 0.0822\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0830\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0829\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0290 - val_loss: 0.0941\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0786\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0837\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0822\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0827\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0827\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0281 - val_loss: 0.0837\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0085 - val_loss: 0.0820\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0861\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0827\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0287 - val_loss: 0.0836\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0086 - val_loss: 0.0835\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0076 - val_loss: 0.0855\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0822\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0822\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0488 - val_loss: 0.0885\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0796\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0776\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0805\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0821\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0835\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0830\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0360 - val_loss: 0.0868\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0761\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0914\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0840\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0837\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0862\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0831\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0411 - val_loss: 0.0751\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0091 - val_loss: 0.0764\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0088 - val_loss: 0.0848\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0846\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0779\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0867\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0467 - val_loss: 0.0822\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0090 - val_loss: 0.0821\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0794\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0886\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0801\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0832\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0826\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0462 - val_loss: 0.0805\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0087 - val_loss: 0.0884\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0816\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0814\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0839\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0847\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0387 - val_loss: 0.0967\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0889\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0829\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0082 - val_loss: 0.0830\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0835\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0832\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0829\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0075 - val_loss: 0.0830\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0830\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0443 - val_loss: 0.0958\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0093 - val_loss: 0.0838\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0811\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0798\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0806\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0827\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0833\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0078 - val_loss: 0.0834\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0370 - val_loss: 0.0785\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0084 - val_loss: 0.0891\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0079 - val_loss: 0.0831\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0080 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0077 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0375 - val_loss: 0.0763\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0787\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0792\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0845\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0083 - val_loss: 0.0831\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0863\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0401 - val_loss: 0.0744\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0857\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0849\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0081 - val_loss: 0.0805\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0850\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0831\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0209 - val_loss: 0.0752\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0827\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0824\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0078 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: 0.0075 - val_loss: 0.0825\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0196 - val_loss: 0.0831\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0839\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0827\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0827\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0081 - val_loss: 0.0827\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0827\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0203 - val_loss: 0.0748\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0818\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0078 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0078 - val_loss: 0.0822\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0230 - val_loss: 0.0819\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0821\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0827\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0257 - val_loss: 0.0863\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0082 - val_loss: 0.0848\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0075 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0825\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0825\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0825\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0825\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0194 - val_loss: 0.0813\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0851\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0823\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0824\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0181 - val_loss: 0.0858\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0829\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0831\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0831\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0831\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0831\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0831\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0216 - val_loss: 0.0900\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0832\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0825\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0824\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0824\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0824\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0824\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - loss: 0.0184 - val_loss: 0.0825\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0824\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0821\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0822\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0822\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0074 - val_loss: 0.0822\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0822\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0822\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Nadam, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0206 - val_loss: 0.0956\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0827\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0830\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0830\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0830\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0830\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0830\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0263 - val_loss: 0.0784\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0843\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0834\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0830\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0831\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0080 - val_loss: 0.0834\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0316 - val_loss: 0.0770\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0797\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0839\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0831\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0297 - val_loss: 0.0796\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0799\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0800\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0081 - val_loss: 0.0838\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0831\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0830\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0271 - val_loss: 0.0838\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0895\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0075 - val_loss: 0.0837\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0829\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0829\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0829\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0317 - val_loss: 0.0855\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0765\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0810\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0844\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0830\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0832\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0832\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0269 - val_loss: 0.0882\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0776\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0861\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0819\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0075 - val_loss: 0.0828\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0348 - val_loss: 0.0807\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0833\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0795\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0826\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0827\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0076 - val_loss: 0.0828\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0074 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0226 - val_loss: 0.0793\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0084 - val_loss: 0.0797\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0074 - val_loss: 0.0840\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0823\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0283 - val_loss: 0.0774\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0762\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0083 - val_loss: 0.0816\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0832\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0830\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0076 - val_loss: 0.0828\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0081 - val_loss: 0.0827\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0281 - val_loss: 0.0885\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0811\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0841\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0834\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0829\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0828\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0418 - val_loss: 0.0657\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0087 - val_loss: 0.0789\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0826\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0848\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0833\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0405 - val_loss: 0.0679\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0088 - val_loss: 0.0872\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0843\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0821\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0826\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0513 - val_loss: 0.0879\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0722\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0839\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0848\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0773\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0077 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0079 - val_loss: 0.0838\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0395 - val_loss: 0.0909\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0815\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0795\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0857\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0820\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0824\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0831\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0402 - val_loss: 0.0838\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0082 - val_loss: 0.0973\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0836\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0873\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0805\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0821\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0824\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0821\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0829\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0829\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0391 - val_loss: 0.0879\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0085 - val_loss: 0.0809\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0086 - val_loss: 0.0837\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0874\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0832\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0865\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0848\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0419 - val_loss: 0.0798\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0818\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0880\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0078 - val_loss: 0.0822\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0079 - val_loss: 0.0828\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0820\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0315 - val_loss: 0.0845\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0088 - val_loss: 0.0772\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0910\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0080 - val_loss: 0.0831\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0084 - val_loss: 0.0795\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0077 - val_loss: 0.0831\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0079 - val_loss: 0.0853\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0406 - val_loss: 0.0847\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0087 - val_loss: 0.0850\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0813\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0878\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0843\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0083 - val_loss: 0.0855\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0832\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0817\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Nadam, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0373 - val_loss: 0.0822\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0081 - val_loss: 0.0890\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0080 - val_loss: 0.0865\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0830\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0079 - val_loss: 0.0813\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0840\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0076 - val_loss: 0.0838\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0077 - val_loss: 0.0833\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0080 - val_loss: 0.0831\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0082 - val_loss: 0.0828\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0543 - val_loss: 0.1004\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0991\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0991\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0272 - val_loss: 0.0991\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0275 - val_loss: 0.0991\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0265 - val_loss: 0.0991\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0991\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0991\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0991\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0991\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0536 - val_loss: 0.1010\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0281 - val_loss: 0.0999\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0998\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0998\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0998\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0998\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0998\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0998\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0998\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0504 - val_loss: 0.0976\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0970\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0970\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0970\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0970\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0970\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0970\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0970\n",
            "Epoch 9/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0252 - val_loss: 0.0970\n",
            "Epoch 10/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0970\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0444 - val_loss: 0.0965\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0249 - val_loss: 0.0973\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0973\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0973\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0973\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0973\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0376 - val_loss: 0.0893\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0177 - val_loss: 0.0885\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171 - val_loss: 0.0885\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185 - val_loss: 0.0885\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168 - val_loss: 0.0885\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173 - val_loss: 0.0885\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169 - val_loss: 0.0885\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0487 - val_loss: 0.0963\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0953\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0236 - val_loss: 0.0952\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0224 - val_loss: 0.0952\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0233 - val_loss: 0.0952\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0952\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0952\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0952\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0450 - val_loss: 0.0945\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0957\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0957\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0957\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0957\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0957\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0383 - val_loss: 0.0953\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0209 - val_loss: 0.0948\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0947\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0205 - val_loss: 0.0947\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: 0.0947\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0947\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0207 - val_loss: 0.0947\n",
            "Epoch 8/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0206 - val_loss: 0.0947\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0458 - val_loss: 0.0986\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0975\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0975\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0975\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0975\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0975\n",
            "Epoch 7/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0975\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 8, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0436 - val_loss: 0.0963\n",
            "Epoch 2/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0266 - val_loss: 0.0975\n",
            "Epoch 3/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0975\n",
            "Epoch 4/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0975\n",
            "Epoch 5/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0975\n",
            "Epoch 6/30\n",
            "\u001b[1m302/302\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0975\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0509 - val_loss: 0.0973\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0966\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0961\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0236 - val_loss: 0.0960\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0237 - val_loss: 0.0959\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0231 - val_loss: 0.0959\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0237 - val_loss: 0.0959\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0229 - val_loss: 0.0959\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0224 - val_loss: 0.0959\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0244 - val_loss: 0.0959\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0584 - val_loss: 0.0977\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0977\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0972\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0971\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0970\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0970\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0255 - val_loss: 0.0970\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0243 - val_loss: 0.0970\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0257 - val_loss: 0.0970\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0248 - val_loss: 0.0970\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0254 - val_loss: 0.0970\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.0970\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0970\n",
            "Epoch 14/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0970\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0513 - val_loss: 0.1005\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0289 - val_loss: 0.0983\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0250 - val_loss: 0.0978\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0978\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0978\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0262 - val_loss: 0.0978\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0252 - val_loss: 0.0978\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0978\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0258 - val_loss: 0.0978\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0251 - val_loss: 0.0978\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0978\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0253 - val_loss: 0.0978\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0446 - val_loss: 0.1012\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0256 - val_loss: 0.0972\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0960\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0958\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0957\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0227 - val_loss: 0.0957\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0229 - val_loss: 0.0957\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0218 - val_loss: 0.0957\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0228 - val_loss: 0.0957\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0215 - val_loss: 0.0957\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0228 - val_loss: 0.0957\n",
            "Epoch 12/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0224 - val_loss: 0.0957\n",
            "Epoch 13/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0957\n",
            "Epoch 14/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0957\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0641 - val_loss: 0.1015\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0968\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0970\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0970\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0970\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0970\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0970\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0554 - val_loss: 0.0956\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0277 - val_loss: 0.0981\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0260 - val_loss: 0.0975\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0261 - val_loss: 0.0976\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0267 - val_loss: 0.0976\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0246 - val_loss: 0.0976\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0573 - val_loss: 0.0974\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0949\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0948\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0223 - val_loss: 0.0948\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0948\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0948\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0948\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0218 - val_loss: 0.0948\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0801 - val_loss: 0.1002\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0283 - val_loss: 0.0983\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0270 - val_loss: 0.0982\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0261 - val_loss: 0.0981\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0263 - val_loss: 0.0981\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0981\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0269 - val_loss: 0.0981\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0264 - val_loss: 0.0981\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0268 - val_loss: 0.0981\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0270 - val_loss: 0.0981\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0266 - val_loss: 0.0981\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0562 - val_loss: 0.0996\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0279 - val_loss: 0.0975\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0978\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0976\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0976\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0976\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0253 - val_loss: 0.0976\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 16, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0697 - val_loss: 0.1022\n",
            "Epoch 2/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0273 - val_loss: 0.0970\n",
            "Epoch 3/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0967\n",
            "Epoch 4/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0967\n",
            "Epoch 5/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0966\n",
            "Epoch 6/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0966\n",
            "Epoch 7/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0966\n",
            "Epoch 8/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0966\n",
            "Epoch 9/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0966\n",
            "Epoch 10/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0966\n",
            "Epoch 11/30\n",
            "\u001b[1m151/151\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0966\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 1\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0836 - val_loss: 0.0992\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0282 - val_loss: 0.0991\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0952\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0951\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0950\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0221 - val_loss: 0.0950\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0226 - val_loss: 0.0949\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0233 - val_loss: 0.0949\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0214 - val_loss: 0.0949\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0223 - val_loss: 0.0949\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0228 - val_loss: 0.0949\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0217 - val_loss: 0.0949\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0222 - val_loss: 0.0949\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0232 - val_loss: 0.0949\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0949\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0224 - val_loss: 0.0949\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0949\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0949\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0949\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0949\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 2\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0777 - val_loss: 0.1042\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0282 - val_loss: 0.1002\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0259 - val_loss: 0.0970\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0966\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0964\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0962\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0229 - val_loss: 0.0962\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0961\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0961\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0961\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0237 - val_loss: 0.0961\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0231 - val_loss: 0.0961\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0237 - val_loss: 0.0961\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0231 - val_loss: 0.0961\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0227 - val_loss: 0.0961\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0235 - val_loss: 0.0961\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0234 - val_loss: 0.0961\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0237 - val_loss: 0.0961\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0230 - val_loss: 0.0961\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0219 - val_loss: 0.0961\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0961\n",
            "Epoch 22/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0961\n",
            "Epoch 23/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0237 - val_loss: 0.0961\n",
            "Epoch 24/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0961\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 3\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0841 - val_loss: 0.0983\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - val_loss: 0.0971\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0273 - val_loss: 0.0986\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0261 - val_loss: 0.0983\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0267 - val_loss: 0.0982\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0258 - val_loss: 0.0980\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0256 - val_loss: 0.0980\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 4\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0892 - val_loss: 0.1013\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0262 - val_loss: 0.0963\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0233 - val_loss: 0.0960\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0222 - val_loss: 0.0949\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0220 - val_loss: 0.0944\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0214 - val_loss: 0.0943\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0213 - val_loss: 0.0943\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0225 - val_loss: 0.0943\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0213 - val_loss: 0.0943\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0212 - val_loss: 0.0943\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0211 - val_loss: 0.0943\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0218 - val_loss: 0.0943\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0217 - val_loss: 0.0943\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0228 - val_loss: 0.0943\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0943\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0214 - val_loss: 0.0943\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0226 - val_loss: 0.0943\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0943\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0213 - val_loss: 0.0943\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0219 - val_loss: 0.0943\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216 - val_loss: 0.0943\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 5\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0910 - val_loss: 0.0973\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0950\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0215 - val_loss: 0.0946\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0207 - val_loss: 0.0935\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0210 - val_loss: 0.0931\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0201 - val_loss: 0.0930\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0212 - val_loss: 0.0929\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202 - val_loss: 0.0929\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0198 - val_loss: 0.0929\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0929\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0202 - val_loss: 0.0929\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0203 - val_loss: 0.0929\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196 - val_loss: 0.0929\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199 - val_loss: 0.0929\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202 - val_loss: 0.0929\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0203 - val_loss: 0.0929\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0195 - val_loss: 0.0929\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198 - val_loss: 0.0929\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188 - val_loss: 0.0929\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0208 - val_loss: 0.0929\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200 - val_loss: 0.0929\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 6\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0938 - val_loss: 0.0993\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0288 - val_loss: 0.0988\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0255 - val_loss: 0.0958\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0956\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0953\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0229 - val_loss: 0.0952\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0951\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0221 - val_loss: 0.0951\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0232 - val_loss: 0.0951\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0227 - val_loss: 0.0951\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0951\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0951\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0226 - val_loss: 0.0951\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0224 - val_loss: 0.0951\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0227 - val_loss: 0.0951\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 7\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0893 - val_loss: 0.1033\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0293 - val_loss: 0.1014\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0268 - val_loss: 0.0990\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0267 - val_loss: 0.0976\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0971\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0970\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0257 - val_loss: 0.0969\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0969\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0248 - val_loss: 0.0968\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0968\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0968\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0243 - val_loss: 0.0968\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0968\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0968\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0968\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - val_loss: 0.0968\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0968\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0251 - val_loss: 0.0968\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0239 - val_loss: 0.0968\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0242 - val_loss: 0.0968\n",
            "Epoch 21/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0236 - val_loss: 0.0968\n",
            "Epoch 22/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0968\n",
            "Epoch 23/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0248 - val_loss: 0.0968\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 8\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0741 - val_loss: 0.1027\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0289 - val_loss: 0.0972\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0260 - val_loss: 0.0972\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0965\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0246 - val_loss: 0.0962\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0235 - val_loss: 0.0961\n",
            "Epoch 7/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0960\n",
            "Epoch 8/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0230 - val_loss: 0.0960\n",
            "Epoch 9/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0233 - val_loss: 0.0960\n",
            "Epoch 10/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0247 - val_loss: 0.0960\n",
            "Epoch 11/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0234 - val_loss: 0.0960\n",
            "Epoch 12/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0249 - val_loss: 0.0960\n",
            "Epoch 13/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0243 - val_loss: 0.0960\n",
            "Epoch 14/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0240 - val_loss: 0.0960\n",
            "Epoch 15/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0245 - val_loss: 0.0960\n",
            "Epoch 16/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0232 - val_loss: 0.0960\n",
            "Epoch 17/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0238 - val_loss: 0.0960\n",
            "Epoch 18/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0238 - val_loss: 0.0960\n",
            "Epoch 19/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0231 - val_loss: 0.0960\n",
            "Epoch 20/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0240 - val_loss: 0.0960\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 9\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.1311 - val_loss: 0.0968\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0302 - val_loss: 0.0998\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0271 - val_loss: 0.0982\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0282 - val_loss: 0.0982\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0264 - val_loss: 0.0981\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0270 - val_loss: 0.0980\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
            "Running for optimizer Adagrad, batch size 32, replicate 10\n",
            "Epoch 1/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0801 - val_loss: 0.0948\n",
            "Epoch 2/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0305 - val_loss: 0.0990\n",
            "Epoch 3/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0260 - val_loss: 0.0969\n",
            "Epoch 4/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0254 - val_loss: 0.0967\n",
            "Epoch 5/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0251 - val_loss: 0.0965\n",
            "Epoch 6/30\n",
            "\u001b[1m76/76\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0241 - val_loss: 0.0964\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Best hyperparameters (GRU): \n",
            " {'model': [128], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.28696019789094285}\n",
            "All average RMSE (GRU): \n",
            " [[0.2869602  0.28772179 0.28931319]\n",
            " [0.28734945 0.2880009  0.2883356 ]\n",
            " [0.310179   0.31114283 0.30957788]]\n",
            "{'model': [128], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.28696019789094285}\n"
          ]
        }
      ],
      "source": [
        "layers = [128]\n",
        "gru_N128_best_hyper_parameters = GRU_Hyper_Parameter_Tuning(\n",
        "                                  layers,\n",
        "                                  X_train,\n",
        "                                  y_train,\n",
        "                                  time_step,\n",
        "                                  val_split,\n",
        "                                  optimizers_names,\n",
        "                                  initial_learning_rate=initial_learning_rate,\n",
        "                                  batch_sizes=batch_sizes,\n",
        "                                  epochs=epochs,\n",
        "                                  num_replicates=num_replicates\n",
        "                              )\n",
        "\n",
        "print(gru_N128_best_hyper_parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Cx-xS3jTtpD"
      },
      "outputs": [],
      "source": [
        "#{'model': [128], 'optimizer': 'Adam', 'batch_size': 8, 'best_avg_rmse': 0.28696019789094285}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2cjP61JTtpE"
      },
      "outputs": [],
      "source": [
        "gru_best_hyper_parameters =  [ ['Adam', 32],\n",
        "                                ['Adam', 16],\n",
        "                                ['Adam', 8],\n",
        "                                ['Adam', 8],\n",
        "                                ['Adam', 8]\n",
        "                                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kt2IdUF2KaW9"
      },
      "outputs": [],
      "source": [
        "def GRU_Model_Implementation(layers,\n",
        "                             hyper_parameters,\n",
        "                             data,\n",
        "                             time_step = 5,\n",
        "                             test_split = 0.2,\n",
        "                             initial_learning_rate=0.01,\n",
        "                             epochs = 5,\n",
        "                             num_replicates = 2):\n",
        "    # data transformation\n",
        "    print(\"Progress: Performing data preparation steps.......\\n\")\n",
        "\n",
        "    # creating training and test data\n",
        "    X= data\n",
        "    y = data['Close']\n",
        "\n",
        "    pca = PCA(n_components=0.99)\n",
        "    X_pca = pca.fit_transform(X)\n",
        "\n",
        "    X_train, X_test = data_split(X_pca, split=0.2)\n",
        "    y_train0, y_test0 = data_split(y, split=0.2)\n",
        "\n",
        "    y_train_original = np.array(y_train0).reshape(-1, 1)\n",
        "    y_test_original = np.array(y_test0).reshape(-1, 1)\n",
        "\n",
        "    y_train_min, y_train_max = y_train_original.min(), y_train_original.max()\n",
        "    y_test_min, y_test_max = y_test_original.min(), y_test_original.max()\n",
        "\n",
        "    X_train_scaled = min_max_transform(X_train)\n",
        "    X_test_scaled = min_max_transform(X_test)\n",
        "\n",
        "    y_train_scaled = min_max_transform(y_train_original)\n",
        "    y_test_scaled = min_max_transform(y_test_original)\n",
        "\n",
        "    X_train, y_train = DatasetCreation(X_train_scaled, y_train_scaled, time_step = 5)\n",
        "    X_test, y_test = DatasetCreation(X_test_scaled, y_test_scaled, time_step = 5)\n",
        "\n",
        "    y_train_original = min_max_inverse_transform(y_train, y_train_min, y_train_max)\n",
        "    y_test_original = min_max_inverse_transform(y_test, y_test_min, y_test_max)\n",
        "\n",
        "\n",
        "    # train_data, test_data = data_split(data, test_split)\n",
        "\n",
        "    num_features = X_pca.shape[1]\n",
        "\n",
        "    # min_train, max_train  = train_data[target_var].min(), train_data[target_var].max()\n",
        "    # min_test, max_test   =    test_data[target_var].min(), test_data[target_var].max()\n",
        "\n",
        "\n",
        "    # train_data_scaled  =  min_max_transform(train_data)\n",
        "    # test_data_scaled   = min_max_transform(test_data)\n",
        "\n",
        "\n",
        "    # X_train, y_train  =   DatasetCreation(train_data_scaled, time_step)\n",
        "    # X_test, y_test    =   DatasetCreation(test_data_scaled, time_step)\n",
        "\n",
        "    # y_train_original  =  min_max_inverse_transform(y_train, min_train, max_train) #in original scale\n",
        "    # y_test_original  =  min_max_inverse_transform(y_test, min_test, max_test) #in original scale\n",
        "\n",
        "\n",
        "    # arrays for collecting test scores\n",
        "    rmse_array = np.zeros(num_replicates)\n",
        "    mape_array = np.zeros(num_replicates)\n",
        "    R_array    = np.zeros(num_replicates)\n",
        "    elapsed_time_array = np.zeros(num_replicates)\n",
        "\n",
        "    models_history = []\n",
        "    train_predictions = []\n",
        "    test_predictions = []\n",
        "\n",
        "    for i in range(num_replicates):\n",
        "\n",
        "      print(f'Program is running for {i} replicate\\n')\n",
        "\n",
        "      model =  Build_GRU_Model(layers,\n",
        "                        time_step,\n",
        "                        num_features,\n",
        "                        optimizer = hyper_parameters[0],\n",
        "                        initial_learning_rate = initial_learning_rate)\n",
        "\n",
        "      callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience= 5)\n",
        "      # This callback will stop the training when there is no improvement in\n",
        "      # the loss for three consecutive epochs\n",
        "      start = time.time()\n",
        "      history = model.fit(X_train, y_train,\n",
        "                          batch_size = hyper_parameters[1],\n",
        "                          epochs= epochs, callbacks=[callback], verbose = 1)\n",
        "      end = time.time()\n",
        "      elapsed_time = end - start\n",
        "\n",
        "      models_history.append(history)\n",
        "\n",
        "\n",
        "      # Getting train and test prediction in original scales\n",
        "      train_pred   =  min_max_inverse_transform(model.predict(X_train).ravel(),\n",
        "                                                y_train_min, y_train_max).reshape(-1,1)\n",
        "      test_pred    =  min_max_inverse_transform(model.predict(X_test).ravel(),\n",
        "                                                y_test_min, y_test_max).reshape(-1,1)\n",
        "\n",
        "\n",
        "      train_predictions.append(train_pred)\n",
        "      test_predictions.append(test_pred)\n",
        "\n",
        "      # Calculating performance scores\n",
        "\n",
        "      scores =   calculate_scores(y_test_original,test_pred)\n",
        "\n",
        "      rmse_array[i] =  scores['rmse']\n",
        "      mape_array[i] =  scores['mape']\n",
        "      R_array[i] = scores['R']\n",
        "      elapsed_time_array[i] = elapsed_time\n",
        "\n",
        "    min_index = rmse_array.argmin()\n",
        "    best_rmse = rmse_array[min_index]\n",
        "    mape_with_best_rmse = mape_array[min_index]\n",
        "    R_with_best_rmse =  R_array[min_index]\n",
        "    elapsed_time_with_best_rmse = elapsed_time_array[min_index]\n",
        "\n",
        "    train_predictions_with_best_rmse = train_predictions[min_index]\n",
        "    test_predictions_with_best_rmse = test_predictions[min_index]\n",
        "\n",
        "    loss_with_best_rmse = models_history[min_index].history['loss']\n",
        "\n",
        "    #val_loss_with_best_rmse = models_history[min_index].history['val_loss']\n",
        "\n",
        "    # Collecting important results\n",
        "    performance_metrics =  {\n",
        "\n",
        "                        'scores': {'rmse': rmse_array,\n",
        "                                    'mape': mape_array,\n",
        "                                    'R': R_array,\n",
        "                                    'elapsed_time': elapsed_time_array\n",
        "                                    },\n",
        "\n",
        "                        'minimums': {'rmse': np.min(rmse_array),\n",
        "                                      'mape': np.min(mape_array),\n",
        "                                      'R': np.min(R_array),\n",
        "                                      'elapsed_time': np.min(elapsed_time_array)\n",
        "                                      },\n",
        "\n",
        "                        'avg_scores':  {'rmse': np.mean(rmse_array),\n",
        "                                        'mape': np.mean(mape_array),\n",
        "                                        'R': np.mean(R_array),\n",
        "                                        'elapsed_time': np.mean(elapsed_time_array)\n",
        "                                        },\n",
        "\n",
        "                          'stds':      { 'rmse': np.std(rmse_array),\n",
        "                                          'mape': np.std(mape_array),\n",
        "                                          'R': np.std(R_array),\n",
        "                                          'elapsed_time': np.std(elapsed_time_array)\n",
        "                                        },\n",
        "\n",
        "                        'maximums': {'rmse': np.max(rmse_array),\n",
        "                                     'mape': np.max(mape_array),\n",
        "                                     'R': np.max(R_array),\n",
        "                                     'elapsed_time': np.max(elapsed_time_array)\n",
        "                                     }\n",
        "\n",
        "                  }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    model_with_best_rmse = {\n",
        "\n",
        "                            'replicate': min_index,\n",
        "                            'rmse': best_rmse,\n",
        "                            #'mae': mae_with_best_rmse,\n",
        "                            'mape': mape_with_best_rmse,\n",
        "                            #'R2': R2_with_best_rmse,\n",
        "                            'R':  R_with_best_rmse,\n",
        "                            'elapsed_time': elapsed_time_with_best_rmse,\n",
        "                            'train_predictions':train_predictions_with_best_rmse,\n",
        "                            'test_predictions': test_predictions_with_best_rmse,\n",
        "                            #'y_train':y_train_original,\n",
        "                            #'y_test': y_test_original,\n",
        "                            'loss':loss_with_best_rmse,\n",
        "                             #'val_loss': val_loss_with_best_rmse\n",
        "                            }\n",
        "\n",
        "     # Collecting hyperparameters\n",
        "    hyper_parameters = {'layers': layers,\n",
        "                        'model_specific_hyper_parameters': hyper_parameters,\n",
        "                       'epochs': epochs,\n",
        "                       'time_step':time_step,\n",
        "                       'num_replicates': num_replicates,\n",
        "                       'test_split':test_split\n",
        "                        }\n",
        "\n",
        "\n",
        "     # Collecting all the outputs together\n",
        "    output_dictionary = {'hyper_parameters': hyper_parameters,\n",
        "                        'performance_metrics': performance_metrics,\n",
        "                         'best_model': model_with_best_rmse,\n",
        "                       }\n",
        "\n",
        "\n",
        "    pd.DataFrame(y_train_original).to_csv(output_dir_path+'y_train.csv')\n",
        "    pd.DataFrame(y_test_original).to_csv(output_dir_path+'y_test.csv')\n",
        "\n",
        "    print(\"Progress: All works are done successfully, congratulations!!\\n\")\n",
        "    return output_dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lYXzavHmTtpH",
        "outputId": "b43d69a6-9423-43e5-c4ea-a5a3f4ad3836"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "Program is running for 0 replicate\n",
            "\n",
            "Epoch 1/3\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.0506\n",
            "Epoch 2/3\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 3/3\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 1 replicate\n",
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0591\n",
            "Epoch 2/3\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0202\n",
            "Epoch 3/3\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: All works are done successfully, congratulations!!\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'hyper_parameters': {'layers': [16],\n",
              "  'model_specific_hyper_parameters': ['Adam', 16],\n",
              "  'epochs': 3,\n",
              "  'time_step': 5,\n",
              "  'num_replicates': 2,\n",
              "  'test_split': 0.2},\n",
              " 'performance_metrics': {'scores': {'rmse': array([43.43021454, 43.00449562]),\n",
              "   'mape': array([13.01040567, 12.8605816 ]),\n",
              "   'R': array([nan, nan]),\n",
              "   'elapsed_time': array([4.76385403, 2.82171965])},\n",
              "  'minimums': {'rmse': 43.004495623660496,\n",
              "   'mape': 12.860581595003797,\n",
              "   'R': nan,\n",
              "   'elapsed_time': 2.8217196464538574},\n",
              "  'avg_scores': {'rmse': 43.2173550822512,\n",
              "   'mape': 12.935493633683393,\n",
              "   'R': nan,\n",
              "   'elapsed_time': 3.7927868366241455},\n",
              "  'stds': {'rmse': 0.2128594585907102,\n",
              "   'mape': 0.07491203867959673,\n",
              "   'R': nan,\n",
              "   'elapsed_time': 0.9710671901702881},\n",
              "  'maximums': {'rmse': 43.43021454084192,\n",
              "   'mape': 13.01040567236299,\n",
              "   'R': nan,\n",
              "   'elapsed_time': 4.763854026794434}},\n",
              " 'best_model': {'replicate': 1,\n",
              "  'rmse': 43.004495623660496,\n",
              "  'mape': 12.860581595003797,\n",
              "  'R': nan,\n",
              "  'elapsed_time': 2.8217196464538574,\n",
              "  'train_predictions': array([[180.41132 ],\n",
              "         [180.41132 ],\n",
              "         [180.41132 ],\n",
              "         ...,\n",
              "         [125.5968  ],\n",
              "         [126.34711 ],\n",
              "         [124.236786]], dtype=float32),\n",
              "  'test_predictions': array([[239.51245],\n",
              "         [243.4489 ],\n",
              "         [242.8436 ],\n",
              "         [242.05882],\n",
              "         [241.76541],\n",
              "         [240.13556],\n",
              "         [239.91483],\n",
              "         [240.84529],\n",
              "         [238.68628],\n",
              "         [239.44484],\n",
              "         [238.14087],\n",
              "         [229.2704 ],\n",
              "         [226.51355],\n",
              "         [224.21713],\n",
              "         [220.19193],\n",
              "         [221.62021],\n",
              "         [224.99968],\n",
              "         [218.32664],\n",
              "         [220.58755],\n",
              "         [223.1878 ],\n",
              "         [227.46109],\n",
              "         [232.32118],\n",
              "         [233.23663],\n",
              "         [234.01288],\n",
              "         [235.75925],\n",
              "         [235.18481],\n",
              "         [236.69916],\n",
              "         [237.12064],\n",
              "         [235.6493 ],\n",
              "         [235.47717],\n",
              "         [237.00034],\n",
              "         [234.91351],\n",
              "         [218.0223 ],\n",
              "         [222.1427 ],\n",
              "         [233.07507],\n",
              "         [232.57703],\n",
              "         [230.731  ],\n",
              "         [233.78497],\n",
              "         [235.08244],\n",
              "         [235.0396 ],\n",
              "         [238.2845 ],\n",
              "         [237.32016],\n",
              "         [234.90515],\n",
              "         [228.6554 ],\n",
              "         [221.33456],\n",
              "         [217.41435],\n",
              "         [216.12733],\n",
              "         [217.40588],\n",
              "         [219.84662],\n",
              "         [200.13663],\n",
              "         [214.71092],\n",
              "         [233.663  ],\n",
              "         [243.41565],\n",
              "         [249.8083 ],\n",
              "         [256.29636],\n",
              "         [251.57846],\n",
              "         [238.96501],\n",
              "         [235.7263 ],\n",
              "         [234.99149],\n",
              "         [234.12656],\n",
              "         [232.81223],\n",
              "         [236.593  ],\n",
              "         [235.08575],\n",
              "         [233.11447],\n",
              "         [233.92166],\n",
              "         [234.84991],\n",
              "         [236.53726],\n",
              "         [233.32768],\n",
              "         [231.56352],\n",
              "         [232.74442],\n",
              "         [235.75333],\n",
              "         [237.15598],\n",
              "         [237.01414],\n",
              "         [237.43109],\n",
              "         [235.98523],\n",
              "         [231.45764],\n",
              "         [220.49704],\n",
              "         [215.94206],\n",
              "         [218.59998],\n",
              "         [222.89696],\n",
              "         [230.24854],\n",
              "         [237.0954 ],\n",
              "         [239.5917 ],\n",
              "         [237.81284],\n",
              "         [233.748  ],\n",
              "         [232.27539],\n",
              "         [233.0235 ],\n",
              "         [232.60638],\n",
              "         [230.56851],\n",
              "         [227.66602],\n",
              "         [223.31216],\n",
              "         [220.88298],\n",
              "         [213.97684],\n",
              "         [210.23134],\n",
              "         [198.9049 ],\n",
              "         [181.68016],\n",
              "         [180.60374],\n",
              "         [180.76501],\n",
              "         [187.88722],\n",
              "         [195.02193],\n",
              "         [197.74086],\n",
              "         [194.16275],\n",
              "         [190.64445],\n",
              "         [175.91211],\n",
              "         [163.5989 ],\n",
              "         [156.13097],\n",
              "         [154.91171],\n",
              "         [149.63544],\n",
              "         [149.15858],\n",
              "         [149.9586 ],\n",
              "         [145.03278],\n",
              "         [147.01323],\n",
              "         [151.45407],\n",
              "         [156.91687],\n",
              "         [164.50815],\n",
              "         [174.09334],\n",
              "         [179.35767],\n",
              "         [174.39932],\n",
              "         [176.34479],\n",
              "         [178.28261],\n",
              "         [184.30771],\n",
              "         [184.59544],\n",
              "         [185.69765],\n",
              "         [188.46457],\n",
              "         [181.12878],\n",
              "         [190.6133 ],\n",
              "         [198.09865],\n",
              "         [201.9844 ],\n",
              "         [204.4896 ],\n",
              "         [205.78838],\n",
              "         [205.77792],\n",
              "         [206.10052],\n",
              "         [210.31326],\n",
              "         [211.8307 ],\n",
              "         [211.54282],\n",
              "         [213.23647],\n",
              "         [209.39142],\n",
              "         [198.86096],\n",
              "         [195.45299],\n",
              "         [198.46861],\n",
              "         [203.19614],\n",
              "         [206.58453],\n",
              "         [208.54706],\n",
              "         [203.82494],\n",
              "         [204.6992 ],\n",
              "         [201.88113],\n",
              "         [193.5127 ],\n",
              "         [184.54453],\n",
              "         [183.37186],\n",
              "         [175.35143],\n",
              "         [174.65933],\n",
              "         [184.73837],\n",
              "         [191.0891 ],\n",
              "         [198.02692],\n",
              "         [207.49794],\n",
              "         [203.9512 ],\n",
              "         [195.8625 ],\n",
              "         [194.17267],\n",
              "         [168.13647],\n",
              "         [175.80939],\n",
              "         [182.73932],\n",
              "         [184.6649 ],\n",
              "         [184.52028],\n",
              "         [178.19691],\n",
              "         [178.5171 ],\n",
              "         [185.21156],\n",
              "         [187.63373],\n",
              "         [185.09348],\n",
              "         [192.78084],\n",
              "         [195.33948],\n",
              "         [197.3561 ],\n",
              "         [201.94331],\n",
              "         [200.87106],\n",
              "         [165.56516],\n",
              "         [172.4809 ],\n",
              "         [181.46028],\n",
              "         [183.38521],\n",
              "         [192.28952],\n",
              "         [192.5189 ],\n",
              "         [199.13034],\n",
              "         [195.96562],\n",
              "         [201.85309],\n",
              "         [210.10086],\n",
              "         [217.45392],\n",
              "         [219.30098],\n",
              "         [219.92014],\n",
              "         [219.54831],\n",
              "         [218.313  ],\n",
              "         [219.44917],\n",
              "         [222.48134],\n",
              "         [218.3761 ],\n",
              "         [221.96567],\n",
              "         [223.21893],\n",
              "         [222.88693],\n",
              "         [222.78479],\n",
              "         [222.58994],\n",
              "         [223.1838 ],\n",
              "         [224.93521],\n",
              "         [222.30023],\n",
              "         [221.33955],\n",
              "         [218.86896],\n",
              "         [217.83891],\n",
              "         [202.11302],\n",
              "         [208.19524],\n",
              "         [201.88953],\n",
              "         [209.37097],\n",
              "         [213.96503],\n",
              "         [219.3632 ],\n",
              "         [216.17552],\n",
              "         [216.4432 ],\n",
              "         [221.61322],\n",
              "         [226.32686],\n",
              "         [227.66083],\n",
              "         [229.1076 ],\n",
              "         [230.92207],\n",
              "         [229.23134],\n",
              "         [231.80887],\n",
              "         [233.98956],\n",
              "         [234.25528],\n",
              "         [233.72302],\n",
              "         [235.14052],\n",
              "         [234.86496],\n",
              "         [234.19547],\n",
              "         [229.26971],\n",
              "         [230.62814],\n",
              "         [225.41478],\n",
              "         [222.48468],\n",
              "         [221.98485],\n",
              "         [220.57803],\n",
              "         [218.8275 ],\n",
              "         [219.17294],\n",
              "         [220.89325],\n",
              "         [220.89864],\n",
              "         [218.26056],\n",
              "         [215.871  ],\n",
              "         [216.50404],\n",
              "         [202.74336],\n",
              "         [199.08987],\n",
              "         [201.127  ],\n",
              "         [206.20251],\n",
              "         [210.33386],\n",
              "         [219.9805 ],\n",
              "         [225.36584],\n",
              "         [229.48062],\n",
              "         [225.08037],\n",
              "         [224.03156],\n",
              "         [220.12161],\n",
              "         [222.53508],\n",
              "         [220.63254],\n",
              "         [223.14847],\n",
              "         [223.43729],\n",
              "         [227.92276],\n",
              "         [230.65485],\n",
              "         [231.48912],\n",
              "         [235.13052],\n",
              "         [236.98125],\n",
              "         [235.20926],\n",
              "         [232.5727 ],\n",
              "         [234.28813],\n",
              "         [233.466  ],\n",
              "         [231.9628 ],\n",
              "         [235.02905],\n",
              "         [233.85666],\n",
              "         [232.84512],\n",
              "         [222.94592],\n",
              "         [218.13597],\n",
              "         [214.26352],\n",
              "         [210.5299 ],\n",
              "         [208.2492 ],\n",
              "         [209.3404 ],\n",
              "         [212.86299],\n",
              "         [214.39519],\n",
              "         [181.31833],\n",
              "         [171.87761],\n",
              "         [178.28943],\n",
              "         [185.60745],\n",
              "         [190.531  ],\n",
              "         [197.73593],\n",
              "         [204.87674],\n",
              "         [209.4969 ],\n",
              "         [207.68893],\n",
              "         [209.92435],\n",
              "         [209.41956],\n",
              "         [205.67937],\n",
              "         [210.34624],\n",
              "         [226.70708],\n",
              "         [208.40494],\n",
              "         [212.20135],\n",
              "         [217.1142 ],\n",
              "         [217.78299],\n",
              "         [215.20961],\n",
              "         [221.35547],\n",
              "         [221.9956 ],\n",
              "         [218.0935 ],\n",
              "         [217.15308],\n",
              "         [218.62668],\n",
              "         [217.07883],\n",
              "         [188.14545],\n",
              "         [183.3643 ],\n",
              "         [184.54167],\n",
              "         [159.78671],\n",
              "         [174.14449],\n",
              "         [196.21727],\n",
              "         [212.39743],\n",
              "         [233.04428],\n",
              "         [244.74219],\n",
              "         [248.00307],\n",
              "         [249.11462],\n",
              "         [247.2258 ],\n",
              "         [232.65903],\n",
              "         [227.58119],\n",
              "         [218.5097 ],\n",
              "         [215.95668],\n",
              "         [219.57434],\n",
              "         [222.36557],\n",
              "         [221.43643],\n",
              "         [224.34413],\n",
              "         [222.95314],\n",
              "         [222.14291],\n",
              "         [223.50075],\n",
              "         [222.88979],\n",
              "         [224.80978],\n",
              "         [225.06415],\n",
              "         [219.5842 ],\n",
              "         [219.42789],\n",
              "         [208.6039 ],\n",
              "         [205.49945],\n",
              "         [199.26889],\n",
              "         [206.1538 ],\n",
              "         [212.84   ],\n",
              "         [217.60805],\n",
              "         [218.18657],\n",
              "         [226.91719],\n",
              "         [229.99974],\n",
              "         [232.14511],\n",
              "         [231.03255],\n",
              "         [228.58911],\n",
              "         [228.54807],\n",
              "         [224.18402],\n",
              "         [225.52522],\n",
              "         [227.65753],\n",
              "         [222.27022],\n",
              "         [215.47217],\n",
              "         [213.48553],\n",
              "         [212.18015],\n",
              "         [210.38147],\n",
              "         [207.3337 ],\n",
              "         [211.4136 ],\n",
              "         [213.5337 ],\n",
              "         [213.57338],\n",
              "         [211.3323 ],\n",
              "         [213.81685],\n",
              "         [216.04578],\n",
              "         [217.7984 ],\n",
              "         [220.6723 ],\n",
              "         [221.66348],\n",
              "         [221.1313 ],\n",
              "         [221.12515],\n",
              "         [222.8677 ],\n",
              "         [223.5917 ],\n",
              "         [226.02173],\n",
              "         [209.84528],\n",
              "         [216.0619 ],\n",
              "         [218.87352],\n",
              "         [220.43   ],\n",
              "         [222.6471 ],\n",
              "         [229.74924],\n",
              "         [231.38942],\n",
              "         [235.2232 ],\n",
              "         [230.44443],\n",
              "         [231.25998],\n",
              "         [230.66013],\n",
              "         [229.04965],\n",
              "         [229.47507],\n",
              "         [232.31943],\n",
              "         [234.09485],\n",
              "         [234.3494 ],\n",
              "         [234.33179],\n",
              "         [237.23178],\n",
              "         [233.64798],\n",
              "         [231.68457],\n",
              "         [232.98434],\n",
              "         [230.56158],\n",
              "         [231.03087],\n",
              "         [231.58484],\n",
              "         [233.3638 ],\n",
              "         [234.83575],\n",
              "         [234.69443],\n",
              "         [233.1294 ],\n",
              "         [229.92065],\n",
              "         [224.1958 ],\n",
              "         [222.14124],\n",
              "         [222.57713],\n",
              "         [225.26613],\n",
              "         [224.06148],\n",
              "         [225.10583],\n",
              "         [225.16357],\n",
              "         [226.57626],\n",
              "         [226.9256 ],\n",
              "         [228.4111 ],\n",
              "         [232.28867],\n",
              "         [235.2179 ],\n",
              "         [233.78754],\n",
              "         [231.90659],\n",
              "         [230.36673],\n",
              "         [230.06026],\n",
              "         [230.91904],\n",
              "         [233.16641],\n",
              "         [235.2501 ],\n",
              "         [218.71388],\n",
              "         [223.70052],\n",
              "         [226.70358],\n",
              "         [223.27339],\n",
              "         [223.91714],\n",
              "         [229.30988],\n",
              "         [229.73265],\n",
              "         [229.27002],\n",
              "         [233.41336],\n",
              "         [230.842  ],\n",
              "         [232.58453],\n",
              "         [235.01233],\n",
              "         [235.272  ],\n",
              "         [232.94727],\n",
              "         [231.10089],\n",
              "         [211.0856 ],\n",
              "         [215.90683],\n",
              "         [221.49847],\n",
              "         [226.5712 ],\n",
              "         [230.08499],\n",
              "         [232.74246],\n",
              "         [230.61914],\n",
              "         [232.39957],\n",
              "         [230.4963 ],\n",
              "         [229.83101],\n",
              "         [233.09009],\n",
              "         [229.00186],\n",
              "         [225.51506],\n",
              "         [225.86224],\n",
              "         [228.33337],\n",
              "         [231.29398],\n",
              "         [233.37897],\n",
              "         [234.91693],\n",
              "         [236.83743],\n",
              "         [236.17441],\n",
              "         [226.50607],\n",
              "         [225.9076 ],\n",
              "         [228.51172],\n",
              "         [231.83282],\n",
              "         [236.89539],\n",
              "         [239.46881],\n",
              "         [239.96036],\n",
              "         [239.53532],\n",
              "         [238.88855],\n",
              "         [232.96048],\n",
              "         [234.2824 ],\n",
              "         [223.47511],\n",
              "         [225.42708],\n",
              "         [227.48944],\n",
              "         [230.44717],\n",
              "         [233.33618],\n",
              "         [233.87143],\n",
              "         [235.55396],\n",
              "         [239.65268],\n",
              "         [243.46457],\n",
              "         [243.87634],\n",
              "         [243.37402],\n",
              "         [241.8161 ],\n",
              "         [237.58908],\n",
              "         [236.59656],\n",
              "         [238.96407],\n",
              "         [238.66603],\n",
              "         [238.38422],\n",
              "         [240.15747],\n",
              "         [241.35568],\n",
              "         [239.07965],\n",
              "         [232.518  ],\n",
              "         [231.52783],\n",
              "         [232.36124],\n",
              "         [233.28842],\n",
              "         [233.55005],\n",
              "         [236.97464],\n",
              "         [235.72269],\n",
              "         [235.66171],\n",
              "         [236.14774],\n",
              "         [239.43007],\n",
              "         [238.95767],\n",
              "         [240.24026],\n",
              "         [221.43352],\n",
              "         [220.7775 ],\n",
              "         [225.59222],\n",
              "         [228.41122],\n",
              "         [229.56177],\n",
              "         [234.98938],\n",
              "         [234.67796],\n",
              "         [232.0104 ],\n",
              "         [235.21974],\n",
              "         [232.76993],\n",
              "         [233.0733 ],\n",
              "         [233.72888],\n",
              "         [234.96436],\n",
              "         [233.84538],\n",
              "         [236.5165 ],\n",
              "         [241.41904],\n",
              "         [245.31572],\n",
              "         [244.77094],\n",
              "         [242.61865],\n",
              "         [241.02032],\n",
              "         [237.09225],\n",
              "         [237.08499],\n",
              "         [239.67776],\n",
              "         [240.96341],\n",
              "         [243.01207],\n",
              "         [244.67224],\n",
              "         [244.02777],\n",
              "         [243.25938],\n",
              "         [241.52301],\n",
              "         [238.21738],\n",
              "         [219.22533],\n",
              "         [223.75394],\n",
              "         [225.18657],\n",
              "         [226.78934],\n",
              "         [228.29062],\n",
              "         [233.59274],\n",
              "         [235.98804],\n",
              "         [240.23846],\n",
              "         [242.1958 ],\n",
              "         [245.84912],\n",
              "         [246.67783],\n",
              "         [237.87704],\n",
              "         [235.35   ],\n",
              "         [233.27463],\n",
              "         [233.98457],\n",
              "         [233.13855],\n",
              "         [235.26868],\n",
              "         [236.82263],\n",
              "         [241.6457 ],\n",
              "         [242.04799],\n",
              "         [237.65335],\n",
              "         [217.0555 ],\n",
              "         [214.4729 ],\n",
              "         [215.22232],\n",
              "         [219.11903],\n",
              "         [222.85495],\n",
              "         [227.0672 ],\n",
              "         [231.09406],\n",
              "         [234.8106 ],\n",
              "         [236.95161],\n",
              "         [235.90378],\n",
              "         [234.2375 ],\n",
              "         [231.81808],\n",
              "         [230.75177],\n",
              "         [212.11594],\n",
              "         [217.5398 ],\n",
              "         [222.52963],\n",
              "         [230.36862],\n",
              "         [236.98119],\n",
              "         [245.91576],\n",
              "         [249.33173],\n",
              "         [252.61932],\n",
              "         [253.17583],\n",
              "         [253.29608],\n",
              "         [246.85124],\n",
              "         [240.41098],\n",
              "         [233.41302],\n",
              "         [230.62567],\n",
              "         [228.37857],\n",
              "         [227.31293],\n",
              "         [230.26804],\n",
              "         [235.6773 ],\n",
              "         [238.90137],\n",
              "         [239.08646],\n",
              "         [234.63608],\n",
              "         [234.51315],\n",
              "         [232.5459 ],\n",
              "         [228.04004],\n",
              "         [220.87209],\n",
              "         [219.17587],\n",
              "         [219.16132],\n",
              "         [219.01624],\n",
              "         [218.98816],\n",
              "         [214.87228],\n",
              "         [220.80734],\n",
              "         [221.91458],\n",
              "         [227.14685],\n",
              "         [230.60065],\n",
              "         [232.25458],\n",
              "         [230.55057],\n",
              "         [229.90057],\n",
              "         [227.49362],\n",
              "         [222.8052 ],\n",
              "         [223.49574],\n",
              "         [223.33289],\n",
              "         [223.06523],\n",
              "         [222.49036],\n",
              "         [219.74315],\n",
              "         [219.34708],\n",
              "         [220.61311],\n",
              "         [216.20285],\n",
              "         [217.82106],\n",
              "         [201.75621],\n",
              "         [204.49327],\n",
              "         [207.13597],\n",
              "         [213.05179],\n",
              "         [216.30612],\n",
              "         [222.19402],\n",
              "         [221.3243 ],\n",
              "         [225.1052 ],\n",
              "         [227.92848],\n",
              "         [230.43706],\n",
              "         [230.65436],\n",
              "         [231.36072],\n",
              "         [228.60086],\n",
              "         [230.73305],\n",
              "         [217.4737 ],\n",
              "         [224.07825],\n",
              "         [224.90164],\n",
              "         [228.91351],\n",
              "         [231.45909],\n",
              "         [236.56474],\n",
              "         [236.08325],\n",
              "         [231.89943],\n",
              "         [232.617  ],\n",
              "         [225.70444],\n",
              "         [228.2825 ],\n",
              "         [231.97205],\n",
              "         [235.16605],\n",
              "         [234.83725],\n",
              "         [234.11023],\n",
              "         [236.52094],\n",
              "         [236.89703],\n",
              "         [237.12125],\n",
              "         [238.23529],\n",
              "         [239.20245],\n",
              "         [241.3959 ],\n",
              "         [238.31241],\n",
              "         [235.56187],\n",
              "         [233.39037],\n",
              "         [232.77365],\n",
              "         [230.16489],\n",
              "         [230.5986 ],\n",
              "         [228.95059],\n",
              "         [229.6724 ],\n",
              "         [219.92499],\n",
              "         [217.85454],\n",
              "         [219.31363],\n",
              "         [220.12753],\n",
              "         [218.32156],\n",
              "         [219.58917],\n",
              "         [217.15285],\n",
              "         [207.87079],\n",
              "         [206.17044],\n",
              "         [206.20369],\n",
              "         [210.58781],\n",
              "         [218.17865],\n",
              "         [222.11066],\n",
              "         [224.22592],\n",
              "         [222.75131],\n",
              "         [217.41359],\n",
              "         [217.89755],\n",
              "         [217.2074 ],\n",
              "         [217.67032],\n",
              "         [220.34708],\n",
              "         [224.36963],\n",
              "         [205.2649 ],\n",
              "         [210.85626],\n",
              "         [217.17029],\n",
              "         [221.83167],\n",
              "         [224.6023 ],\n",
              "         [230.19562],\n",
              "         [229.05081],\n",
              "         [226.36734],\n",
              "         [218.47975],\n",
              "         [204.36398],\n",
              "         [200.96352],\n",
              "         [194.04405],\n",
              "         [191.57751],\n",
              "         [162.5914 ],\n",
              "         [170.79993],\n",
              "         [177.44244],\n",
              "         [187.67293],\n",
              "         [186.39163],\n",
              "         [201.387  ],\n",
              "         [209.51056],\n",
              "         [214.33139],\n",
              "         [211.6233 ],\n",
              "         [219.48798],\n",
              "         [221.73732],\n",
              "         [224.10957],\n",
              "         [226.9418 ],\n",
              "         [232.33295],\n",
              "         [235.70529],\n",
              "         [235.90005],\n",
              "         [235.77393],\n",
              "         [230.23625],\n",
              "         [223.95993],\n",
              "         [225.36961],\n",
              "         [224.55878],\n",
              "         [225.80185],\n",
              "         [228.98438],\n",
              "         [232.96277],\n",
              "         [233.08136],\n",
              "         [232.85419],\n",
              "         [231.24309],\n",
              "         [227.0422 ],\n",
              "         [214.28464],\n",
              "         [217.68239],\n",
              "         [216.4323 ],\n",
              "         [216.00974]], dtype=float32),\n",
              "  'loss': [0.0293055959045887, 0.018901534378528595, 0.01875324547290802]}}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "hyper_parameters = ['Adam', 16]\n",
        "\n",
        "layers = [16]\n",
        "initial_learning_rate =0.01\n",
        "target_var = \"Close\"\n",
        "\n",
        "gru_output = GRU_Model_Implementation(layers,\n",
        "                                      hyper_parameters,\n",
        "                                      data1,\n",
        "                                      time_step = 5,\n",
        "                                      test_split = 0.2,\n",
        "                                      epochs = 3,\n",
        "                                      initial_learning_rate=initial_learning_rate,\n",
        "                                      num_replicates = 2)\n",
        "\n",
        "gru_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAMx815MTtpI"
      },
      "outputs": [],
      "source": [
        "def Multiple_GRU_Models(hidden_layers,\n",
        "                        hyper_parameters,\n",
        "                        data,\n",
        "                        time_step = 5,\n",
        "                        test_split = 0.2,\n",
        "                        initial_learning_rate=0.01,\n",
        "                        epochs = 30,\n",
        "                        num_replicates = 2):\n",
        "\n",
        "  num_models = len(hidden_layers)\n",
        "\n",
        "  # collect all scores\n",
        "  rmse = []\n",
        "  mape = []\n",
        "  R = []\n",
        "  elapsed_time = []\n",
        "\n",
        "  # collect all avg scores\n",
        "  avg_rmse = []\n",
        "  avg_mape = []\n",
        "  avg_R = []\n",
        "  avg_elapsed_time = []\n",
        "\n",
        "  # iteratively update the best rmse and the corresponding model\n",
        "  best_avg_rmse = float('inf')\n",
        "  best_rmse = float('inf')\n",
        "  best_model_hidden_layers = None\n",
        "  best_model_output = None\n",
        "\n",
        "  for i in range(num_models):\n",
        "    print(\"Running model with hidden neurons: \", hidden_layers[i])\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"Best Hyper_parameters used: \", hyper_parameters[i])\n",
        "\n",
        "    print(\"\\n\")\n",
        "\n",
        "    output = GRU_Model_Implementation(hidden_layers[i],\n",
        "                                      hyper_parameters[i],\n",
        "                                      data,\n",
        "                                      time_step,\n",
        "                                      test_split,\n",
        "                                      initial_learning_rate,\n",
        "                                      epochs,\n",
        "                                      num_replicates)\n",
        "\n",
        "    rmse.append(output['performance_metrics']['scores']['rmse'])\n",
        "    mape.append(output['performance_metrics']['scores']['mape'])\n",
        "    R.append(output['performance_metrics']['scores']['R'])\n",
        "    elapsed_time.append(output['performance_metrics']['scores']['elapsed_time'])\n",
        "\n",
        "    avg_rmse.append(output['performance_metrics']['avg_scores']['rmse'])\n",
        "    avg_mape.append(output['performance_metrics']['avg_scores']['mape'])\n",
        "    avg_R.append(output['performance_metrics']['avg_scores']['R'])\n",
        "    avg_elapsed_time.append(output['performance_metrics']['avg_scores']['elapsed_time'])\n",
        "\n",
        "    if avg_rmse[i] < best_avg_rmse:\n",
        "      best_avg_rmse = avg_rmse[i]\n",
        "      best_rmse = output['best_model']['rmse']\n",
        "      best_model_hidden_layers = hidden_layers[i]\n",
        "      best_model_output = output\n",
        "\n",
        "\n",
        "  rmse = np.array(rmse)\n",
        "  mape = np.array(mape)\n",
        "  R =  np.array(R)\n",
        "\n",
        "  # Collecting all  scores\n",
        "\n",
        "  performance_metrics = {\n",
        "\n",
        "       'scores':  {'layers': hidden_layers,\n",
        "                   'rmse': rmse,\n",
        "                   'mape': mape,\n",
        "                   'R':R,\n",
        "                   'elapsed_time': elapsed_time },\n",
        "\n",
        "       'avg_scores':  pd.DataFrame({'layers': hidden_layers,\n",
        "                                    'rmse': np.array(avg_rmse),\n",
        "                                    'mape': np.array(avg_mape), 'R':np.array(avg_R),\n",
        "                                    'elapsed_time':np.array(avg_elapsed_time)}),\n",
        "\n",
        "       'stds':     pd.DataFrame({'layers': hidden_layers,\n",
        "                                 'rmse': np.std(rmse, axis = 1),\n",
        "                                 'mape': np.std(mape, axis = 1),\n",
        "                                 'R':  np.std(R, axis = 1 ),\n",
        "                                 'elapsed_time': np.std(elapsed_time, axis = 1 )}),\n",
        "       'minimums': pd.DataFrame({'layers': hidden_layers,\n",
        "                                'rmse': np.min(rmse, axis =1 ),\n",
        "                                'mape': np.min(mape, axis= 1),\n",
        "                                'R': np.min(R, axis =1),\n",
        "                                'elapsed_time': np.min(elapsed_time, axis =1)}),\n",
        "\n",
        "       'maximums': pd.DataFrame({'layers': hidden_layers,\n",
        "                                'rmse': np.max(rmse, axis =1),\n",
        "                                'mape': np.max(mape, axis =1),\n",
        "                                'R': np.max(R, axis =1),\n",
        "                                'elapsed_time': np.max(elapsed_time,axis =1)})\n",
        "    }\n",
        "\n",
        "\n",
        "  output_dictionary = {\n",
        "                     'hyper_parameters': hyper_parameters,\n",
        "                      'best_avg_rmse': best_avg_rmse,\n",
        "                      'best_rmse': best_rmse,\n",
        "                      'best_model_hidden_layers': best_model_hidden_layers,\n",
        "                      'best_model_output': best_model_output\n",
        "                      }\n",
        "\n",
        "  #Save all statistics:\n",
        "  performance_metrics['avg_scores'].to_csv(output_dir_path+'multiple_gru_models_average_scores.csv')\n",
        "  performance_metrics['stds'].to_csv(output_dir_path+'multiple_gru_models_stds.csv')\n",
        "  performance_metrics['minimums'].to_csv(output_dir_path+'multiple_gru_models_minimums.csv')\n",
        "  performance_metrics['maximums'].to_csv(output_dir_path+'multiple_gru_models_maximums.csv')\n",
        "\n",
        "\n",
        "  #Save all scores in the file for future analysis\n",
        "  pd.DataFrame(performance_metrics['scores']['rmse']).to_csv(output_dir_path+'multiple_gru_models_all_rmse.csv')\n",
        "  pd.DataFrame(performance_metrics['scores']['mape']).to_csv(output_dir_path+'multiple_gru_models_all_mape.csv')\n",
        "  pd.DataFrame(performance_metrics['scores']['R']).to_csv(output_dir_path+'multiple_gru_models_all_R.csv')\n",
        "\n",
        "  #Save best model results\n",
        "  pd.DataFrame(best_model_output['best_model']['loss']).to_csv(output_dir_path+'best_gru_model_loss.csv')\n",
        "  pd.DataFrame(best_model_output['best_model']['train_predictions']).to_csv(output_dir_path+'best_gru_model_train_predictions.csv')\n",
        "  pd.DataFrame(best_model_output['best_model']['test_predictions']).to_csv(output_dir_path+'best_gru_model_test_predictions.csv')\n",
        "  pd.DataFrame(best_model_output['performance_metrics']['scores']['rmse']).to_csv(output_dir_path+'best_gru_model_all_rmse.csv')\n",
        "\n",
        "  # writing all result in the file\n",
        "  write_dic_to_file(output_dictionary, output_dir_path + \"multiple_gru_models_full_results.txt\")\n",
        "\n",
        "  # Display some key results in the screen\n",
        "  print(\"\\nBest model and its avg rmse and minimum rmse):\\n\", best_model_hidden_layers, best_avg_rmse, best_rmse)\n",
        "  print(\"Hyper_parameters:\\n\", hyper_parameters)\n",
        "  print('\\nAverage scores:\\n',  performance_metrics['avg_scores'])\n",
        "  print('\\nStandard_deviations:\\n',  performance_metrics['stds'])\n",
        "  print('\\nMinimums:\\n',  performance_metrics['minimums'])\n",
        "  print('\\nMaximums:\\n',  performance_metrics['maximums'])\n",
        "\n",
        "  print(\"Progress: All works are done successfully, congratulations!!\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbAht5VD62KW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4n_gjX3TtpJ"
      },
      "source": [
        "#### **Running Multiple GRU Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWIQT89PTtpK",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "initial_learning_rate= 0.01\n",
        "gru_hidden_layers = [[8], [16], [32],  [64],  [128]]\n",
        "\n",
        "gru_best_hyper_parameters =  [ ['Adam', 32],\n",
        "                                ['Adam', 16],\n",
        "                                ['Adam', 8],\n",
        "                                ['Adam', 8],\n",
        "                                ['Adam', 8]\n",
        "                                ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68TxzQySsABC",
        "outputId": "824d1a85-638e-4d8e-f592-2e96c277919b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running model with hidden neurons:  [8]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Nadam', 16]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "Program is running for 0 replicate\n",
            "\n",
            "Epoch 1/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - loss: 0.0608\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0211\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0199\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0201\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 20/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 1 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0589\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0168\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0192\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 2 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0678\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0173\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 3 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0553\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0201\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0157\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0161\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0169\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 4 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0549\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0205\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 20/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 5 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0564\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0163\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0167\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 20/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 21/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 22/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 23/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 6 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0578\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 7 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0652\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 20/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 21/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 22/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 8 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0615\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0156\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0164\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0202\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0170\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 9 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0603\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 20/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 10 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0630\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 11 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0620\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 20/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0200\n",
            "Epoch 21/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 22/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0634\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0160\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0208\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 13 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0588\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0200\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 14 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0557\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0206\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0162\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 15 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0599\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0215\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 16 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0667\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 20/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 21/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 22/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 23/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 24/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 25/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 17 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0589\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0162\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 18 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0654\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0197\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 19 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0588\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0199\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 20 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0586\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0209\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 21 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0569\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 22 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0647\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 23 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0549\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0200\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 24 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0639\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Program is running for 25 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0621\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0169\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 26 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0634\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0203\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 27 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0660\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 19/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 20/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 28 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0688\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 29 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0635\n",
            "Epoch 2/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 3/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 4/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0165\n",
            "Epoch 5/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0166\n",
            "Epoch 6/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 7/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 8/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 9/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 10/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 11/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0204\n",
            "Epoch 12/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 13/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 14/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 15/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 16/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 17/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 18/25\n",
            "\u001b[1m178/178\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n",
            "Running model with hidden neurons:  [16]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Nadam', 8]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "Program is running for 0 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0380\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0170\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 17/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 18/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0206\n",
            "Epoch 19/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 20/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 1 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - loss: 0.0355\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0169\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0155\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0190\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 2 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0328\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0184\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - loss: 0.0176\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0202\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 17/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0200\n",
            "Epoch 18/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0167\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 3 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0383\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0202\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0198\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0162\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 4 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0382\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0171\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0199\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0205\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 5 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0348\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0199\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0222\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 6 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0410\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0192\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 17/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0191\n",
            "Epoch 18/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0170\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 7 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0329\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0207\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0200\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 8 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0356\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0200\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 9 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0386\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0172\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0203\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0196\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 10 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0350\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0207\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0175\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 11 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0337\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0163\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0189\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0362\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0164\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0197\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 13 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0387\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0206\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0199\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 14 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0389\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0165\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0199\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 15 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0385\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 16 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0345\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0160\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 17 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0404\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 18 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0353\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0201\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 19 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0337\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0166\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Program is running for 20 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0357\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0163\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0198\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 21 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0412\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0170\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0159\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 22 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0381\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 23 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0354\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0173\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 24 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0357\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0168\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0173\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 25 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0434\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0171\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0164\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 26 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0374\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0167\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0200\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0161\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0166\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 27 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0412\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0171\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 28 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0418\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 29 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0393\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n",
            "Running model with hidden neurons:  [32]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Adam', 8]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Program is running for 0 replicate\n",
            "\n",
            "Epoch 1/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0437\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0211\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0170\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0174\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 1 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0419\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 17/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 18/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 19/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0192\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 2 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0375\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0218\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0202\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0170\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0216\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0169\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 3 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0447\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0194\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0199\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 17/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 18/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0211\n",
            "Epoch 19/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 20/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 21/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 22/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0199\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 4 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0375\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0206\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0199\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 5 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0372\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 6 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0392\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 7 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0346\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 8 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0368\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 9 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.0337\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0189\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0205\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 10 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0428\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0215\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0196\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 11 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 0.0422\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0173\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0201\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0355\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0206\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0199\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 13 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0375\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0189\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0181\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 14 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0376\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0195\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 15 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0373\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0192\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0200\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0206\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0197\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 16 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0447\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0198\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0192\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 17 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0356\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0165\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0198\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0181\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 18 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0406\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0186\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0203\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0175\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0201\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 19 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0308\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0192\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 20 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0397\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0184\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0189\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 21 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0410\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0202\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0179\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0195\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0201\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 17/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 18/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 22 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0330\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0178\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0173\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 23 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.0360\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0204\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0177\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 24 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0478\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0189\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0190\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0172\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0198\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0202\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 25 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0382\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0178\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0198\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0183\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0204\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0207\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 26 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - loss: 0.0430\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0185\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0204\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0182\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0203\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0176\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0201\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 27 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0351\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0215\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Program is running for 28 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0379\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0202\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0193\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0204\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 17/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 18/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 19/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 20/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0196\n",
            "Epoch 21/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0201\n",
            "Epoch 22/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0192\n",
            "Epoch 23/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0186\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 29 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 6ms/step - loss: 0.0376\n",
            "Epoch 2/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 3/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0205\n",
            "Epoch 5/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0200\n",
            "Epoch 6/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0188\n",
            "Epoch 7/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 9/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 10/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0201\n",
            "Epoch 11/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.0180\n",
            "Epoch 13/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0184\n",
            "Epoch 14/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 0.0197\n",
            "Epoch 15/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 16/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 17/25\n",
            "\u001b[1m356/356\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n",
            "Running model with hidden neurons:  [64]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Nadam', 32]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n",
            "Program is running for 0 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0557\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0197\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0171\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0184\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0157\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 1 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0576\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0194\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0172\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0195\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0164\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0215\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 2 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0577\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0152\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0168\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0164\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0198\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 3 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - loss: 0.0610\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0166\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0170\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0166\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0180\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 4 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0530\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0164\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0188\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0166\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0205\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0167\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0165\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 5 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - loss: 0.0603\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0168\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0162\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0213\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0198\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0210\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0182\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0197\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0159\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Program is running for 6 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0519\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0202\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0199\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0188\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0170\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0174\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0188\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 7 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0561\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0166\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0198\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0203\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 8 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0558\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0192\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0197\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0172\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0164\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0160\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0183\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0169\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 9 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0587\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 10 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0587\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0206\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0167\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0175\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0164\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 11 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - loss: 0.0536\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0198\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0161\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0199\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0175\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0161\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0202\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0559\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0175\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 13 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0551\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0170\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0193\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0183\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0178\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0200\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0200\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 14 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0544\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0190\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0161\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0196\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0185\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0170\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0189\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0181\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 15 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0555\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0198\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0174\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Program is running for 16 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0576\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0185\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0194\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0182\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0189\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 17 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0548\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0196\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0202\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0189\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0183\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0171\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 18 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0587\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0162\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0185\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0187\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0176\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0186\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0167\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 19 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0594\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0169\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0189\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0168\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0197\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0193\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0209\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0173\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0159\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0176\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0158\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 20 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - loss: 0.0559\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0190\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0192\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 21 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0541\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0183\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0177\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0180\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0170\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0168\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0181\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0194\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0175\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 22 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - loss: 0.0575\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0195\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0189\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0166\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0174\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0188\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0180\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0179\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0177\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0191\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Program is running for 23 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0518\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0177\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0186\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0210\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0194\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0206\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0162\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0172\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 24 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - loss: 0.0548\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0194\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0164\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0173\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0166\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0188\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Program is running for 25 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0532\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0162\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0168\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0164\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0205\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0198\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0199\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 26 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0558\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0178\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0188\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0200\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0177\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0192\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0193\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0175\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0180\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0195\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 27 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - loss: 0.0525\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0202\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0207\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0172\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0174\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0161\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0188\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0155\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0186\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0181\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 28 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0573\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0187\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0199\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0170\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0185\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0173\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0183\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0168\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0187\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0167\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0182\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0153\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0169\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0203\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0176\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0162\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0190\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Program is running for 29 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - loss: 0.0551\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0193\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0191\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0174\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0183\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0184\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0197\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0179\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0176\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0177\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0179\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0179\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0189\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0203\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0171\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0178\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0163\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0182\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0181\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0190\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n",
            "Running model with hidden neurons:  [128]\n",
            "\n",
            "\n",
            "Best Hyper_parameters used:  ['Nadam', 32]\n",
            "\n",
            "\n",
            "Progress: Performing data preparation steps.......\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Program is running for 0 replicate\n",
            "\n",
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0570\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0204\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0194\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0188\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0177\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0174\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0179\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0190\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0187\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0165\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0187\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0209\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0193\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 1 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0673\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0199\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0173\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0200\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0174\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0165\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0201\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0180\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0180\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0192\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0198\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0185\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0190\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Program is running for 2 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0563\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0190\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0201\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0191\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0183\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0214\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0177\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0175\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0182\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0191\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0181\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0182\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0190\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0193\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0190\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0188\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0188\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 3 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0545\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0173\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0177\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0173\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0202\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176 \n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0188\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0203\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0189\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0172\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0194\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Program is running for 4 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0558\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0170\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0168\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0200\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0188\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0194\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0199\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0191\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0200\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 5 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0519\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0196\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0175\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0188\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0174\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0166\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0188\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0176\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 6 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0549\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0200\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0202\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0162\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0184\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0181\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0173\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0166\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 7 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0572\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0163\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0173\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0172\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0200\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0166\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0173\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0172\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0182\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0187\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 8 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0603\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0215\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0193\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0165\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0165\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0170\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0170\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0162\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0170\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0174\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0165\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0192\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Program is running for 9 replicate\n",
            "\n",
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0610\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0190\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0172\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0175\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0186\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0167\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0186\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 10 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 9ms/step - loss: 0.0575\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0175\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0157\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0166\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0166\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0167\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0174\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0189\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0186\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0191\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0168\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 11 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0633\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0170\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0186\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0170\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0186\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0202\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0205\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0176\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0166\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0180\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0183\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0189\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 12 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0641\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0185\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0172\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0168\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0157\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0200\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0197\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0172\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0186\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0182\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0168\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0170\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0179\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 13 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0569\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0183\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0187\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0173\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0199\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0178\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0167\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0177\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0175\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0180\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0174\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0177\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 14 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0531\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0192\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0176\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0177\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0192\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0187\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0179\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0165\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0209\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0196\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - loss: 0.0187\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0182\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0176\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0158\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0168\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0196\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 15 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0589\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0209\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0178\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0196\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0179\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0171\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0175\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0194\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0165\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0170\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0183\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0175\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0174\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 16 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0624\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0197\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0206\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0163\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0192\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0174\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0174\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0165\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0178\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0185\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0181\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0183\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 17 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0645\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0179\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0172\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0169\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0181\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0203\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0169\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0186\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 18 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0554\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0177\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0172\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0175\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0193\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0188\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0188\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0191\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0190\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 19 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0607\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0181\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0199\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0175\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0181\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0185\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0179\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0188\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0202\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0170\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0168\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 20 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - loss: 0.0585\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0179\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0190\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0196\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0179\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0191\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0185\n",
            "Epoch 25/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0180\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 21 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0593\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0195\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0199\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0161\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0176\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0185\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0186\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0160\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0188\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0180\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0166\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0182\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Program is running for 22 replicate\n",
            "\n",
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0570\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0178\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0206\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0167\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - loss: 0.0176\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0184\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0198\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0194\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0185\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0172\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Program is running for 23 replicate\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0548\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0178\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0167\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0184\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - loss: 0.0178\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0176\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0164\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0196\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0162\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0206\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0177\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0182\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0197\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0168\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 24 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0606\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0168\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0194\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0180\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0194\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0196\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0174\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0176\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0187\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0208\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0175\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0170\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0186\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0177\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 25 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0598\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0193\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0183\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0173\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0169\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0198\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0174\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0168\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0189\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0172\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0184\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0171\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 26 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0554\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0207\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - loss: 0.0178\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0190\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0182\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0166\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0173\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0169\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0176\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0193\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - loss: 0.0167\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0191\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0183\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0190\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0177\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0185\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 27 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - loss: 0.0568\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0186\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0179\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0174\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0165\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0192\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0188\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0190\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0170\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0178\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0191\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 0.0190\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0171\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0163\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0175\n",
            "Epoch 24/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 28 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - loss: 0.0570\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0196\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0196\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - loss: 0.0192\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0176\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0181\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0180\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0172\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0174\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0187\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0181\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0182\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0194\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - loss: 0.0190\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0162\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0185\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0169\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0177\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0203\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0193\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Program is running for 29 replicate\n",
            "\n",
            "Epoch 1/25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - loss: 0.0645\n",
            "Epoch 2/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - loss: 0.0188\n",
            "Epoch 3/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - loss: 0.0178\n",
            "Epoch 4/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0187\n",
            "Epoch 5/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0187\n",
            "Epoch 6/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0182\n",
            "Epoch 7/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0182\n",
            "Epoch 8/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0172\n",
            "Epoch 9/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 10/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0179\n",
            "Epoch 11/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0180\n",
            "Epoch 12/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.0161\n",
            "Epoch 13/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0196\n",
            "Epoch 14/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0183\n",
            "Epoch 15/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - loss: 0.0190\n",
            "Epoch 16/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - loss: 0.0181\n",
            "Epoch 17/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0192\n",
            "Epoch 18/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: 0.0188\n",
            "Epoch 19/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0195\n",
            "Epoch 20/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0189\n",
            "Epoch 21/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0178\n",
            "Epoch 22/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0171\n",
            "Epoch 23/25\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0184\n",
            "\u001b[1m89/89\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2889: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
            "  c = cov(x, y, rowvar, dtype=dtype)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: divide by zero encountered in divide\n",
            "  c *= np.true_divide(1, fact)\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:2748: RuntimeWarning: invalid value encountered in multiply\n",
            "  c *= np.true_divide(1, fact)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Best model and its avg rmse and minimum rmse):\n",
            " [32] 43.23743029673688 42.403846611857446\n",
            "Hyper_parameters:\n",
            " [['Nadam', 16], ['Nadam', 8], ['Adam', 8], ['Nadam', 32], ['Nadam', 32]]\n",
            "\n",
            "Average scores:\n",
            "   layers       rmse       mape   R  elapsed_time\n",
            "0    [8]  43.786632  13.116550 NaN     21.459652\n",
            "1   [16]  43.796412  13.120591 NaN     29.847872\n",
            "2   [32]  43.237430  12.929401 NaN     31.370003\n",
            "3   [64]  44.663973  13.375558 NaN     19.150530\n",
            "4  [128]  44.859861  13.436002 NaN     31.094237\n",
            "\n",
            "Standard_deviations:\n",
            "   layers      rmse      mape   R  elapsed_time\n",
            "0    [8]  0.429197  0.146360 NaN      3.579730\n",
            "1   [16]  0.394013  0.157505 NaN      6.792557\n",
            "2   [32]  0.424416  0.171552 NaN      8.290647\n",
            "3   [64]  0.145125  0.044613 NaN      2.575899\n",
            "4  [128]  0.153065  0.050778 NaN      2.038058\n",
            "\n",
            "Minimums:\n",
            "   layers       rmse       mape   R  elapsed_time\n",
            "0    [8]  43.012790  12.865844 NaN     16.227490\n",
            "1   [16]  43.158755  12.854164 NaN     21.524930\n",
            "2   [32]  42.403847  12.580190 NaN     18.953528\n",
            "3   [64]  44.219407  13.241602 NaN     10.285028\n",
            "4  [128]  44.267551  13.249407 NaN     27.775188\n",
            "\n",
            "Maximums:\n",
            "   layers       rmse       mape   R  elapsed_time\n",
            "0    [8]  44.924077  13.533103 NaN     29.821247\n",
            "1   [16]  44.772974  13.552293 NaN     48.118361\n",
            "2   [32]  44.145309  13.338137 NaN     51.595577\n",
            "3   [64]  44.914231  13.456451 NaN     26.767690\n",
            "4  [128]  45.087584  13.525322 NaN     35.464642\n",
            "Progress: All works are done successfully, congratulations!!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "Multiple_GRU_Models(gru_hidden_layers,\n",
        "                    lstm_best_hyper_parameters,\n",
        "                    data1,\n",
        "                    time_step = 5,\n",
        "                    test_split = 0.1518,\n",
        "                    initial_learning_rate=initial_learning_rate,\n",
        "                    epochs = 25,\n",
        "                    num_replicates = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V69YaDSNTTtd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEGyUA2_2aDO"
      },
      "source": [
        "## **Step 6: Results Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDUcREHyQ-5E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6e5d072-24be-48e0-d11a-943753245b69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rnn-100N-hyperparameter_tuning__results.txt\n",
            "rnn-150N-hyperparameter_tuning__results.txt\n",
            "rnn-200N-hyperparameter_tuning__results.txt\n",
            "rnn-10N-hyperparameter_tuning__results.txt\n",
            "rnn-30N-hyperparameter_tuning__results.txt\n",
            "rnn-50N-hyperparameter_tuning__results.txt\n",
            "multiple_rnn_models_average_scores.csv\n",
            "multiple_rnn_models_stds.csv\n",
            "multiple_rnn_models_minimums.csv\n",
            "multiple_rnn_models_maximums.csv\n",
            "multiple_rnn_models_all_rmse.csv\n",
            "multiple_rnn_models_all_mape.csv\n",
            "multiple_rnn_models_all_R.csv\n",
            "best_rnn_model_loss.csv\n",
            "best_rnn_model_train_predictions.csv\n",
            "best_rnn_model_test_predictions.csv\n",
            "best_rnn_model_all_rmse.csv\n",
            "multiple_rnn_models_full_results.txt\n",
            "rnn_loss_plot.png\n",
            "rnn_loss_plot_improved_with_border.png\n",
            "rnn_all_scores_boxplots.png\n",
            "lstm-10N-hyperparameter_tuning__results.txt\n",
            "lstm-30N-hyperparameter_tuning__results.txt\n",
            "lstm-50N-hyperparameter_tuning__results.txt\n",
            "lstm-100N-hyperparameter_tuning__results.txt\n",
            "lstm-150N-hyperparameter_tuning__results.txt\n",
            "lstm-200N-hyperparameter_tuning__results.txt\n",
            "gru-10N-hyperparameter_tuning__results.txt\n",
            "lstm-16N-hyperparameter_tuning__results.txt\n",
            "lstm-8N-hyperparameter_tuning__results.txt\n",
            "lstm-32N-hyperparameter_tuning__results.txt\n",
            "lstm-64N-hyperparameter_tuning__results.txt\n",
            "lstm-128N-hyperparameter_tuning__results.txt\n",
            "multiple_lstm_models_maximums.csv\n",
            "multiple_lstm_models_stds.csv\n",
            "multiple_lstm_models_average_scores.csv\n",
            "multiple_lstm_models_minimums.csv\n",
            "multiple_lstm_models_all_mape.csv\n",
            "multiple_lstm_models_all_R.csv\n",
            "multiple_lstm_models_all_rmse.csv\n",
            "best_lstm_model_train_predictions.csv\n",
            "best_lstm_model_loss.csv\n",
            "best_lstm_model_test_predictions.csv\n",
            "multiple_lstm_models_full_results.txt\n",
            "best_lstm_model_all_rmse.csv\n",
            "gru-8N-hyperparameter_tuning__results.txt\n",
            "gru-16N-hyperparameter_tuning__results.txt\n",
            "gru-32N-hyperparameter_tuning__results.txt\n",
            "gru-64N-hyperparameter_tuning__results.txt\n",
            "gru-128N-hyperparameter_tuning__results.txt\n",
            "y_train.csv\n",
            "y_test.csv\n",
            "multiple_gru_models_all_R.csv\n",
            "best_gru_model_loss.csv\n",
            "multiple_gru_models_average_scores.csv\n",
            "multiple_gru_models_stds.csv\n",
            "multiple_gru_models_maximums.csv\n",
            "multiple_gru_models_all_rmse.csv\n",
            "best_gru_model_train_predictions.csv\n",
            "multiple_gru_models_all_mape.csv\n",
            "multiple_gru_models_minimums.csv\n",
            "best_gru_model_all_rmse.csv\n",
            "best_gru_model_test_predictions.csv\n",
            "multiple_gru_models_full_results.txt\n",
            "lstm_gru_loss_plot.png\n",
            "lstm_gru_loss_plot_improved_with_border.png\n",
            "multiple_avg_scores_plots.png\n",
            "true_vs_prediction_plot_train_data.png\n",
            "true_vs_prediction_plot_test_data.png\n",
            "best_model_predictions_test_data.png\n",
            "best_model_predictions_train_data.png\n",
            "comparative_rmse_boxplots.png\n",
            "lstm_all_scores_boxplots.png\n",
            "gru_all_scores_boxplots.png\n",
            "best_model_rmse_qq_plots.png\n"
          ]
        }
      ],
      "source": [
        "# List all files and directories in the specified path\n",
        "files = os.listdir(output_dir_path)\n",
        "\n",
        "# Print the list of files\n",
        "for file in files:\n",
        "    print(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeiFBTvr2pMA"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.set_theme(style=\"whitegrid\")\n",
        "#plt.style.use('ggplot')\n",
        "\n",
        "\n",
        "def read_df_from_file(file_name):\n",
        "   return pd.read_csv(file_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zf2SR6mkE01j"
      },
      "outputs": [],
      "source": [
        "lstm_loss = read_df_from_file(output_dir_path+'best_lstm_model_loss.csv')\n",
        "gru_loss = read_df_from_file(output_dir_path+'best_gru_model_loss.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vewWgL4ExbP"
      },
      "outputs": [],
      "source": [
        "def loss_plot(lstm_loss, gru_loss):\n",
        "  fig = plt.figure(figsize = (6,4))\n",
        "\n",
        "  colors = ['indigo', 'darkgreen']\n",
        "\n",
        "  plt.plot(lstm_loss, '--o',  linewidth = 1.5, color = colors[0])\n",
        "  plt.plot(gru_loss, '--o',  linewidth = 1.5, color = colors[1])\n",
        "\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Loss(MSE)\")\n",
        "\n",
        "  plt.legend(['LSTM', 'GRU' ],  loc = 'upper right')\n",
        "  #plt.rcParams['axes.facecolor']='w'\n",
        "  plt.grid(color='#F5F5DC')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "  fig.savefig(output_dir_path +\"lstm_gru_loss_plot.png\",dpi=600)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5pJ-6ZdQ-5E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "outputId": "f4b6bba3-eee5-4c25-e439-ee67b59d9520"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss_plot(lstm_loss.iloc[:, 1], gru_loss.iloc[:, 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJdOFt7tFmOK"
      },
      "outputs": [],
      "source": [
        "import matplotlib.patches as patches"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgL9yWm1Q-5E"
      },
      "outputs": [],
      "source": [
        "def loss_plot(lstm_loss, gru_loss):\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "    # Set a modern theme\n",
        "    sns.set_theme(style=\"whitegrid\")\n",
        "\n",
        "    # Colors and line styles\n",
        "    colors = ['#4B0082', '#228B22']  # Indigo and Forest Green (Hex Codes)\n",
        "    line_styles = ['-', '--']  # Solid line for LSTM, dashed for GRU\n",
        "\n",
        "    # Plot LSTM and GRU loss curves with markers\n",
        "    ax.plot(lstm_loss, linestyle=line_styles[0], marker='o',\n",
        "            markersize=6, linewidth=2, color=colors[0], label='LSTM')\n",
        "    ax.plot(gru_loss, linestyle=line_styles[1], marker='s',\n",
        "            markersize=6, linewidth=2, color=colors[1], label='GRU')\n",
        "\n",
        "    # Adding titles and labels with better formatting\n",
        "    ax.set_xlabel(\"Epochs\", fontsize=14, color='#333333')\n",
        "    ax.set_ylabel(\"Loss (MSE)\", fontsize=14, color='#333333')\n",
        "\n",
        "    # Customize ticks and grid\n",
        "    ax.tick_params(axis='both', which='major', labelsize=12, color='#666666')\n",
        "    ax.grid(True, which='major', linestyle='--', linewidth=0.5, color='gray')\n",
        "\n",
        "    # Adding legend with improved location and aesthetics\n",
        "    ax.legend(loc='upper right', fontsize=12, frameon=True,\n",
        "              framealpha=0.9, edgecolor='black')\n",
        "\n",
        "    # Add a light background color for visual appeal\n",
        "    ax.set_facecolor('#FAFAFA')\n",
        "    fig.patch.set_facecolor('#FFFFFF')\n",
        "\n",
        "    # Enhance plot borders\n",
        "    ax.spines['top'].set_visible(False)\n",
        "    ax.spines['right'].set_visible(False)\n",
        "    ax.spines['left'].set_linewidth(1.5)\n",
        "    ax.spines['bottom'].set_linewidth(1.5)\n",
        "\n",
        "    # Add a border around the entire figure\n",
        "    border = patches.Rectangle((0, 0), 1, 1, transform=fig.transFigure,\n",
        "                               linewidth=1.5, edgecolor='#4D4D4D', facecolor='none')\n",
        "    fig.patches.append(border)\n",
        "\n",
        "    # Adjust layout to prevent clipping\n",
        "    fig.tight_layout()\n",
        "\n",
        "    # Save the figure with a high DPI\n",
        "    fig.savefig(output_dir_path + \"lstm_gru_loss_plot_improved_with_border.png\", dpi=600)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcxjqgZg3A_n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "8c8c3fa4-35a8-43a7-f7bc-118c12f48302"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "loss_plot(lstm_loss.iloc[:, 1], gru_loss.iloc[:, 1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ygUTIh_3I_l"
      },
      "source": [
        "###  **Plot 2: Average Scores Plot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b4eAoTDGV6V"
      },
      "outputs": [],
      "source": [
        "#Read avg scores files\n",
        "\n",
        "lstm_avg_scores = read_df_from_file(output_dir_path+'multiple_lstm_models_average_scores.csv')\n",
        "gru_avg_scores = read_df_from_file(output_dir_path+'multiple_gru_models_average_scores.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUtbosB63FLo"
      },
      "outputs": [],
      "source": [
        "def avg_test_scores_plot(lstm_avg_scores, gru_avg_scores):\n",
        "  neurons = [8, 16, 32,  64,  128, 256]\n",
        "\n",
        "\n",
        "\n",
        "  fig = plt.figure(figsize = (20, 5))\n",
        "  plt.subplot(131)\n",
        "  plt.plot(lstm_avg_scores['layers'], lstm_avg_scores['rmse'],\n",
        "           '-o', linewidth = 2.5, color = 'indigo')\n",
        "  plt.plot(gru_avg_scores['layers'], gru_avg_scores['rmse'],\n",
        "           '-o', linewidth = 2.5, color = 'darkgreen')\n",
        "\n",
        "  plt.xticks([0,1,2,3,4,5], neurons)\n",
        "  plt.title(\"RMSE\")\n",
        "  plt.xlabel(\"Neurons\")\n",
        "  plt.ylabel(\"Avg. RMSE\")\n",
        "  plt.legend(['LSTM', 'GRU'],  loc = 'best')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "  plt.subplot(132)\n",
        "  plt.plot(lstm_avg_scores['layers'], lstm_avg_scores['mape'],\n",
        "           '-o', linewidth = 2.5, color = 'indigo')\n",
        "  plt.plot(gru_avg_scores['layers'], gru_avg_scores['mape'],\n",
        "           '-o', linewidth = 2.5, color = 'darkgreen')\n",
        "\n",
        "  plt.xticks([0,1,2,3,4,5], neurons)\n",
        "  plt.title(\"MAPE\")\n",
        "  plt.xlabel(\"Neurons\")\n",
        "  plt.ylabel(\"Avg. MAPE\")\n",
        "  plt.legend(['LSTM', 'GRU'],  loc = 'best')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "\n",
        "  plt.subplot(133)\n",
        "  plt.plot(lstm_avg_scores['layers'], lstm_avg_scores['R'],\n",
        "           '-o', linewidth = 2.5, color = 'indigo')\n",
        "  plt.plot(gru_avg_scores['layers'], gru_avg_scores['R'],\n",
        "           '-o', linewidth = 2.5, color = 'darkgreen')\n",
        "  plt.xticks([0,1,2,3,4,5], neurons)\n",
        "  plt.title(\"R\")\n",
        "  plt.xlabel(\"Neurons\")\n",
        "  plt.ylabel(\"Avg. R\")\n",
        "  plt.legend(['LSTM', 'GRU'],  loc = 'best')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "  fig.savefig(output_dir_path+\"multiple_avg_scores_plots.png\",dpi=600)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCavQPZg3d_g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "86eef48c-782f-4ed9-8c11-629a9a40c134"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x500 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "avg_test_scores_plot(lstm_avg_scores, gru_avg_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bD1p6kFq3i3z"
      },
      "source": [
        "###  **Plot 3: True Vs Predicted Plots in Train and Test Data(By best LSTM and GRU)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-CetXlEhG-Bm"
      },
      "outputs": [],
      "source": [
        "#Read true vs predicted values\n",
        "\n",
        "y_train = read_df_from_file(output_dir_path+ 'y_train.csv')\n",
        "y_test =  read_df_from_file(output_dir_path+ 'y_test.csv')\n",
        "lstm_train_pred = read_df_from_file(output_dir_path+ 'best_lstm_model_train_predictions.csv')\n",
        "lstm_test_pred = read_df_from_file(output_dir_path+ 'best_lstm_model_test_predictions.csv')\n",
        "gru_train_pred = read_df_from_file(output_dir_path+ 'best_gru_model_train_predictions.csv')\n",
        "gru_test_pred = read_df_from_file(output_dir_path + 'best_gru_model_test_predictions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOmF1fSTKrR3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJTkLnycKrLK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m9wEfk_VKwPu"
      },
      "outputs": [],
      "source": [
        "def best_model_true_vs_prediction_plot(y_train, y_test,\n",
        "                                       lstm_train_pred, lstm_test_pred,\n",
        "                                       gru_train_pred, gru_test_pred):\n",
        "\n",
        "    ##====== Visualizing true vs predicted plots for training data ========#\n",
        "    fig1 = plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot for LSTM on training data\n",
        "    plt.subplot(121)\n",
        "    plt.scatter(y_train, lstm_train_pred, marker=\"+\", color='mediumblue')\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "    plt.title(\"LSTM\")\n",
        "\n",
        "    # Adding y = x line for LSTM training data\n",
        "    min_lim = min(min(y_train), min(lstm_train_pred))\n",
        "    max_lim = max(max(y_train), max(lstm_train_pred))\n",
        "    min_max_pair = [min_lim, max_lim]\n",
        "    plt.plot(min_max_pair, min_max_pair,\n",
        "             linestyle='--', color='red', label='y = x')\n",
        "\n",
        "    plt.xlim(min_lim, max_lim)\n",
        "    plt.ylim(min_lim, max_lim)\n",
        "\n",
        "    plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "    plt.rcParams[\"axes.linewidth\"] = 2.75\n",
        "    plt.rc('xtick', labelsize=10)\n",
        "    plt.rc('ytick', labelsize=10)\n",
        "\n",
        "    # Plot for GRU on training data\n",
        "    plt.subplot(122)\n",
        "    plt.scatter(y_train, gru_train_pred, marker=\"+\", color='mediumblue')\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "    plt.title(\"GRU\")\n",
        "\n",
        "    # Adding y = x line for GRU training data\n",
        "    min_lim = min(min(y_train), min(gru_train_pred))\n",
        "    max_lim = max(max(y_train), max(gru_train_pred))\n",
        "    min_max_pair = [min_lim, max_lim]\n",
        "    plt.plot(min_max_pair, min_max_pair,\n",
        "             linestyle='--', color='red', label='y = x')\n",
        "\n",
        "    plt.xlim(min_lim, max_lim)\n",
        "    plt.ylim(min_lim, max_lim)\n",
        "\n",
        "    plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "    plt.rcParams[\"axes.linewidth\"] = 2.75\n",
        "    plt.rc('xtick', labelsize=10)\n",
        "    plt.rc('ytick', labelsize=10)\n",
        "\n",
        "    # Save the figure for training data\n",
        "    fig1.savefig(output_dir_path + \"true_vs_prediction_plot_train_data.png\", dpi=600)\n",
        "\n",
        "    ##====== Visualizing true vs predicted plots for test data ========#\n",
        "    fig2 = plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot for LSTM on test data\n",
        "    plt.subplot(121)\n",
        "    plt.scatter(y_test, lstm_test_pred, marker=\"+\", color='mediumblue')\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "    plt.title(\"LSTM\")\n",
        "\n",
        "    # Adding y = x line for LSTM test data\n",
        "    min_lim = min(min(y_test), min(lstm_test_pred))\n",
        "    max_lim = max(max(y_test), max(lstm_test_pred))\n",
        "    min_max_pair = [min_lim, max_lim]\n",
        "    plt.plot(min_max_pair, min_max_pair,\n",
        "             linestyle='--', color='red', label='y = x')\n",
        "\n",
        "    plt.xlim(min_lim, max_lim)\n",
        "    plt.ylim(min_lim, max_lim)\n",
        "\n",
        "    plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "    plt.rcParams[\"axes.linewidth\"] = 2.75\n",
        "    plt.rc('xtick', labelsize=10)\n",
        "    plt.rc('ytick', labelsize=10)\n",
        "\n",
        "    # Plot for GRU on test data\n",
        "    plt.subplot(122)\n",
        "    plt.scatter(y_test, gru_test_pred, marker=\"+\", color='mediumblue')\n",
        "    plt.xlabel(\"True\")\n",
        "    plt.ylabel(\"Predicted\")\n",
        "    plt.title(\"GRU\")\n",
        "\n",
        "    # Adding y = x line for GRU test data\n",
        "    min_lim = min(min(y_test), min(gru_test_pred))\n",
        "    max_lim = max(max(y_test), max(gru_test_pred))\n",
        "    min_max_pair = [min_lim, max_lim]\n",
        "    plt.plot(min_max_pair, min_max_pair,\n",
        "             linestyle='--', color='red', label='y = x')\n",
        "\n",
        "    plt.xlim(min_lim, max_lim)\n",
        "    plt.ylim(min_lim, max_lim)\n",
        "\n",
        "    plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "    plt.rcParams[\"axes.linewidth\"] = 2.75\n",
        "    plt.rc('xtick', labelsize=10)\n",
        "    plt.rc('ytick', labelsize=10)\n",
        "\n",
        "    # Save the figure for test data\n",
        "    fig2.savefig(output_dir_path + \"true_vs_prediction_plot_test_data.png\", dpi=600)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSb93RqfKqx8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hq-fq7OK2BV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "cfbf8d7d-ab35-4750-886a-2fc24510ea8e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA/UAAAGRCAYAAAAkQZOcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAADC20lEQVR4nOzdd3gU1frA8e+mQbKBSEmiiBACEgLBAFIEhagXQcXOvWIDVBTLD0XBiqggKlzF3q4Fu4JX7IqKFbACl6JBRDAEBDQJICW7gbT5/TGZzezubJ9tyft5Hh6ys7MzZzbZPfOe8h6LoigKQgghhBBCCCGEiDsJ0S6AEEIIIYQQQgghgiNBvRBCCCGEEEIIEackqBdCCCGEEEIIIeKUBPVCCCGEEEIIIUSckqBeCCGEEEIIIYSIUxLUCyGEEEIIIYQQcUqCeiGEEEIIIYQQIk5JUC+EEEIIIYQQQsQpCeqFEEIIIYQQQog4JUG9EEIIIYQQQggRpySoF0J49Pbbb5OXl8fPP//scZ/du3dz9913c/LJJ3PUUUcxePBg/vnPf3L//fdjs9n48ccfycvL8+uf/px5eXmsXLnS7XyKolBUVEReXh5XXHFF2K5dCCGEaM7++OMP7rrrLkaOHElhYSGFhYWceuqpzJw5k19//dWx32OPPeZUl/fq1YsTTzyRu+++m3379rkdNy8vj7vuusvwnJ988gl5eXn8+OOPYbsuIZqipGgXQAgRv/bs2cPo0aOprKxk9OjR5ObmsmfPHjZs2MD8+fM5//zz6dq1K/fdd5/T6x588EHS0tK48sorPR67RYsWfPjhh/Tv399p+/Lly/nrr79ISUkJyzUJIYQQzd1XX33F9ddfT2JiIqeffjo9evQgISGBkpISFi9ezPz58/niiy84/PDDHa+ZMWMGaWlpVFVV8f333/PKK6+wbt065s+fH8UrEaJ5kKBeCBG0hQsXsmPHDubPn0+/fv2cnqusrCQ5OZkWLVpw5plnOj337LPP0qZNG7ftekVFRXzyySdMnz6dpKTGr6oPP/yQXr16sWfPHlOvRQghhBCwdetWpkyZQocOHXjxxRfJyspyev6GG27g9ddfJyHBecDvyJEjadu2LQDnnXce119/PYsWLeKnn37iqKOOilj5hWiOZPi9ECJoW7duJTExkT59+rg9l56eTosWLYI+9qhRo9izZw/ffvutY1t1dTWffvopp59+etDHFUIIIYRnzz33HHa7ndmzZ7sF9ABJSUmMGzeOww47zOtxtJF2W7duDUs5hRCNJKgXQgTt8MMPp66ujvfeey8sx+7Tpw8fffSRY9vSpUvZv38/p556qunnE0IIIYQ69L5z584UFhaGdJxt27YB0Lp1azOKJYTwQoJ6IUTQRo8eTdu2bbnllls45ZRTuPPOO/nwww/Zv3+/Kcc//fTT+fzzzzlw4AAAH3zwAQMGDCA7O9uU4wshhBCiUWVlJeXl5Rx55JFuz+3bt4/du3c7/ml1s2bv3r3s3r2b7du389Zbb/H666/Ttm1bBgwYEKniC9FsSVAvhAha+/btee+99zjvvPPYt28fCxYsYOrUqQwePJgnnngCRVFCOv4pp5zCwYMH+eqrr6isrOTrr7+WofdCCCFEmFRWVgKQlpbm9tzYsWMZPHiw499rr73m9PzJJ5/M4MGDOfHEE5k2bRqdOnXi2WefJTU1NSJlF6I5k0R5QoiQZGVlMXPmTGbMmEFpaSnffPMNzz77LI8++ihZWVn861//CvrYbdu2ZfDgwXz44YccOHCAuro6Ro4caWLphRBCCKGxWq0A2O12t+fuuusubDYbO3fu5MYbb3R7/rHHHiM9PZ3du3fzyiuvsG3bNlq2bBlUOSwWS1CvE6K5kqBeCGEKi8VCly5d6NKlC8cffzwjRozg/fffDymoBzjttNO4/fbb2blzJ8OGDZO5eUIIIUSYtGrViszMTDZu3Oj2nDbHXpsr76p///6O7PcnnHACp59+OjfccANvv/22U6b8lJQUt6H7Gm17KIl2hWiOZPi9EMJ0RxxxBK1bt6aioiLkY5100kkkJCSwZs0aTjvtNBNKJ4QQQghPjj/+eLZs2cJPP/0U9DGsViuTJk1i/fr1fPzxx07PdejQgc2bNxu+TtveoUOHoM8tRHMkQb0QImhr1641HKL3008/sWfPHrp06RLyOaxWKzNmzOCaa67hxBNPDPl4QgghhPDssssuIzU1lWnTprFz50635/3Nl3P66adz6KGH8uyzzzptLyoqYu3atRQXFztt37dvHx988AH5+flkZmYGfwFCNEMy/F4I4dNbb73FsmXL3LZv27aNzz77jOHDh1NQUEBycjK///47b731Fi1atODKK6805fxnn322KccRQgghhHc5OTnMnTuXqVOncvLJJ3P66afTo0cPFEVh27ZtfPjhhyQkJHDooYd6PU5ycjLjxo3jvvvuY+nSpQwbNgyAiRMn8sknn3DRRRcxZswYcnNzKS8v55133qG8vJx77703EpcpRJMiQb0Qwqf58+cbbn/ttdc45JBD+OGHH/jyyy+prKykTZs2HHvssVxxxRX07NkzwiUVQgghRKiGDx/OBx98wPPPP8+3337LW2+9hcVioUOHDhQVFXH++efTo0cPn8cZM2YMTz31FM8++6wjqG/fvj1vvvkmjz32GB9//DG7du0iPT2dvn378tBDDznm7gsh/GdRQl1zSgghhBBCCCGEEFEhc+qFEEIIIYQQQog4JUG9EEIIIYQQQggRpySoF0IIIYQQQggh4pQE9UIIIYQQQgghRJySoF4IIYQQQgghhIhTsqSdF71796ampgaAhIQEDjnkkOgWSAghRLO3Z88e6uvrAXUd6J9//jnKJYpvUtcLIYSINYHW9RLUe1FTU4O24l9dXR27du2KcomEEEKIRlowKoIndb0QQohY5k9dL8PvhRBCCCGEEEKIOCU99V4kJCRQV1cHgMVioW3btlEukUpRFGpra0lKSsJisUS7OEGRa4i+eC8/yDXECrmGCNm3D6qq2J2YiNJQxoQEaZsPVazW9bEmLj4jcUze3/CT9zj85D02wYEDsG8fuxMSAqrrJaj34pBDDnEMw2vbti3fffddlEukstvtrF+/nvz8fNLS0qJdnKDINURfvJcf5BpihVxDhEyZAg8/zJCCAnYdPAgg879NEKt1fayJi89IHJP3N/zkPQ4/eY9N8PHHcOqpDOnRg10Nc+r9qeuliV8IIYSIRYqi9s5rZs+GZcsgPT16ZRJCCCGEufbubfz5lFPgq6+gTZuADiFBvRBCCBFrdu+Gc85RK/faWnVbixZw7LHRLZcQQgghzFFXB7NmQdeuUFrauP344wM+lAT1QgghRCxZuhQKC+Hdd2HFCli+PNolEkIIIYSZtm2Df/wD7rgDdu2C+fNDOpwE9UIIIUQsqK2FGTPghBPUyv7II+GHH2DIkGiXTAghhBBmef99tfF+yRKwWuHll+HWW0M6pCTKE0IIIaLtjz/gwgvVOfMA48fD44/L/HkhhBCiqThwAG68Ua3fAfr1gwUL1Eb8EElPvRBCCBFt48erAX2rVvDqq/DiixLQCyGEEE3Jww83BvRTpsB335kS0IME9UIIIUT0Pfmkmhhn9Wq1x14IIYQQTct118GIEbBoETzwgJoA1yQS1AshhBCR9ssv8OyzjY979FCXsOnaNXplEkIIIYR59u5Vs9vX1amPW7aETz9VV7YxmcypF0IIISJFUdRg/rrr4OBByM+H446LdqmEEEIIYaYffoDzz1eXqquvhzvvDOvppKdeCCGEiIS//4Zzz4UrroCqKjjpJNPm0gkhhBAiBtTXw+zZaoN9aSl06QInnxz200pPvRBCCBFu334LF1wAW7dCUpJa4U+ZAgnSti6EEEI0CTt2wLhx8MUX6uPzzoP//AcyMsJ+agnqhRBCiHC6/351/dm6OnXO/Pz5MGBAtEslhBBCCLN89ZU6Gm/nTkhLU7PcX3wxWCwROb0E9UIIIUQ4tWqlBvQXXqhmuW/dOtolEkIIIYSZsrKgshIKC9W153v0iOjpJagXQgghzLZvX2PwfsUV0L07nHhidMskhBBCCPPo6/peveDzz+Hoo9Us9xEmk/mEEEIIsxw4ANdco7bU79mjbrNYJKAXQgghmgpFgRdfhE6d4PvvG7cfe2xUAnqQoF4IIYQwx6+/wjHHqPPoSkvhww+jXSIhhBBCmGnfPnU63SWXqOvQP/10tEsESFAvhBBChEZRYN48dcjd2rWQmQkffQQXXRTtkgkhhBDCLMuXQ9++asLbxES45x61/o8BMqdeCCGECNbeveqc+TfeUB8PHw4vvwyHHRbdcgkhhBDCHPX1MHcu3HYb1NZC585qYD94cLRL5iA99UIIIUSwbr1VDeiTkmDOHPj0UwnohRBCiKbkvffg5pvVgP5f/4I1a2IqoAfpqRdCCCGCN2sWrFsH//63Op9eCCGEEE3LWWfB+eerSW8nTIjY2vOBkJ56IYQQwl9//gn336/Oowdo1w6WLJGAXgghhGgqqqvh3nvVpHigBvGvvw6XXRaTAT1IT70QQgjhn0WLYPx42LkTsrLUn4UQQgjRdGzapPbKr1ypjsR77bVol8gv0lMvhBBCeHPwIEyZAqNGqQF9YSEMGhTtUgkhhBDCTK+9pma3X7kS2rRR58/HCempF0IIITz57Te1xX7VKvXxtdeq8+dbtoxuuYQQQghhjv37YdIkdfUagGHD4NVX4YgjoluuAEhQL4QQQhj573/h0kvBZlPnzr/wApx+erRLJYQQQgizrF8PZ54JGzdCQgLccQdMn66uQx9HYiqof/rpp1m8eDElJSW0bNmSvn37csMNN5CbmwvAnj17eOyxx/jmm2/4888/adu2LcOHD2fy5Mm0atXKcZy8vDy3Yz/44IOMGjUqYtcihBAizrVrB3Y7HH+82mJ/+OHRLpEQQgghzNS+vdpTf8QR6vD7oUOjXaKgxFRQv3z5ci688EJ69+5NXV0dDz74IBMmTOCjjz4iLS2N8vJyysvLufnmm+nWrRvbt29nxowZlJeX8+ijjzoda/bs2QzV/VJat24d6csRQggRb/btg7Q09ed//AO++EIdhhdnLfZCCCGE8GDfPtBiw8xM+OgjyMmBtm2jWqxQxFRQP2/ePKfHc+bMYfDgwaxbt44BAwbQvXt3HnvsMcfznTp14rrrruPGG2+ktraWpKTGy2ndujWZmZkRK7sQQog4Vl9P9ksvkfraa7B8OXTtqm4/4YTolksIIYQQ5vn8cxg7FubOhQsvVLf16xfdMpkgprPf79+/H4CMjAyP+1RWVpKenu4U0APMnDmTQYMG8c9//pOFCxeiaGsKCyGEEHp//UWLM8+k42OPYdm9uzFRjhBCCCGahpoauOUWGDEC/voLHn8cmlB8GFM99Xr19fXce++99OvXj+7duxvus3v3bp588knGjBnjtP3aa6/lmGOOITU1lW+++YaZM2dit9sZN25c0OVRFAW73R70681UVVXl9H88kmuIvngvP8g1xIp4voaEzz6jxeWXk1hRQX2LFthnzyZh4kR1Ln2MkkZqIYQQIgAlJepKNsuXq4+vuAIefBAsluiWy0QxG9TPnDmTjRs38vrrrxs+X1lZyRVXXEHXrl2ZNGmS03P/93//5/i5Z8+eVFVVMW/evJCC+traWtavXx/068OhtLQ02kUImVxD9MV7+UGuIVbE0zVYamro8OSTHPrKKwDYu3Vj8733ciA3F379Ncql8662tjbaRRBCCCHiw4IFahC/bx8ccgg89xyMHh3tUpkuJoP6u+66i6+//ppXX32VQw891O35yspKLrvsMqxWK0888QTJyclej1dYWMiTTz5JdXU1KSkpQZUpKSmJ/Pz8oF5rtqqqKkpLS8nJySE1NTXaxQmKXEP0xXv5Qa4hVsTjNSQ99hgpDQF9zRVXUHX77Rz466+4uAbX6WZCCCGEMFBcrPbQAxx7LLz+OnTqFN0yhUlM3RkoisKsWbP47LPPeOWVVzjiiCPc9qmsrGTChAmkpKTw1FNP0aJFC5/HXb9+PRkZGUEH9AAWi4U0LSNyjEhNTY25MgVKriH64r38INcQK+LqGq6/Hr76Cq68kuSzziLVboe//oqLa7A0oeGCQgghRNgUFMDNN0NKirr+fBNuFI+pK5s5cyYffvghTz75JFarlYqKCgBatWpFy5Ytqays5NJLL6Wqqor777+fyspKKisrAWjbti2JiYl8+eWX7Nq1i8LCQlq0aMG3337L008/zaWXXhrNSxNCCBFNlZXw8MNq5Z6crFbwn3wS7VIJIYQQwiyKAk8+CaeeCl26qNvmzIlumSIkpoL6+fPnAzB27Fin7bNnz+acc85h3bp1rF27FoCTTjrJaZ8vvviCjh07kpSUxGuvvca9994LqMve3XLLLZx77rkRuAIhhBAxZ9UqOO882LgRqqrgnnuiXSIhhBBCmGnnTrj0UvjgAzjmGFi6VG3EbyZiKqjfsGGD1+cHDRrkc59hw4YxbNgwM4slhBAiHilKY+98TQ107AgnnxztUgkhhBDCTF99BRddBDt2qCPxLrigSQ+1N9K8rlYIIUTzUF4Ol1wCixapj88+W81427ZtdMslhBBCCHPU1sLMmeoIPEWBHj3UbPeFhdEuWcRJUC+EEKJp+e47dbmav/6CFi3goYfgyiub1Hq0QgghRLNWXq422H/3nfp4wgR45BGwWqNbriiRoF4IIUTT0q4d7N8PPXuqLfa9e0e7REIIIYQwU0aGmiendWt45hkYMybaJYoqCeqFEELEv/37oVUr9ee8PPj0U+jbF2J8eTohhBBC+MluV+fMJyWpI/H++19ITGzMdN+MJUS7AEIIIURIFiyAzp1hyZLGbcceKwG9EEII0VT89BP07w+zZjVu69ZNAvoGEtQLIYSITzabunzN+efD33+ra9MKIYQQoulQFHjiCRg4ENavh+efh8rKaJcq5khQL4QQIv6sWQNHHw0vvKAmwLv9dnjttWiXSgghhBBm2bVLTYY3aRIcPAijRsGqVZCeHu2SxRyZUy+EECJ+KAo89hjceCNUV8Phh8Orr8Lxx0e7ZEIIIYQwy9KlcOGFsG2bOo/+vvvg2mtlJRsPJKgXQggRPz7+GCZPVn8+4wyYNw/at49umYQQQghhnr//VnvlKyuhe3eYPx/69Yt2qWKaBPVCCCHixymnwNix6ty6//s/abEXQgghmpo2beDBB9U16B97TIbb+0Hm1AshhIhdtbXw73+rrfagBvEvvaTOr5OAXgghhGga3nlHDeI1l12m5s2RgN4vEtQLIYSITVu2QFER3HILXH65Op8eJJgXQgghmoqqKrj6ajjnHHU1mz171O1S1wdEht8LIYSIPW+9pbbS79kDrVvDP/8pFbwQQgjRlKxbB+edB8XF6uPzzoO0tOiWKU5JUC+EECJ22O1w/fXwzDPq40GD1AQ5XbpEt1xCCCGEMIeiwLPPwnXXqT312dnw8sswYkS0Sxa3JKgXQggRGzZtgjPPhF9+UXvlb7kFZs6E5ORol0wIIYQQZjhwAC66SB2RBzBypJorJzs7uuWKcxLUCyGEiA1t28K+fXDooera8//4R7RLJIQQQggztWgBdXWQlASzZ8OUKZAgad5CJUG9EEKI6Nm/X81sa7GoQf3778Phh0NWVrRLJoQQQggz1NXBwYPqfHmLBebNg5IS6N8/2iVrMqRZRAghRHQsXQo9e8KLLzZu69tXAnohhBCiqdi+HYYPhwkTGlexadtWAnqTSVAvhBAismprYcYMOOEE2LYNHnsM6uujXSoRIU8//TSjR4+mb9++DB48mKuvvpqSkhKnfQ4ePMjMmTMZNGgQffv25ZprrmHnzp1O++zYsYOJEydSWFjI4MGD+fe//01tbW0kL0UIIYQ3778PRx0FX38NH3yg9s6LsJCgXgghROT88QeceKKaAK++HsaPhyVLZD5dM7J8+XIuvPBC/vvf//LCCy9QW1vLhAkTsNvtjn3uvfdevvrqKx5++GFeeeUVysvLmTRpkuP5uro6rrjiCmpqaliwYAFz5szhnXfe4dFHH43GJQkhhNA7cACuvVZNfrt7tzoKb9Uq6No12iVrsuQuSgghRGS8+y4UFsKyZeo8+ldfVYfet2oV7ZKJCJo3bx7nnHMORx55JD169GDOnDns2LGDdevWAbB//37eeustbrnlFgYPHkxBQQH33nsvq1evZs2aNQB88803bNq0ifvvv5/8/HyKioqYPHkyr732GtXV1VG8OiGEaN5alJbS8vjj1VF4oCbC+/576N49quVq6iSoF0IIEX6//QajR8Pff6vz6NasgQsvjHapRAzYv38/ABkZGQAUFxdTU1PDkCFDHPt07dqVDh06OIL6NWvW0L17d9q3b+/Y57jjjqOyspJNmzZFrvBCCCEa1dXRbcoUEn7+GTIz4aOP4IEH1Iz3Iqwk+70QQojw694dbr0Vqqvh7rshJSXaJRIxoL6+nnvvvZd+/frRvaEXZ+fOnSQnJ9O6dWunfdu1a0dFRYVjH31ADzgea/sEQ1EUp2kAolFVVZXT/8Jc8v6Gn7zH4VdVXc2uW28l5403qH3uOTjsMJDv1KAoWlJBP0lQL4QQwnyKAs89pybD69ZN3TZrlrqUjRANZs6cycaNG3n99dejXRQAamtrWb9+fbSLEdNKS0ujXYQmTd7f8JP32FzWn38meedO9pxwgrphwAB+7t8f9uxR/4mgBJr4VYJ6IYQQ5vr7b5g4ERYuhKOPhu++U3vmJaAXOnfddRdff/01r776Koceeqhje/v27ampqWHfvn1OvfW7du0iMzPTsc9PP/3kdDwtO762TzCSkpLIz88P+vVNWVVVFaWlpeTk5JCamhrt4jQ58v6Gn7zHJquvJ+mBB0ieNQtSUzkwciT2Dh3U97hLF3mPQ5SUFFiYHlNB/dNPP83ixYspKSmhZcuW9O3blxtuuIHc3FzHPgcPHmTOnDksWrSI6upqjjvuOO68806nYXg7duxgxowZ/Pjjj6SlpXHWWWcxderUgN8cIYQQAfr2W7jgAti6FZKS4Lzz1P+FaKAoCrNmzeKzzz7jlVde4YgjjnB6vqCggOTkZL7//ntGjhwJQElJCTt27KBPnz4A9OnTh//85z/s2rWLdu3aAfDdd9+Rnp5ON21kSBAsFgtpaWlBv745SE1NlfcojOT9DT95j02wYweMGwdffKE+Pu00Ujt1QklOBuQ9NoMlwI6QmEqUJ8vcCCFEnKqrI+nf/4aiIjWg79pV7aG/4QZZrk44mTlzJu+//z4PPPAAVquViooKKioqOHDgAACtWrVi9OjRzJkzhx9++IHi4mKmTZtG3759HUH9cccdR7du3bjpppv49ddfWbZsGQ8//DAXXnghKZKvQQghwmfRInUlmy++gLQ0eP55eP11aEh2KqIjprpP5s2b5/R4zpw5DB48mHXr1jFgwADHMjdz585l8ODBgBrkn3rqqaxZs4Y+ffo4lrl54YUXaN++Pfn5+UyePJm5c+cyadIkqeyFEMJsu3bR/eqrSfnf/9THF14ITz4JLonOhACYP38+AGPHjnXaPnv2bM455xwApk2bRkJCAtdee63TqDxNYmIi//nPf5gxYwZjxowhNTWVs88+m2uvvTZyFyKEEM2JoqgN9Q8+qD4uLIQFC6BHj+iWSwAxFtS7CnSZmz59+nhc5mbGjBls2rSJnj17BlWWWMqI2xSyd8o1RF+8lx/kGmJFVVISLauqUKxWqh96iDptqboY+c70Rzz9HgLNiBtrNmzY4HOfFi1acOeddzoF8q4OP/xwnn32WTOLJoQQwhOLpXE63eTJMGcOtGwZ3TIJh5gN6mNtmZtYzIjbFLJ3yjVEX7yXH+QaosFSXY2SkOCo4FNmz8ZSW8vBzp0hxr4rAxEPv4dAM+IKIYQQQaushPR09edZs2DkSDjxxOiWSbiJ2aA+1pa5iaWMuE0he6dcQ/TFe/lBriFaLBs20OLKK6k76SRq7rpLvQaIq2twFU+/B0n6KoQQIuz27YP/+z/YuBGWLYPkZHUlGwnoY1JM3hnE4jI3sZgRtylklpRriL54Lz/INUSMosALL8A114DdTsJff5E8fTo0BMFxcQ0+xMM1BJoRVwghhAjIihVw/vnw+++QmKgG9RLMx7SYSkmsKAp33XUXn332GS+99JLXZW40Rsvc/Pbbb+zatcuxjxnL3AghRLO2d6+6VN2ECepc+X/8A9asgUMOiXbJhBBCCGGG+nqYOxeGDFED+k6dYMkSCejjQEz11M+cOZMPP/yQJ5980rHMDajL27Rs2dJpmZuMjAzS09O5++67PS5zc+ONN1JRUSHL3AghRCh+/FFtsd+8WW2xv/tuuOkmWapOCCGEaCrKymD8ePj0U/Xx6NHw7LPQpk10yyX8ElNBvSxzI4QQMWbfPjj5ZNizB3JyYP58OOaYaJdKCCGEEGa65BI1oE9NhUcegcsuUzPei7gQU0G9LHMjhBAxpnVrePhh+PhjePppaFhiVAghhBBNyMMPqw34zz0HQS4BLqJHxk4KIYRwtmgRLF3a+HjcOLWHXgJ6IYQQomnYtEkN4DXdu8O330pAH6ckqBdCCKE6eBCmTIFRo9SkeFrCUYtFhuAJIYQQTcVrr0HfvjBxInz9deN2qevjVkwNvxdCCBElv/2mJsNbtUp9PHo0WK3RLZMQQgghzLN/P0yaBC+/rD4eNgy6do1umYQppKdeCCGaM0WBl16Cfv3UgL5dO3j/fTVJTsuW0S6dEEIIIczwv//B0UerAX1CAsycCV9+CS5LiIv4JD31QgjRXFVXw6WXqsPwAI4/Hl59FQ4/PKrFEkIIIYSJnnwSrrsOamrUIP6112Do0GiXSphIeuqFEKK5Sk5WK3ht7fnPP5eAXgghhGhqWrRQ6/uzz4Y1aySgb4Kkp14IIZqT+no4cADS0tSEOE8/rbbeDx4c7ZIJIYQQwiyVlZCerv586aXQsSOMGCHJ8Joo6akXQojmoqwMTj0Vxo5V59IDHHKIBPRCCCFEU1FTA7feCgUFsHu3us1igZEjJaBvwiSoF0KI5mDxYigshE8/Vdeh//XXaJdICCGEEGbavFkdWj9nDmzZAm+9Fe0SiQiR4fdCCNGUVVfD9Olw//3q44ICWLAA8vOjWy4hhBBxy2arIz19rdv2srICsrOLo1Aif1mAptmofS6LeYa7ycDGHtK5nOksnHg0TFwV4ZLE/3tcWVmI1ZrI5s0HyM39xeM+gONzoL0mWiSoF0KIpur339W151esUB9ffTXMnQupqdEtlxBCCCFMkUYVj3A/l/EeAN9SyAXcw1YOi3LJRCRJUC+EEE1RfT2ceSasWwdt2sC8eWrWWyGEECJINlsdAKWlBw2f//77ykgWRwB38ySX8R71WLiHS5nJROokxAvJU0/9yRFHtGTv3lqP+/zvfzaOOCLF8dhmq3f8HI0ee/mNCyFEU5SQAE89BXfcAS+9BJ06RbtEQggh4pzRkHu9s84qjUxBhMMsLmMQxdzG1XzNgGgXp0m48cZyn/sUFW1yepyd/bPjZ0XpZ3qZfJFEeUII0VSsWgULFzY+HjoUvvxSAnohhBCiiWjH31zPq4C6is3fZHAsz0tA38xJT70QQsQ7RYGHH4abb4akJOjVqzERnixfI4QQwiRacrDS0oMUFLgnQ3v33RzprQ+j41nBq9zO4VSwDyvz0KbVSV1vpvvvz3IMv7/iih2G+yxZ0o0jjkhxJNIrK+uN1Rq9/nIJ6oUQIp6Vl8Mll6jL1AGcdhpkZ0e3TEIIIZokba5wTk4Lw+cHD06PZHGajURquZNnuI3nSUBhPTmsoFe0i9VkXXXVYY7s92Ac1B99tNXpsdWaINnvhRCRZ7PV07+/+7Ijsb8cjav4Xzol2Gs4keW8ynQOYxcHSOF6pvCfd/4J75QCpSaX0Zem+XvQlqjxtHyTt/2ivbyNEEKI+NeJP3md2zgWtW55jjOZzI3YkZVsRCMJ6oUQIg7N4kmmNbTYryOX87iXYo6MdrGEEEI0A1ZrosdkYNFIEuYPu93O+vXryc/PJy0tzbHdYvG+jntUr+eDD2DsWNi7F1q3hmee4bIxY7gseiXyytN7HK+6dGnp8/cfK3/vEtQL0cxoy9Fs2VJt+LwsRxMfFCABhf8wmilcT5W02IfFwoW7OPTQFJ/7/fJLFZ07pzgtaRPt5W2EEEL4puUJKC+vccyPLinpSVZWcjSLpWrVCvbtg2OOgddfhy5dol0iEaMkqBeimZHlaOJXGlWO4XYzmchS+vE5x0S5VE3bxRdv82u/gQN/c9sW7eVthBBCBMLi4ecIs9nA2jBf+/jjYfFiKCqC5BhoZBAxS5a0E0KIGJdGFc9yF0u5jBTUERZ1JElAL4QQQoQoPX0t6elryc1d59iWm7vOsT1iFAWefBJycuA3XUPx8OES0AufJKgXopmprCyksrKQFStyDJ9/913j7SI6CtnA/7iQy3iPvmzgRFZEu0jNyosvduSTT3L55JNcr/stX96dsrICSkp6OraVlfV2fN6EEEIIj3bvhtGj4f/+D3buhGeeiXaJRJyR4fdCNDPa3N7OnY3nCctyNLFCYRJvMJeHaUEN28nkImbxNQOiXbBm5Z//bOfIau9Nz56pbvtFe3kbIYQQvkV9Tv3SpXDhhbBtm9ojf999MHlyZM4tmgwJ6oUQIsa0ZQ/PcxdnsgSADxjKJdzJLtpEuWRCCCFEUxXhOfW1tXD33TBrFtTXw5FHwoIF0E9ysIjAxVRQv2LFCubNm0dxcTEVFRU88cQTDB8+3PF8Xl6e4etuvPFGLrtMXdzhxBNPZPv27U7PT506lYkTJ4av4ELEIas1gZUrFcNlR+IlqVdTWDrF8BrOOQfeWQIpKTB3LqdPmsROSxST9vjQZH8POt6WbwpmPyGEELHBaN68fn592L7Tn30WZs5Ufx4/Hh5/HNJltKQITkwF9Xa7nby8PEaPHs2kSZPcnv/mm2+cHi9dupTbbruNkSNHOm2/9tprOffccx2PrVoGSSFEs2Oz1Tkq7MrKwvgYDv3AA7B9Ozz9NPTpE+3SCCGEEMJsl10G77yjBvQXXhjt0og4F1NBfVFREUVFRR6fz8zMdHr8xRdfMGjQII444gin7Var1W1fIUTzpJ/jbLPVxWRQn/LnnyR+/z1ojZldusAPP0AM984LIYQQTUFlZSE2Wx3Z2cWObWVlvbFaTc4nXlUFjz4K11+vjsRLToZPP5W6XpgibrPf79y5kyVLlvDPf/7T7blnn32WQYMGcdZZZ/Hcc89RW1sbhRIKIaLJZqtr+KfotimO7bEi8Z13yL/gAlpcc426Fq1GKnkhhBAi7KzWRLcGfy3RqWkdAevWwcCBcMstMH1643ap64VJYqqnPhDvvPMOVquVESNGOG0fO3YsPXv2JCMjg9WrV/Pggw9SUVHBrbfeGtL5FEXBbreHdAyzVFVVOf0fj+Qaoi/eyw/eryE9/Ve3bfo5cjZbj/AVzB92O8k330yL558HoOboo6nt2BElRr5nAtHU/5ZijaIovncSQgjhk9bIb7PVG24POahXFHXu/HXXqT31WVnquvNCmCxug/q33nqL008/nRYtWjhtv+SSSxw/9+jRg+TkZO68806mTp1KSorxEl7+qK2tZf369UG/PhxKS0ujXYSQyTVEX7yXHzxdg/fW72h+nltu2kTutGkkl5SgWCz8dfHF7LjiCrXCj7HvmUA03b+l2CKjz4QQwhxGSfIAx1D8kHLx/P03TJwICxeqj0eOhJdeguzs4I4nhBdxGdSvXLmSzZs38/DDD/vct7CwkNraWrZt20Zubm7Q50xKSiI/Pz/o15upqqqK0tJScnJySE1NjXZxgiLXEH3xXn7wdQ3uPfV60fo8J770EilTpmA5cAAlO5t9Tz3Fjk6dmvDvIT7E0zUkJcVl1S2EEM3H//6nrmSzdSskJcHs2TBlCiTE7cxnEePi8s5g4cKF9OrVix49fA+fXb9+PQkJCbRr1y6kc1oslphbqik1NTXmyhQouYboi/fyg/E1VFYWAlBeXkNu7i8AlJT0JCsrGYC0tCglzEtPhwMH4NRTsbz4IslWK6xf32R/D/EmHq7BInMwhRDCFNq9gs1WT3b2zwAUF+dTULDesV0TUI99Rgbs3g1du8L8+TBggHmFFsJATAX1NpuNrVu3Oh5v27aN9evXk5GRQYcOHQCorKzkk08+4eabb3Z7/erVq1m7di3HHHMMVquV1atXM3v2bM444wwyMjIidh1CiOjTKl+rtU63LSE62e9tNtCW1hw7Ftq3h5NPVhPkxOEceiGEEKIpMLon0AJ6wBHogx/r1evr+m7dYNEiKCyE1q1NKasQ3sRUUF9cXMy4ceMcj2fPng3A2WefzZw5cwD46KOPUBSF0047ze31KSkpLFq0iMcff5zq6mo6duzIxRdf7DTPXgjRvOgrbFPmyAWithbuuQfmzYNVq9RgHuCUU8J/biGEEEJ4ZbPVeZxXH5APPoAJE+CNN+CEE9RtQ4eGflwRs/R/OxG7r/QipoL6QYMGsWHDBq/7jBkzhjFjxhg+16tXL/773/+Go2hCiDhltSaiKP3Mq7j99ccfcOGFsGyZ+nj+fLjmmsidX0RUrFXuQgjRnHj7DtY/p1XJRsrKCrBaE52G4peV9QYUsrOLsVhWuX+/HzgAN90Ejz2mPn7wwcagXogIkmwNQogmrby8GotllVNAb7PVh3e9+nffVYfcLVumzqF/9VUJ6IUQQsQNre60WFZRXl4d9HFstjrHccJW5wZBuwfQz5nPzi5uKGPjsqFep+39+iscc0xjQD9lSmOme9FkGf3thP2+0g8x1VMvhBBm04bcO28LYI5cIKqq4IYb4Mkn1cf9+8OCBWqiHNEkGa1xHHRiJSGEEAHx9B1ss9UZ1v9VVerzWVnel7JzPr5F97geFIWkV16kxQ2T1bw4mZnw4otw6qmhX5CIeUajPsN2XxkACeqFEE1SVFpLZ85sDOhvvBHuvhtSUiJfDhExsVq5CyFEMLRe+YqKxjq0oqIOm+2AYyUZf6YYhbPB09d0Ov13sKsRIyzAbz7PUVlZSHr6WrcgPzv7Z05gOV9ylbrhH/+AV16Bww7zq+xChIsE9UKIJsnX/HltGRtT3XorLFkCM2bAyJHmH18IIYQII6PebX02eH+Fq8EzUvlxvJ3jKwbwMqMYN/s4dT69rD3frBgtg1hW1hurNbp/BxLUCyGaJVOGRf/9Nzz/vDqPzmJR16X97jv1Z9EsxGrlLoQQ4RKtKUZGc5ZLSnphtVqoqKiloOBXv49VXNzD5/4lJT3Jzf0FC/VcwwJe5VRWlhxLVlYSKO9CuoRRzZHR33zUlkzWkb9GIUSTZBRsacrKCkI/wXffwfnnw9atkJoKV1+tbpeAvlmJ1cpdCCGCodWPW7bUMHCg8YpU/vS4a8epqKhz9PQXF+eTmRncd6OnHvrc3HVBHa+g4FcqKws9zr1Xj/0Lh1LBK9zBcJZzAivJzX0ARTk6qHMKEU4S1AshmiSjoEo/DzDoJcjq6mDOHLjzTvXnrl1hwADTyi2EEEJES1aWmgemoqI2pOP4Gsbva/i9ax0djiH3Wq9/WVmBYXlP4Rte4k4y2YONlrxPkellEPFLWzI5VkhQL4QQ/tq+HS66CL7+Wn184YVqYrzWraNaLBF9sVa5CyFEMLRAd9euxqD+k09y6d491dEr3lSmGHnqoU+hmtk8zhReA2AN3bG+/wZzBvVkTiQLKEQAJKgXQjRprsFW0Bl5Fy+GCy6AXbvAaoUnnoBx42S4vRBCCL8EPUIsgox6xE8+ucTpsT9TjIx6v0tKeqnz0b0wqqPLy2soLs4PKmFfoDrxJ29zA0ejzrd/lDHcxGQOnlEPqNcjDbgiFgUU1N96660Bn8BisXDvvfcG/DohhAiHoDPypqfDnj3Qt6+69nz37mEqoRDRJXW9EOZwDeKbg8agXHF7rrGnv8Bjo4DxvPlfTCyhZ0uWHMkZRftpx152ksElzOBDhkXk3EKEKqCg/scff3TbduDAAXbv3g1ARkYGAHv37gWgbdu2pKamhlpGIYSIDrsd0tLUn4cMgY8/hmHDoEWL6JZLiDCSul4I86nBrkX3OLIZ5F0TzQU7UsBXL7U/c9+zs4tN6+0uLu5BTk6LkObcp1JFFS0pKtoItOJs5vLZmsHMO6yjrGoi4kZAQf2XX37p9HjTpk1ceumlXHHFFYwfP562bdsCsHv3bl566SXeffddnnnmGfNKK4QQfvA2xNGvJcgUBV54AW65RZ0/37Onuv2kkyJSfiGiSep6IUJjNITcdSi6GWu2m811ubhwslhWUVZWQFZWSkhrzxcU/EpJSc+gy9GfdcxnGv9mPM9xDgBr6EFqt05O+8mqJiLWhdTkNGvWLIYNG8b111/vqORBbbW//vrrGTp0KLNmzQq5kEKIwNhsdVgsq7BYVkW0ko4HVmtiw78E3bYEx3b27lXnzk+YABUVaiI8IZoxs+v6FStWcOWVV3LccceRl5fH559/7vT8LbfcQl5entO/CRMmOO2zZ88epk6dSr9+/ejfvz/Tpk3DZrOFdqFCmCQ9fS3p6WvdllONBputjvLyan755YDT9vT0tWzefMDjPcLy5XlOj8vKCigrK3DcW7j+045TWVlIZWUhJSW9fJYtO7vYlPuUYIbnW6hnKi/zHZfQjW1M4TUSaUwOKAG8iDchJcpbu3YtI0eO9Ph8fn4+H330USinEEIIJ/oW/fLy7m7Pqf97ToLntUfgxx/Vtec3b4bERLj7brjpJpOvQIj4YnZdb7fbycvLY/To0UyaNMlwn6FDhzJ79mzH45SUFKfnb7jhBioqKnjhhReoqalh2rRp3HHHHTzwwAN+l0OIaCop6UlWVnLYz+OtB1wLhvUj2Bq5zom3GGxzpwXDWVn+l9FTFvpwyWIXL3EnJ/M9AAv5B5cznTpdWGSz1cmqJiKuhBTUZ2RksHTpUi644ALD55cuXUqrVq1COYUQIgBBZ3b347ixnrEXAk+C57iW+np17fnbb4faWsjJgfnz4Zhjwl1kIWKe2XV9UVERRUXe13tOSUkhMzPT8Lnff/+dZcuWsXDhQnr37g3A9OnTmThxIjfddBPZ2dl+l0WIcKisLMRmq3MKVktKemK3K44M7nZ7vVO9Gs2FVIzqzoEDf3N67GvUQXl5LVZrnWPUW6yOEjyJ73mFO8hmN3ZaMJkbeI6z0ec7gMagXoh4EVJQP2bMGB599FGuuuoqxo4dS6dO6vyTLVu28Morr7B06VKuueYaUwoqhPDNV1ALsR2Ue2Oz1bndJNls9VRVqf9r+ex8H8O9wSPplRdpoWX8HjMGnn4aGpKBCdHcRaOuX758OYMHD6Z169Ycc8wxXHfddbRp0waA1atX07p1a0dADzBkyBASEhL46aefOCmE3BeKomC320Muf1NUVVXl9L8wptUrdnu903bXIeIFBb86frbbq0hIOAjE7/urZbYH2Ly5G126bIpiaYx1ZgeLmEwSdfxMV8Ywh/XkGu6bnV3sGA0oCfL811y/J2y2erKy1Iaw8vLupvzNKIrvkTF6IQX1V199NdXV1cybN4+vv/7a6bnExEQmTpzI1VdfHcophBBRFK6ef9dzuI4CMNpm1GCh3jRYgN9QlH6OIYTl5bVONxga12NoDR6J9KZ25Eg491y45BJZe16EJF5Gtvgr0nX90KFDOemkk+jYsSN//PEHDz74IJdffjlvvPEGiYmJ7Ny502luP0BSUhIZGRlUVFSEdO7a2lrWrw//WtjxrLS0NNpFiGn9+wdef6xZswFtAQnz31//yrNsmUJVFYwYoe7/3nsKFguccUbg1xOLAT3AFjpwNxPI5G9u4DoO0NLr/lqQtnJlYMGVaH7fE2obhvpZ2bCh8fMcitraWt876YQU1ANcd911jBs3ju+++44dO3YAcPjhhzN48GC3SlcIEV5Gmd3VZDWKo5fAUy+CkaDXdDeZv8P4tOApN9d7Ft1kariGBTzOGKpJUefRffyxBPNCeBDJun7UqFGOn7VEecOHD3f03odTUlIS+fn5YT1HvKqqqqK0tJScnBxZwtCrX33v4kILpAF27uxs6vu7eXMtdns9vXqVeN2vX798ystrATUgP+qoIxt6G3/z+jrNp58ewciRf4RYWvOdz8f8j3x+IweAmUzE34YOjXwn+K+5fU9o99Tq/+pnp2PHIx099aH02CclBRamhxzUg5oB97TTTjPjUEKIEGhBbXl5jWOba4+1PihfuTIy5TJiNApAm5PnOjLA91y+7l6f1+vGVuYzjf6sZ9bldSgPPaQ+IQG9CFEkRrZEU7Tq+iOOOII2bdqwZcsWBg8eTPv27dm9e7fTPrW1tezdu9fjPHx/WSwW0vyZy9OMpaamynvkhbdlU12nkBkx+/3NzPRvuTir1XlpuLS0lqSl+f+dFWsBvRU7j/NvLuZDVpHHYF6kmhQCCei132Ug74NQNZfvCat1lds2/UiVUDq/LAHel4Yc1NfV1fHJJ5/w448/smvXLq699lry8vLYv38/33//Pf369aN9+/ahnkYIEQWNw9lrHD39ZmXsNbrJMBoy78+SQFlZvznWuwXjmyqAvY+vJf3ma0mwVbKLDKzDT6RlnAdaInbEysiWcIhmXf/XX3+xZ88eR8Det29f9u3bR3FxMQUFBQD88MMP1NfXc9RRR4WlDEL4y6jxzmiN85KSXo46r6ysNxbLQTZs2BCRMvoj0hnpzdSX9SxgGt3ZSh0JvMfx1AW4indZWUHcN8SK5iWkoH7fvn1cdtll/PTTT6SlpVFVVcVFF10EQFpaGnfffTdnnXUWU6ZMMaWwQgjvysurAbDbG+d/LV+eR1qaxZGUR+sxsNur2LrV+w2EVqFZrXW6be43J7EgO7vYETRp8/K1gCodG08yh9aTFgHwNUdzEbPYPiabylGS4VYIb8yu6202G1u3bnU83rZtG+vXrycjI4OMjAwef/xxRo4cSfv27fnjjz+4//776dy5M0OHDgWga9euDB06lNtvv52ZM2dSU1PDrFmzGDVqlGS+FzFNv0SaflqZ1ZqAxZJgyjxcjdHIoeLifEf2faChZ97iaFwIZr332KIwmfncxyOkUMsfZHMhd7OMwBtU5b5A+MPbyJxICymonzt3Lhs3bmTevHnk5+czZMgQx3OJiYmMHDmSJUuWSFAvRIQYtawPHOgcuGtBucXi+wun8aZA0W1THNv9rfSMEoeVlRW4lbekpBdWqwWbrT6omwujDPm92chb3MiR/IGSkEDNtDvoefVNbO8gybCEuWKpcjeT2XV9cXEx48aNczzW1qM/++yzmTFjBr/99hvvvvsu+/fvJysri2OPPZbJkyc7rVU/d+5cZs2axfjx40lISGDEiBFMnz7dpCsWInThWOM8kCScRiOH9AE9NIUgvlFr9vM6tzGKbwF4lyImcAe7OSTgYzWFBKciMvwdmRMJIQX1X3zxBWPHjuXYY4/l77//dns+JyeHd955J5RTCCGiyNcQ+WBuWPQ3Ja6yspJCWt/W6Lj7SSOL3WzhUC6ov4fv7u4Ddzfe2DSlOc8iumKpcjeT2XX9oEGDvA4znjdvns9jHHLIITzwwAN+n1OIWOMa9MtKiqGx05K27OMAKUzhep7iXwSaEE8TaMeFELEgpKB+//79dOzY0ePztbW11NUFd3MuhAhcWZk6v7Sios7RIl9cnE9mploxaXPOI8Vo+F9FheclOhr3D+17I5UqqlDHMZZyOKfxCMV0ZQ+t3fZtKnOehQgXqetFc+SrV9yfXnOzlrf0lFhWW+nF9dg2Wx1lZQXYbIpTQ7yWCK+p9NAnUYMFqCGZWpI5n3tpjY2fOTKk42qj/aTHXvgrHCNzAhVSUN+pUyfWrXNPbKX59ttv6dq1ayinEEIEoDFor3Zsy8xMDDqY99VI4Ivx8D/Py/2YkZjnJL7nJe7kYmawGHWY8Df0Dfm4QvgrFip3M0ldL0R0+ZtY1ttIOPU1TSOYB8hhO69zG9/Qh5u4DlDXoTdTevraJvVdLpq2kCb6/fOf/+Stt95i0aJFKIo659ZisVBdXc1DDz3EsmXLGDNmjN/HW7FiBVdeeSXHHXcceXl5fP75507P33LLLY41a7V/EyZMcNpnz549TJ06lX79+tG/f3+mTZuGzWYL5TJFE2ez1WGxrHL8C7WXuCnJzi4mO7vYaR5eQcF6x/ZYkkwN/+YRFjOJw9jFjbzitk9JSU8qKwspK+vt2FZW1pvKykLHfGghhDOz63ohYpmWm8V1acrG7d6f9/cYZt5zuJ6/qTuXxazhfAbzMxN4j3a4TwsSorkJqad+/PjxbNq0iSlTptC6tTqs9YYbbmDPnj3U1tYyZswY/vWvf/l9PLvdTl5eHqNHj2bSpEmG+wwdOtSRVAdwSpyjnb+iooIXXniBmpoapk2bxh133CFz70RcC3QIn/75aA4d87S0nCfFxT289uR7kssfzOc2BqL2XDzBv7ihoeVeLysr2e39aApznoUIJ7PreiFima+lKY24TuPydYxAG5ErKwsdjQRGve3+1K9NQRpVPML9XMZ7AHxLIRdwD7toE9JxXe89mkKCU9H8hBTUWywWx1I2n376KVu2bKG+vp5OnTpxyimnMGDAgICOV1RURFFRkdd9UlJSHGvVuvr9999ZtmwZCxcupHdvtSdu+vTpTJw4kZtuukmWuhFOjFrSQZ2npi3hFu15Vb6G0vkjPX1tUOXXt/jrKzx/16nXl10bxu9LMAH9BSziKebQGhu7ac0EbuddTnTap7i4B5mZSRK8CxEEs+t6IZo71x58ALu93tPuWK2JId8LxLtCNrCAW+nBFuqxcA+XMpOJ1IUWyhiuRy+N/SJQRvfrkY4dQvskNOjfvz/9+/c341A+LV++nMGDB9O6dWuOOeYYrrvuOtq0UVvoVq9eTevWrR0BPcCQIUNISEjgp59+4qSTTgr6vIqiYI+R1KRVVVVO/8ejWLiG9HTjANJonprdXuW2BFwkrsEoqVxFhQ27XS2La0uydnPg2lChf01W1m+O7cuWeS6//txVVQccP1ss1djttY7jlJd3N2zR1t+ghGuo/mDW8hq3A7CUvlzELP7gMLf9tMYCm60HABZL489wMKpZh2PhsxAquYbI0obAR1ok63ohosXfpSm9Pe/pGNrP+p51/c8rV5p9NU1DKlV8xtVksoftZHIRs/gacxoTrdZErNZEKisLm33DiTCXzVYXP0F9fn4+9913H6effrrh84sWLWLq1KmsX2/OetBDhw7lpJNOomPHjvzxxx88+OCDXH755bzxxhskJiayc+dO2rZt6/SapKQkMjIyqKioCOnctbW1pl2HWUpLS6NdhJBF9xr8X+rkhx820NB2RGqq83PhuAYtrhg61L2MXbpscvy8cqXzzX3//sbXpL1m8WIF1+t2Lb927t27cey7evVmx88//bSx4T1QH2/YsIHUVHX/ESOCWz4mWN9TyPOcwRYO4x4u9dlib7X+yrJlitvvMBbI5zk2xMM11NZ6XkEiHCJd1wsRTb6WpjTqkTPq2XUPEKPTGNcUVJHKdUxlDJ9xKXd4HG5fXJzvlAPIFy2/jhZ8SVI8EShtVGt5eY3bcxUVdY6Rv5EI7kMK6n31FtTV1WGxmHeTP2rUKMfPWqK84cOHO3rvwykpKYn8/PywnsNfVVVVlJaWkpOTQ2osRid+iIVrKC+vx2arx26vp1evEq/7nnFG49+x1sMbzmuwWv0bhu7+N+n9da5Bt9ZosHlzN7Kykjyee+LExtedeabxMVasyAFKfRc6JApXspCFDGdnQ6U+gTsIpIEmLy8vpubKxcJnIVRyDZGVlGTKIDu/RbquF6IpstnqKSnpZTgasKysAIulmq1bN0ShZLGpiJUoWFjK0QC8zqm8zikY1fclJT2DqtdlSVvhylsOK6PnvI3u0DcwReLvK+Q7A08VeWVlJd98841jaHw4HHHEEbRp04YtW7YwePBg2rdvz261e9GhtraWvXv3epyH7y+LxUJaWlpIxzBbampqzJUpUNG8hrQ0yMwMfE101/JG6xrKygpQlESnL5xgh4916bIp5C+cAQNKQ3q9L+35mxe5k1F8yyi+4XQeRq3cAwsmFKUFiqJNX4idOXPyeY4N8XAN0Qigo1nXCxENrj23RmvFuw6799Zr5205Oas10W2Kn2sA0VyGhydSy508w208z1+0o5AFjkZ8T/V9ly4tsVhWRa6QollwHZXjmh+qvLza9SVRFXBQ//jjj/PEE08AaiV/4403cuONNxruqygKY8eODa2EXvz111/s2bPHEbD37duXffv2UVxcTEGB+sb/8MMP1NfXc9RRR4WtHEKYzZ/KW5unrr/pCCVILS+vjrll6jQnsJxXuZ0O7OQAKSzi2KCPJS3zQvgWS3W9ENHiK1mtP1nv/TtPPRZLPZ5SethsdTFbP5upE3/yGrdxHOr7+DHHYqel19f4m4jX+LWS5V6otOTZ+s+Z62fOZlN0P9e75a/ydXzAcBqP1uvvui1QAQf1vXv35oILLkBRFF5//XWOPfZYcnJynPaxWCykpqbSq1cvRowY4fexbTYbW7dudTzetm0b69evJyMjg4yMDB5//HFGjhxJ+/bt+eOPP7j//vvp3LkzQ4cOBaBr164MHTqU22+/nZkzZ1JTU8OsWbMYNWqUZL4XHrm2xsdCa28gwbnFssrpCyFYsXjDkEQNM3maW3iRBBR+oQtjmE0xR0a7aEL4JdDlKGNFOOt6IYSzxsYBC5s315KZ6brGvTnz8Zcs6UZR0SbfO0bBOXzBc8yiDfvZi5UruI03GOn1Nfp7t0CX0AXJci8a+dMgp5864/o3tmTJkRQVbfR5/LKygrDdbwcc1OuXnauqqmLMmDH06dPHlMIUFxczbtw4x2NtPfqzzz6bGTNm8Ntvv/Huu++yf/9+srKyOPbYY5k8ebLTWvVz585l1qxZjB8/noSEBEaMGMH06dNNKZ9oHrSKoby81vEBLinp5ZhzHslyeGqd1+aP6Z8zY/m7WNKBchZyE4NRvzif4WyuYypVhDbfWVrmhfAtnHW9ELHOaKi9Vu/abIrj3sAo673NVseWLdUMHPgbwdAnw9Xog4ni4ny2bTvIySd7zwVkJBYD+kRqeYJ/cwVvA/ADBVzAPWymY0DH8Sc437y5Gxs3box4Ul8R20LpENN4C+idz+Xeu68tpe261GV9fWCNeSFFKVrQbZZBgwaxYYPnJCHz5s3zeYxDDjmEBx54wMxiiWbAqDctK6vx+aysyK9xri2zYtSqp95E6JP31ZvypRRL9pNGFrvZQzqXM52FBL8kpZ60zItIMAoK9D/H09+g2XW9ELHOqIHcaE68FtBHohdO4yu7+/Ll3YNuUIiGOhJphY16LPyb8dzBldSSHJZzWa0JtG2rJjyO9dwpInLC3SGmX5XB6HvEKHlmdvbP5ObWEkhe3JC6q1555RUmTJjg8fnLLruM119/PZRTCNGseQrUs7OL3da59ZaEJ1605ADasj/7Secc5tKH+aYF9EJESnr6WtLT17p9TrXt8UTqeiH8E8gc23DxFNAvWNA54GMtX96d5cvzQi2SAaWhvgewcCXT+AdPMY1rAgroLZZVTvdJ2s/aUnWgjrAQItyWLDmSsrKChiTW/ZxyPQSyzGIoQgrq33zzTbp27erx+W7duvHf//43lFMIEVZaYgzX3jStYlCUfo6kda6VR7jLZbGsaggKwj/Xffny7mE/hy9H8RuruJCredOx7Se6s4UOpp1DUfrFVQ+pELFA6nrR3GjZ5vXBIag98ZWVhY57A3AO5GO5cf2887YE/JqBA39j4EBzl9lrw17e4kYWMA19I/7XDAj52EaNqfrfiUy9E0a0z3tJSa+gj1FUtJGsrBSyslJ872ygpKRnyA1QIf11//HHH14r+tzcXKfEd0LEmqbUmxaK6A7VU/g/3uBHxpNPKVN4lWTclwMyg9aII0S4GQUFZWW9HdvjidT1ornRpr+5BoHadjC+fxDeHcdq1nA+5/AVp/AtR+HfPGRvtI4YqdtFsLTPdai5s2y2OsrLqxv+FgPL25Cb+0vIjU4hvTo5OZmKigqPz5eXl5OQIK1iIn556sUPV+VhNHLAH+qQn95u24uLe5hVtLBoyx7eZSqPcx8tqeZ9hjGIl6gJ03y65tZYI6LHKCjQ8jnE22gRqetFc2RU15txD2BGj1yseffdHK/PJ1DHHTzD10ykE2X8RieO4UV+IvRRgvqOGE+NqdpQaKv1V4/LBgoRKm10rRmNfSUlPcnMDKyRIaQmicLCQt555x0uvvhi0tPTnZ7bv38/b7/9NoWF8dUjIZoXoyVQtGy2RgGg/kNqs5kfMAcbcHoKEgL9QoikIlbyKrfTkXIOkswNXMfjjCHQ1k0hRHhJXS+aI6P62Ixe+ays5LhsXC4p6elxesFZZ5V6fF1H/uJVbqcIdbngFzmNa7iJSqyml9HoXkiG3At/uS5xrSkvrw7bVFhtVQ1V4/1vMI3/Id3xT5o0iYsuuoizzjqL8ePH061bNwA2btzISy+9REVFhWSiFzFN+9A4t7orYelJC8d61fr16Y1uEmIhaY+Rw6jgUybRghp+pTPnMZu1hCMZTyNZyk5Eg6ebhHgidb0QIrgGd4V3uIH+rGc/aVzJrbzOqaaWylfd7joUuqpKvTdSlLq4GzUloiMrKwVF6YfFssrnvtqoEH8bAVyXp9YEk/0+5J76//znP9xxxx3cc889WCzqh0ZRFDp27MhTTz1F3759QzmFEFHjrRdfddDnMfTBtj4TZiDn9MZXhRSrSXv+JJOZTKQr27iWG7GHuPa8P2QpOyGCI3W9aI78WZ5u+fK8gBPJacPE4623Xr/slno/Y/HjPsXCNdzEAzzEOO7id44IQ8ncO2K0xlSLZZXb71Bdo17NIxTvDa4i9qgdbf53qJk5AiDksbnHHnssn332Gb/88osjUU6nTp3o1auXo+IXIlY19tDr/1Ytju3uFUVjYGi3B3Yu/Qe3vLyGrCztmI3nMAo6vVWe5eXVAFRU1AZWmCg4my/ZQGd+QU24NZtLCPdQ+0isGSxEcyB1vTBTOEaumc2fMgWbGd5qTaSyshCbrS4u66isrBTH/YerfErIZzNv8w8AfuAojuV5fNX36jDkxICnOGRnF0twLiLCn8Y4fxvrli/v7pakWr+efVlZb848M5ndu/0vnykTbhMSEigoKKCgwHdPpBCxxNecuWArCq1RwFNrnb4H3dc5XG8s9IFqPNwMpFLFgzzElbzFz3RlIC9zgJaEM6AvKytwJCSTyl4Ic0hdL5oDrf4uLTUOWkOljcjz1mjgbf66L4EO/w3U8uXdsdnqDDoTFC7jHR5hLhagPzmORnx/6vvc3F9MXxnEaPTj4sUKffrkkZYW/hGComnx1hgXaCeS0apT+vXsrdYEAm0vDyioX7FiBQADBgxweuyLtr8Q8SiYwDCUYXVGPRj6FvF46JXX9GITC5hGAb9Tj4UPGUot/vXIhHJTE48ZxkV8i4eeR39JXS/CxajBW/9zLHxuwj0s3tfoPAht6pxrYPHJJ105+eTfgz6eK6NgJIP9PMPdnMvnAHzKMewiI+BjB/LeawnGsrOLHXOdXb97jd7f1FQ1YEpLi/7fmog/Wh4rdxZTG9TS09dyzDGBvSagoH7s2LFYLBbWrl1LSkqK47EniqJgsVhYv369x32ECJYZN9G+582H/2ZdP9TfU8I7/TkLCn419fzhoXAlC3mQh0jlIH/SjrHM4gsG+X2EYJPaxXtAJZqWeAz2pa4X4RKu0XHxoLi4Bzk5LSJ+XjMDeiODWcvr3EYOf1JDItOYxANchOLnqtklJT3JykoOeCpCbu4vHpcGdP3eFcJMnhLbmSGUaaMBBfUvv/wyACkpKU6PhYhVvm6oPS1/EuqNdyBJcLztV15eC9TEbMI7I1bsvMwdnMNXACziWC5mBhW09ev12tD5QDP3x0vAJJoWXz2P8UjqehFN+uWjysoKyMpKCct5It3gVlDwq2GjhRZ0VlTY6NJlE6B2LpgVJITTzbzA3TxFEnX8zuGcx2xW0ivg49hsdW7fm8XF+YDitSPD9d6ovLwWq9W9F1UbcWm326XxUYRdsIH5kiXd0E9VURQloNcHFNQPHDjQ62MhIsHM4Xueesb9OY+3uS7avJvS0oMh9azrs83GiwOk0J49VJPEzVzLI5zvd4t9sBmBN2/uJgG9MJW/N/y+eh7Lynrrjhlbw4w9kbpehIun0XGgOIZRe+p9DZW33ttoZqJvTL7bWE9q701xcY+YHp3XghqSqOM1TuYqbmU/6QEfw1OnhX5+sf/Hcr9n8ve+TQh/6Ifel5T0cvzN6Uf5ao1I3mIMI0VFm5weV1REcEk7IaLBn+F7+pZ+ja8batcbd1/nsdl6eC2n1ZoYlaF20ZBAHYnUU0MydSRxIXeTxd+sIt+v1+sT2wWjS5dNTXrYpohf+u+M5jLMWAhPPI2O09u5s/GmuaKiDlBzynjqsTcK1n01yLmuXR6rYjGgb8mBhmS3cA+X8j968BFDidX3M5D7NiECYbVadD9Hf9nkgIL6W2+9NeATWCwW7r333oBfJ0QofM130fcWaGy2esrLzR3qbrUmNvll1TryF69yO2s5ksncBMA2DmUbhwZ0HO3L0KgnR4hIsdnqUZS6hqkvKm1Ip/Y51gcKRn+voSR5jAVS14tIcg2w9cvE6XtrjRrCXHvCjOZlG426873+fPeGsrgnhQsHm62OrCz1XOvW5dKrV0lEzhuIFhzkPh5hKGsYzAscpAV1JPERw8JyPv3yXkJEWyBT7fTfS/oppYHe02ZmJvH33/7vH1BQ/+OPP7ptO3DgALsbFtHLyFAzXe7duxeAtm3bkpoqS0YIc3lLbqfOyzLKSunMVy88OGdW1dM+oHDQ4/EDHXITr87ga57nLtqxl75sYDaX8BeZAR8nO7vYbZkfT7/HJUuOpKhoI6AOu9+2bSN5eXlBXoEQzrQbaz3XIZ36z7Zxro7GnkejAF/LkBurpK4X4aYNT7VYVgXU6O16s+zKdXWYYBuHzQ7mly/vTufOKdhsdW5JcV2nAsRiQJ/HZhYwjT6o78spfMu7nBjmswY2nxiMAyjn5Mee79uE8Mbonl5ft3vqpQ/k+01/fwt4TVBrJKCg/ssvv3R6vGnTJi699FKuuOIKxo8fT9u2aiKs3bt389JLL/Huu+/yzDPPBFQgIXzxltzOVyDtOjTPG089bTZbfVCJ3JqSlhzgfh5hEv8FYAU9OZ97gwroNdrvROuN8fRFqP/Cs1oTHMvTCBErbDb9zahxpawtwaTxNm8/0pmcpa4XscZonr1RHeE6XD1WRnvpGwlcRxxEayqAr0R06ijDn7mE93mM+7BygAoOYTwz+Zjj3PZXf0cWRyOo83zjwEcsBjP1wGgan35YtN0e8CGF8JtRb34g2rULbfh+SHPqZ82axbBhw7j++uudtrdt25brr7+eXbt2MWvWLF588cVQTiOEacwY4q0P9pcto+E4jTfd8T701pd8SljArRyFmtDjfsZyG/9HDckRL0tW1m+O34EQ0WDcer/O8GeNc9AfuAAT4oZM6noRLv4HexbKy6ubRGO6a6b3aE3P8zW03Vpbyevcxvl8CsDnDGQsd3lsvHefU+y7cdMssvqNCDd/lsAOdYSuviGrrKw3Z54Z2OtDCurXrl3LyJEjPT6fn5/PRx99FMophPBIG76n5y1Y1w/V04a/BTO8y5emHNCnUM1nXM3hVFBGW8Yxk8UMMe34+t+Rr2kWTTlPgWjajAJ9o3n74D5HWJ3zH9moXup6ES7+BmKhrgQT7Moq4RAr5fCmuLgHLa6bwPl8Si2JTOcq7mO815Vs9NPowPleKNwjJsrLa7Ba6xw99Ub3h0KEIlxLYHuSnf0zubk1AWW/D2nMakZGBkuXLvX4/NKlS2nVqlUopxAiII1f6I1/2pWVhShKP7fMuenpa0MODIcOtVBaWk1paWzO01KH1+kfh5b5tZoUrmMqn3IMhcw3NaAH5y/NxmF0jQFM4zz7xlb/qio10PEnl4IQvpSXdw96iPuSJUcGfd7c3HVu30dG31HZ2T+7zRsON6nrhdm0/Ddm97y71nHasP309LWO5He+XiPUHsOub15ETe8+HMc8/s0lfi1NG63e8tzcX8jOLo6LBhMR22y2OiyWVVgsqygvr3b87OkeU7+/v/lyysoKqKwspKSkl5lFD62nfsyYMTz66KNcddVVjB07lk6dOgGwZcsWXnnlFZYuXco111xjSkGFMOLvWtKuievMnJcai0ltNPrhdY0J/gIzmLWkcpAvUdeqXshJLGQ44RhO52vZQaNRECNGWKAheY+0zItQWa0JpKUFd2Oqz/egV1lZGPBUH332/WiTul6YLdDgy2j+txaw6+uFzEzn21r9c56S32nHdF0Tfvny7qYlzHOtf11HoIES9dFnh1LBKL5hHmcDsJXDSPn5OQKp6222Oo+j7LQGeptNMZx3L0Q80I8CcY0t/LnHdo4/nEfd6b+D1OH3yTTkp/VLSEH91VdfTXV1NfPmzePrr792ei4xMZGJEydy9dVXh3IKIfyWnr7WEdi7Dr1ybWFrbq25wQw9TKCOW3iRmTzNblpzFAsoo33DsxbefTeHs84qNXyt682Rv4yWHYzVtW9F02bmUpSuFb0/wUIs3ehKXS+izWj+t2sjb6iN9a51VlqaOQlYfc33joVEryfzLS9xJ1n8zXay+IRjG54JrP5NT19r2LiuH6asvx/LyvI/DFm+PM+x3KH+Z2hcrUjm1YtgaaOH9PV+RUXj36q65LVzwlrX2MJmq6ekpCd2e73T94k+q723e3H9a6zWBAJMfh9aUA9w3XXXMW7cOL777jt27NgBwOGHH87gwYMdGXKFMJunDJPadn3lof6LcGapGBPoEMcOlPMKt3MiKwH4jEHYaem0T8uWxjciZgVD/jZCLF6s0KdPHmlpsqSWME9WVgqK0i/o5SlLSnp5vGGN1NrXZpK6XpjJqDc32HXJXYNIs+qgYBqmly/vTs+eqV7zvrh+p0QzR0wK1dzL40zlNQDWciSldPC4v5mjFzTqSCbf74E+iNf/DJCVlSwBvQiJUT2v/z7SNyJ6+nv1NBrP0yg+s4Uc1IOaAfe0004z41BC+MXTTXa0h6/FqkCG/Y5iKS8yg/bspZJU/o+beZnTcG2xP/lk42kH/v4OtHV7wWKYSdTfQEpb0i7YIdNC+CuQES+5uesMh+gFGnC4rqZRVlbAGWck8fffARTcJFLXC7MYBWCZmZ6/w42G2oNzclWjnrZIGzjwNxSln9+J2lxHFyxerHDkkUdisyX73cDh6ztF68V23acbW1nArRyN2njxKGO4ickcpIXHY/kK6PXX4+k9MNouAbmIpkBzMkXiOyaYz0TIQX1dXR2ffPIJP/74I7t27eLaa68lLy+P/fv38/3339OvXz/at2/v+0DAihUrmDdvHsXFxVRUVPDEE08wfPhwAGpqanj44YdZunQpf/zxB+np6QwZMoSpU6eSnZ3tOMaJJ57I9u3bnY47depUJk6cGOqlimZGGzIXbE9drPK05J6Feh7iASazAIBV5HEes9lI54DPod1oefvi025+9F+m+uFzkv1exALXG1Dt79KM7wRv01SMcmBo30mWQMfkmcDMul40b66NXI3bPY8o87yqjMVRh8RKPW00YtD5ehs/v0ZlDrSROju72HFcowZ8rRdb3yg5hk95lrtphZ2dZHAJM/iQYX6f05Ngg3Obrc7w3kRrzFEb+407AKRBQIQqVr47NMFOJQopqN+3bx+XXXYZP/30E2lpaVRVVXHRRRcBkJaWxt13381ZZ53FlClT/Dqe3W4nLy+P0aNHM2nSJKfnDhw4wC+//MJVV11Fjx492LdvH/fccw9XXXUVb7/9ttO+1157Leeee67jsdVqDeUyRQzyt7dLzSypsHNnbdBDxrTKMN4CSU/D5DzN31NIoDU2AB7iAm7hGqpJMdzXG7OWDvK2fIgWaNntdtavD3y4phDB0v4uPTWOaYqLe1BeXt3wqPEmXj9Hz9vwXu27Rh/0aHlDIh3Tm13XC6HRf88HsxxsuJdKC4ZW/xn1Uvu6h9Anfg2Et+Ma1aWPPtyBVtfZ+ZqjOeTD1/nwtEq/zqP1+uuT3UHwiXg1nu4ZtL8J1yBH5s+LpizYv+2Qgvq5c+eyceNG5s2bR35+PkOGNC5vlZiYyMiRI1myZInfFX1RURFFRUWGz7Vq1YoXXnjBadvtt9/Ov/71L3bs2EGHDo1zgKxWK5mZmUFckYgX/gbXoSSbKi+vJStL/dnXByyUeWbacjrBzN/zxnN5LFRWFlJRYaNLl4205CAHGubLX8NNzGcknzE44PMFUqn7M0RPiFiWlZXs9XlPn2d/htTqGwxce9iiwey6XjRPRrlwzFzSTmt8dw04o8VT7p9olMNqTcSaUK2bElTIGdft5iOOY1PPToD3Bkrt+0zr9dePsPOVCFCIWGc0MhR8N957O56aWE997ZIl3Sgq2uS0j9GKHqE2joWUcvOLL75g7NixHHvssYbDAXNyctyGwpupsrISi8VC69atnbY/++yzDBo0iLPOOovnnnuO2trYWRpIxI/c3HWkp6913ExrN9dGQkkcU1Dwq+kBvTfZ2T+Tnr6Wwi6r2TViGnv+MZOSTWrDgo20oAJ60K8r38hoDU7tS8vfLy4t6NfmKQoRC7x9H4RKfxNRXl7jtLydzVaPEuG8n9Gu60XToNWn+ptm1xvoUI+v1i3uf6PRWIve6HqjoVX6apg7F/LyoLzcsf0DiqgnkaysZBSln8fvM9dlAsOhsrKQysrChqXvVGrQo9IaRiorC+VeQJhKmx6j3us3Vq6VlYV06dLScf/pS0lJT8ffsdWa6NTw7xrQg9rAr7/3r6wsJCsrJaS/7ZA+qfv376djx44en6+traWuLrDkA/46ePAgc+fOZdSoUaSnpzu2jx07lp49e5KRkcHq1at58MEHqaio4NZbbw3pfIqiYLfbQy22Kaqqqpz+j0ehXsPmzd0A2LmzlgEDSs0qlkfa7z4KU1mDsnRpZ4YN2+Lx+YH8zHxuo+3i7dSSyIFvvgXaBX2+detyqaiwYbcnOPVKGP1+LZZq7HZzGtrksxAbmus12O3+9cCtW5dLr17GiSV9ce0lyM7+mdzcGpLCf5/tEM26XjQfvnrEysoK3HrhjZLAGY3ki1TD+fLleXTunOyxHJGWxS5e4k648XsAbs6+m/u42BF8aMGMFogoSj/Ky6udpv9oK4HohTrCTp9nwFNPv35Uk75hREb2iWgwmvZbUtLL8X0UCyswhHRb0KlTJ9at8zzE6dtvv6Vr166hnMJQTU0NkydPRlEUZs6c6fTcJZdc4vi5R48eJCcnc+eddzJ16lRSUgKfH6ypra2Nubm7paWl0S5CyIK9hv79wx9dv/eegrZSk/53v2yZ+n9VlTb/Dd54Q2HMmNiJ+A8cKMVofVkL9dzES8ziKZKpo5TDOJ97+eHi4AN6wGPAYrR9w4YNpKaq79/QoWoZly1TW0f1j1MDWKGuOX8WYklzuQYt7lf/V/9m339foaoKx/eA9v0xdKgl6IA+VkSrrhdNi7fkp+A7WZV6w+zceOTasBbthFf6pdaMrtef4bzr1uXSvn1ayI0Cf7/xFxmTLsFSUQ4tW3Lwvoe479oBPl9nFMQL0dQYTwfyPAzOaJlbo1FBGq3hS38eo+89wK1xLVghBfX//Oc/mTt3LoMGDeKYY44BwGKxUF1dzRNPPMGyZcu46667QjmFm5qaGq677jp27NjBSy+95NRLb6SwsJDa2lq2bdtGbm5u0OdNSkoiPz/f944RUFVVRWlpKTk5OaQGEvn4YLPVk5WlDiMvL+8O4PTYU4K1YIR+DeFvdR88OM/rNe/caQP+AIipgB4aGxv0DqWCl7mTk/gRgDc4iSu4jb20imjZ8vLyGhLt1KMlBMrLy2t49jenfcD971L/OwnXZyGS5BpiQyDXYLW6f/+ccYbzZ+6oo45sWKc+tO+qTz89grZtEx0jkjZv7sZ550V2Sbto1PWi6fGW/BQ8z2sFtZfMeB1pz5+vYOfDmsXT9foSTCOgft57MjXczZMcMuZlAOp7FnDgxdeo7JwP16rvqzqlpzGA0Qc24ext9JVXQT+tyVsQJESojL5PAs3F4c+IFV/fe4Eup+dNSEH9+PHj2bRpE1OmTHHMa7/hhhvYs2cPtbW1jBkzhn/961+mFBQaA/otW7bw8ssv06ZNG5+vWb9+PQkJCbRrF1pPpMViIS0tLaRjmC01NdXUMilK4x9WWprzTW1aWmpY1gHXX4O34Viuz0UiIY6va05NjW7ym8AoLORmjmUtdlpwDTfxPGdi1JvvSVlZb7/mBrreSLkmA6msTEJREpxaRCsrk5zKoigtUBS1Atf/iXv6nZj9WYgGuYbYYNY1ZGZaSUtrvEEtL68N6rtq5Mg/3I6bkBDZRsRI1/WieTK6+Q2l58puj0zyCf0QXPCe7MpbT2Ao9I0b03iem1ADeq6+GuuTF3JgYC3QWH+7fhdFani7USBldF+h/t4bg3jJdi8izVNDl1nJnf1p4ApUSEG9xWJxLGXz6aefsmXLFurr6+nUqROnnHIKAwb4HuajZ7PZ2Lp1q+Pxtm3bWL9+PRkZGWRmZnLttdfyyy+/8PTTT1NXV0dFRQUAGRkZpKSksHr1atauXcsxxxyD1Wpl9erVzJ49mzPOOIOMjIxQLrVJM/rDilYrrr+s1sSwDrPz5wNrtSawcqVCp055jp7kYHhbq9o8FiZzA08xm3Hcxa90CfgI/raSu/aMuGb7Nuo5MZo3rNEnzom1v0PRPDUG6jUG6yr3auihV2l/p9pKGvHI7LpeNG+ebor1jfdGGhvz6/3qgfe10oS+7jXq1S8uzmfXrhq3JFfvvpvDWWeV6ra4B+quQYAmEln5H+RCTuVbZnMx7zxxAweeXBX2c5otPX2t03KeQpjN28gg8NbYFNy9p+v3nsXi/rkMtXEt6KC+qqqKG2+8kREjRnDGGWfQv3//YA/lUFxczLhx4xyPZ8+eDcDZZ5/NpEmT+PLLLwE488wznV738ssvM2jQIFJSUli0aBGPP/441dXVdOzYkYsvvthpnr1w588QlHC24nprrdKWYgnXEjhGAsloXVUVennCFdB3Yyt9+ZU3GQHA/+jJQF4mkN55TTQrV0+ZkmXOn4gWrVLPzfX+3WnW36j2nRSNhqxw1PWi+fInQZqn58xuzNePpDHiqVFAC+i1+bLl5TVOz9ts9Y77mnB/ZsvKCrDYKmn5+ku0nj4MsLCpbDDWtDW82pDZ13hufy9AcTRkRGp4u7dAyqiDQ5bLE+HSFP+ugg7qU1NT+e677xg2bJhphRk0aBAbNmzw+Ly35wB69erFf//7X9PKI8Krqsp4bioYt5AZPReO9Zv9/aDbbPUNid3cl6qItov4iCeZQwo1bCCHn+je8Eyww3Yt2Gx1DUsOWdwafUpKejqW77DZ6pwS/BQX5zvdHJWU9MRur3eqvIuLe5CWlhgTawsLEQ76VnqjxDkAy5d3d1seU83uHb2bj3DU9UIAjsRQ4F5vhDoqy1Ndpec8ZL63x/080WeJdz5uY4+/9pnXRhl4qxsDVVZWQNb2dXDeefDbb0ziRh7nPLeh6kbvn340kbpPZIa3e5tH7BrQa++VBPYiUvQjdrSVNfTTfM0cLRqO3BEhDb8/+uijWb16Neeee24ohxFRFkutuIGyWhMNl5kIVnFxD8rLq/1aRz2QIfeVlYWUlh4M+zD7dGw8yRzGsgiArzmaXYQ+9cTXXPrc3F90PR6uDQeK276uCgp+dVtHWJuXKMlyRKzy1OvkbU4teM7Q7RrQg//TXsJJ6noRKqMRedp2o/rbdVRWoMmk9GtE+yOYteT9ve9oLLtz3ZiW5l8ju9rgoLicTyHjxcfh9luhupr6wzvy0/Yj/TpeLAjkni09fa2MzBNhY9TgDsb3qmaOFvWVQC8YId0t3HHHHfzvf//joYce4q+//grlUCLK0tPXOv2xZmUluVSKimPJhVAzNWpz4vTLQZeU9GxoSNAeN/5cVlbg1opeVlYQliGpBQW/kp1dbHrvf3r62rAH9EfzC6u4kLEsoo4EbudKeu5Yxnayw3pejfb34Xpz5O91u++n3fA0NgpoX3jSai9igfa36Bp4m/s3amn4zozeOvBS14tQeaof/A3utNd7o/bOe+d8bxF473wwPF27PmhwLbu+nK43+pWbO6CMupMWN0+F6mo480wS1q5hiXI5itLP43ePFrxo+7g+FkLEt5B66s844wzq6up45plneOaZZ0hMTHRbC95isfC///0vpEKKpsE9CU5jK7Vri5h+7Ufj1ix1m1GiiUjZvLkbGzdupE2bLo7lpqLlWl7nfh4hhVq2cCgXcA/f0YdZh6X6PUXBtXfRtYfcvacgvILpOREi0owCbtchekard2j76T9jvpL1RKu3Sup6ES3FxfmUl1f7tW9WVrLbZ8TbutJWa0LIU/i0EWbO08nyycz0v2HPqAyu6187ehOXLoUh/eDPP6FFC3jwQbjqKrDE1rK6vhh9B7rOqZeReSLSfE2TC8ffpFnZ9CHEoP7kk082pRAiOoyGw+n/YF3XC9VolU9ZWQFZWSl+J74JrGyeM/Frz4ej50qbQ+PPNXTpsgm1YaLU9HIEKo0DpFDLQv7B5UxnW+VQw/18rdvruYU/usvJyNA7EU3evuN8LdHk+rerzSN2TwIWuzevUteLUAUbPOvnnPuaamfUmOa63XX4v3af422+e0lJL+z2OsNRZ0bbMjMTycpqbPQKZu6sxxv9lBQoL4f8fHjjDegd/GiDcNy7+Xtso3NlZkZnnr8QRsIxPD7cggrqDx48yBdffEGXLl045JBDOP7448mK5/V6mil/bka9VcLZ2cV+BVue5tK9/LLCuHFq67JWwWnn0weeRoluwtWLm5WV7PaBda2cwPOc2EhqwUEO0gKAf3Mx6+nCexyPfgSENpJBq1S9jWzQfp/elhUyuvkJp0BWIhDCLEaf+VCO5frdpy6F5/4Zq6wsdFsmL5q9VVLXC7N4Cp61hnT/6hTvvdH+3L/oP1taXW90k65vTAg0gas/Aaz+M63/fli8WKFPnzynfW27bKS3VxNFV1YOwPrhhzBsGKSluR03nIF6uGl/I7FwfyVEPAo4qN+1axfnnXce27ZtQ1EULBYLLVu25IknnmDIkCHhKKOIEn96wsvLq722gnv7ctYCepUSlS/yUNeIX7xY4cgjj2zotY+MZGqYxVOcwrcM4iUO0BKFBN7jBMc+ru9lsGu+ut4UaPPwIlXxxtMNiWia1O9Bi+6xc2+gt144T/OA9YGF9hnThhj/8Yfz8lgVFTVkZ//qtG8kSF0vzGachd3/hHaBNOb7MzXPaFqMP/VaSUkvR6DvOroxEEbnGjHCAqgJMxWlHwdeXsC+8ZPoxZOso5u6U4gjZ3yNYAjlOybQYxuNSJCReSKWeBo1E4sNaAEH9U8++STbt2/n4osv5phjjmHLli08+eST3HHHHXz++efhKKMIEzOWU3BtXXddbs5f3tZ6X768O507p2Cz1XsdOh6MnJwWHisQba6s/hpdpwIcOAB2e2jr1HujHwJYXJxP652l7Dh+HINQbyjOZAlvMNKvY/nTE+Laq+hPRa82FlhMHz0RTCOEEKGoqlL/5hWl8e/e23cceBpa6v8QvfLyWsNee024E2x6Es66fsWKFcybN4/i4mIqKip44oknGD58uON5RVF49NFHefPNN9m3bx/9+vVjxowZ5OTkOPbZs2cPs2bN4quvviIhIYERI0Zw2223YbVaQyqbCC/XRmEzG4e1pVW9jSbzdI+jTYsxGuLvGrjrOzwC+awHMnc2jSpqLrmMli/O4zBgCq8xgTs91smBBNOBThkKRDiPLYTwLuCg/ptvvuHMM8/k5ptvdmxr3749U6dOpaSkhNzcXFMLKMInkCFhwVADYP94C9YHDvwtqCVt/GGz1XmskI172JyH4Z1xhgUoMb1cGv0QwLsLHuJp7uUIbPxNKyZwB+9woqnnc71mT5Wx682J/nejBeP6GyPtpsifofux0uIpmp+hQxt7yUKhzzvi6+89kKG92neyovjY0QThrOvtdjt5eXmMHj2aSZMmuT3/7LPP8sorrzBnzhw6duzII488woQJE1i0aBEtWqhTjm644QYqKip44YUXqKmpYdq0adxxxx088MADQZdLxI8lS46kqGij07adO2sb6hnP9y7e7nFKSw8avkatt9S60MwpYUYdK4sXKxydVE3rKyaQ9OIG6rFwL5cyg4mA5zpZgmkhIiOcI11CFXBQ/+eff3L00Uc7bTv66KNRFIVdu3ZJUN8E+NtyXlzcg8zMJCoqah29SfphaYHOQ/MmXEs6ecoLEM3lo1xZsfMY93EJHwCwjD5cyN38wWGmHH/Fihzy8zNM6zExGqKvvyHSb/cn6BEilqhLT1kc32/6v2X3TNuJlJUVmDbKSPsc5ebWkBRSmlvfwlnXFxUVUVRUZPicoii8/PLLXHXVVY7e+/vuu48hQ4bw+eefM2rUKH7//XeWLVvGwoUL6d2QKGz69OlMnDiRm266iezsyCzjKYJjRv3qGtCD2gHgi7d6ztOoGPfVeZwzZLvmrvGX+74KuYveoM1Tj2I5eJAdtOciZvEVA/0+pj9CHaXpbdixGSNAhYhlsdyAFvBtQXV1taOlXKMtbVNb63/PrIgdwS6nUFDwq9vrzAzk9bQPkXbT7JpMKlzn8+X99xV69w7vnHotoFcSErirfgKzuIy60BaucNK+fZLPucG++Ps35Do/GSyO80rvvIi2ZcsU8vLyUJQWHpdz9PS9k51d3JAIzLn1Pl4braJV12/bto2KigqnefutWrWisLCQ1atXM2rUKFavXk3r1q0dAT3AkCFDSEhI4KeffuKkk04K+vyKomC320O6hqaqqqrK6f9AlZfXRjT/TDhUVNiw27Wh+AlO0+/s9ioslsCDV+0Y5/EpXR++H4APGMol3Mku2hi+pry8u9PfaXl5d0D9ztHe482buznqb/2+2up3Fku9bttBR9l9/fl7u+ZQjx1uof4NC9+a+3tsZv2hBDgsL6jIYPv27axb1xi87d+/H4AtW7bQunVrt/179eoVzGlElASS4d0os3O4Wa2JxEoC5nANgy0p6UVWVhI2Wx39sq+iH79ybf2NLOVo3y/2QAtOjHoNtZ6TQOYG+5MkRAtytADJ2/xkGR4ooi01Vf2bV5TGm9RAepi8TV8xg9bINnx4Mrt3m3poQ9Go6ysqKgBo166d0/Z27dqxc+dOAHbu3Enbtm2dnk9KSiIjI8Px+mDV1tayfv163zs2Y6WlpUG9rn//8K+l/t57CmeeGb7z6Bslli1TUOMW9Xxr1mwgNVV9TvvfXytXQlXlcP6+8QPK+h/HGU+dB1h44w2FMWMar2fxYoXUVNi6dYPhcfTl2bZto9dy6PfdsGGDzzJrMZo/1xzosSMt2L9h4b+m+h4vW6b+X1WlJbZs/FwCptYfgTagBxXUP/LIIzzyyCNu22fOnOn0WMuYKxVkfNGCM29Do5cv787Agb9FPGP9unV20tLCs06kPkgtKytoyEhd63X0gXrzYG7PQ3v+5p7cu3lOmQXAdrLpw3x8Lefji37JQD39TYqZgbUsSyOaCm0kitb4Fa2/ba2RzRL+2AhonnV9UlIS+fn50S5GTKqqqqK0tJScnBxSA4jSGhv+Q89X4cvgwXmsW1dLr17hy3WjUXNwNNJu8AFsth6+D1BbS9Kzz1J7ySXQsiVW66/A47Ci8Tj6gB6gT588rw2N6nutvs95ed73Vfd3f31Wlvr68vLuTq9Xy+fM2zW7HjvcvJVdE+zfsPBfc3mP9Z81X5/LYCUFOM8u4KB+9uzZgb5ENEH+zF3zx7p1ubRvn+b3ENVgM0FrjRAarSfcE21euLes1OFwAst5ldvpwE54rz/WM88Mad55MK/1NZTezCQhMtdOxCJPn4FAGxO10TEANpviaCAsLs4nMzMxLCt6mCVadX1mZiagLqmXpRuStWvXLnr0UIOG9u3bs9tlqEJtbS179+51vD5YFouFNIP1v0Wj1NTUgN4jq9X38nJmUZQWpKYGNz3NNfne8uXdad8+CX0ODf1yld74fH+2bIELL4RvvyVl82Z4/PGGJzy32PkzZz8tLbTGeUVpzHeQlpZKWpr/33nR/twEUvZA/4ZF4Jr6exzKZ8VflgBb8AP+5jv77LMDfYmIU5GYC5qWlkCoPdD+n6eR1Wpp+D/RMEhV5+z7DuhDGeqnb2hIooaZPM2tlhexKAr1efkcOLQTitscdP/oK399BW80b37z5m5kZvq/DJSvJCH6RHiuScVATbCoNc4EshyQEJHkbXqJUWNZSUkvQHEJ0hVHA6G2Dj04r2rhSyjrYIciWnV9x44dyczM5Pvvv3f0mFdWVrJ27VrOP/98APr27cu+ffsoLi6moEBdbeOHH36gvr6eo446KirlFuYrKelp2OhltMKKJtApL/p62DX5nrZdn/Feq7PUqWXOq7l4aqR2+y755F247DLYswdateLA0YNJbUi2t3ixwpFHNubpCeXzH8g62v401sdqErxYzkYumq5g85GFU5jz54p4pK8I/KEP0gIVqaQ5ruXTKmJF6edh6Tr/es/atlWHeSlKSsCNIJ07q0mnOrOD+UxjMD+rnXqXX07CQw9hTd8ABDdSwFOF5mkZQzMrPf37afQ+RmvdbSHMkpWV4pbp3miajv57JpDPmL5hrCk2fNlsNrZu3ep4vG3bNtavX09GRgYdOnRg3LhxPPXUU3Tu3NmxpF1WVpYjG37Xrl0ZOnQot99+OzNnzqSmpoZZs2YxatQoyXwfg7RgsLT0oGnf/2Z1Ovgz6tA1W3/jY9cGd3VUjqfPa0sOkHLt1fD8M9rJYf586rI7w6Xq513L66GJ1Offn4zekbh/CEYsZyMXIpIkqG/mfLXkqssxKV7nlRtV0suX5zFwoJrIpbg439EzpbXq2u1VjrlP8ayqSss2G9wNhvL2FpRLLsGydy97SKfly8/RcuwYv1/vOq1AE84KzVNrvackfN5E+2ZACFc2Wz2KUmd6r4/rMljacWOpxytSiouLGTdunOOxNtT/7LPPZs6cOVx++eVUVVVxxx13sG/fPo4++miee+45p2z8c+fOZdasWYwfP56EhARGjBjB9OnTI34tIjjq0PZkt3sL/SgYT3WJ66gZsJiSlFI/MsB5RJlzj5y2hJ0rfSOe/t6qpKQXeWxmITeT/PzvAFRPuZGa2++C5GSn7xftniIU0nMtRPMkQb1wMKoIwILV/5HZDlpAD5CZqe8p1hI9JRguH6VvDIgUoyDVX2qSmOBGG2RnF6MsrMeydy8MHswhr78OOTley1VW1hubrc5x46HO9wucOu2gB+vXr/cYSHhq8DG+IVD87jlpTsGLiB82W31Ddm7vjWTg/HmorCw0TKhZUtKTrKxkw3P50+PVlHuXBg0axIYNnr/nLRYLkydPZvLkyR73OeSQQ3jggQfCUTxhMqOeVE895P7UI673KFoPuT+Mp8k0Dun3db5gAuLc3HUcQUsOp5w/acc47uLzB4+BB90bLfT3FMF+BwTTcx3I0PpYG3Ycq9MChIg0CeqbKaMA3oz5ab5olU15eXfD5aPCEdAXF/cALE7zWLXs9hD5VusWHOQgDT1Oo0fDu+/CqFHgkuXS842/8XJb+l6GSFdogQyFjIXhekKYwds0pdzcX2LqxleIWOZrKd2yst66pVEb70tc71FKSnpitytO9b2+1z03d11DrhdnNpuC3d44zF4/AtE1INbKatSYV1zcg/Lyamw2xamu/4PDOJMH+ZUcKnBejjEWRGJofSBz/AMRq9MChIg0CeqbKTOWZPIns7pW+bkORwsHT0l1jOfwqXPhbLY6wy/+kpJejspavUmoN2EuoMLVvMmjh7/OwSXfoRx6mLr5zDMDOoprK7nrkF51n+ArNH+H7unL4Wk4oiaUDP5ChJPR37trb55rwsdQh8dqYq3HS4hoaAySa7zs5V9vvD/3AEb7eJti6EqrA42S6WrnOo7VbGA6V3ErH3McAMvoZ9jgru9hXrxYoU+fPNLSgl8KzKi+lZ5rIZo+CeqFV54CZWjMhuqaAVZP3yrrGiRqc8cyMxN9ttL7I5C53EZD0YzmvAJkZSW7JcoJVFv28Dx3cSZLYDukvfIczJjh12v9ufE3s8HErKF70DgEWYIXEauME2Wuc3ns/N3iutqDDPsUwjOjnm39srL+1F3Z2cU+h1mHq9MgkM90AnXcxjzu5FkSqWc68/iYY9E6Enw1uGsjGINZHstzAj/QVuLwJRx1daTm+Mt9hmjuJKhvprxVjt6CdP1+4P+XsWtlq2a9V+ev6rOqmtWjq0/OZwZ/y2S0EsAw/sdrTKcj5RwkGe67jxY3eJ4rGiozh7X5q3FpQNfeFO8jIoSId65/1zLsUwhnjaO79KPJLAF/TnwNsw4lP44rb0uvakGqfkQfwOGUsaH/vVhXfgPAS4xiEjc37Od/p4Mrf4ete2vUyM4ujlrAK9nphYgMCeqbKX/nIBlVRJ7WJHelBf+BtJ6bdTOsD+iNRhv4ankPtsVXH9AnUsvtPMd05pFIPRvoTKdvF5I6pH/Ax/UkHC3gwSad8dXjKRW3iEXa33tFhc2xxKb+Zl3LvyG98UKERl8faQ3llZWFXhvzi4t7kJPTwvA5b8cPlbfpdkZ13Rl8zfPchXXlXkhP58DDT3DxZWryvaysZK/1n3a/YbfbWb/evM4IIUTzIkG9cBNsxeg6hF5rJDAKEtety6VXrxKgcT62tp/5gh+KpvGWGGfFihwGDCh1e80NvMKdPAvAPM5kMjdQ0q2Q+oZA3IwbkGBawPWt/suWuR9Tks6I5kT7u7bb9UG6fsSJxW2b6+dBhn0K4Zv2OdHXQenpa71mns/MTDIYDeP58+Y6Fc1bo5y/HQ7p6Wu99pD3ZT3vMRWAFfRkwOr3qDusC1wW2nSAQBvtfU1ziBbJTi9EZEhQ38wZVY7+zB/XKmHXykb/Wm3ItVFFmJbm+8vc23z+QBglwAl0KJo2vNxqdW8g8LSs3GOcx9l8xcNcwAJObjhv0x1yJhW3aCr03ztmrwAiRHNlvGwuVFR4vudQn6t23Eu4Bu3egm1Pz3nrcCgr642vJVpdX7eafKouvJTE9ofQ8867oU0qVkKv44Mftq54+Dk6pKNAiMiQoF648dV6XVLS06/l77x9Ye/cWeu2rbT0oFOw7yug9zZv3qwGAT1P74s2ZLeyojv1zzxHxm3HoZCAnVSO4SWMRwqYI5BA2uiGSktWqCjuc94D7X00u+IO1/I3Qhjxp/GpqTXECRFJnupQb/lv9M95GnnWmNPFc6+2EeM6RcFmcw+Ey8tryMpqeF1aArz4IhSNdDxf/5+nSU1PIsXrGcPLeApc431QMN9fUg8LET9iKqhfsWIF8+bNo7i4mIqKCp544gmGDx/ueF5RFB599FHefPNN9u3bR79+/ZgxYwY5OTmOffbs2cOsWbP46quvSEhIYMSIEdx2221YrdYoXFHT5G+w7DpMTF8ZGA1XD3TJOO/z5i26IX2WsPcc92ITmzPPpYDfmcJkHmCc49xGzJpqEEggbVThjxihJisECViEWLZMIS8vD0VpIaNNhIgxFssqiovznbZVVKgdBL46GhSln191nKceeu3+IoP97PnXE/Dmm7QYPgIL96CQABbzG++b2ug3maYkRHjF1DeD3W4nLy+PO++80/D5Z599lldeeYUZM2bw3//+l9TUVCZMmMDBgwcd+9xwww1s2rSJF154gf/85z+sXLmSO+64I1KXEDdstjosllVYLKt0Ldx1Ptcb11RWFjYkuOntcZ/s7J9JT18b1rXpNa4NDbm568jOLiY7u9ipAtTKFAwtoY/e4k/r2Xn3ElYwjgJ+py7rUNbSHVCnKLi+P2VlBU2+tVuruPWrGgTCZqtr+Oc+tSPUpQWF8EZbTkr/naE1kjXlz6wQkWBGY7Zrr35Bwa8hr5jjb7A5mLWs4Xx4801ISiJpxHDq64Kv6/wpl/rPv+8jo/uysrLeju2BkHpYiPgTUz31RUVFFBUVGT6nKAovv/wyV111laP3/r777mPIkCF8/vnnjBo1it9//51ly5axcOFCevdWv9SmT5/OxIkTuemmm8jOzo7YtcQTozXOy8oKsNnq3YLl4uJ8MjO15WmCy6xeXl7jV2+/2cvS6flKfGPEdd827OWoWbNo981XAHzMEPp/+V/ezTnUsb9r5Reu4MCfmxKjVv/FixX69MkjLS3V9DIFS5a/EUKIpkebx+7vPUCgKisLQ+rV9pQQN4E6KqYuos3Ds7DU1UFuLixYAAMG+DxmJIevmzkFTuphIeJPTAX13mzbto2KigqGDBni2NaqVSsKCwtZvXo1o0aNYvXq1bRu3doR0AMMGTKEhIQEfvrpJ0466aSgz68oCna7PaRrMEtVVZXT/4HQWl31ra9bt1a67We3HyA3d5Pbdn2QbbP1wG5vPM7mzd2Axjnmmzd3c1Sodrvdcc6qKvf59Eas1hqnx65Z5lesyHGag69l03fdt6LCRnl5d2y2ekfZtO12e4Jflb7r+zaIn/kvN5P9TRnVJHEL1/AwF6AUlAFlDfs6vz/l5d2xWA4SrT8jbXSgxdJYptRUSEg4iMWSELVyBUr/OQzlsxAr5Bpig/4aUlPVz68qep9ZTxQl+smvhAhUYyN3ePLMuOeFCSyg1fbV5s4DZLKbBdxK2wdWqhsuuACeegpat/brmEbJgwMlw9aFEP6Im6C+oqICgHbt2jltb9euHTt37gRg586dtG3b1un5pKQkMjIyHK8PVm1tbcytH1paWhrwa/r3d69Mjea364NfT7T3Y2VDXbdr10Z27watwt64cSP6X4fRub356aeN6Ct/13IaldvoOU/Xom1ftkwh1UdHtWvZa0jiUHaxkSM4j9msIt/tNa7vz9atG7yfJELU2KXxeoL5OwonbZm9qiptzr86okD7HRl9DmPtGoIh1xAb4uEaamv9axgVIpaEYypeSUlPsrKSTT+upooWdKQcxWrF8sQTMG6cX/PnG6c1KrptimN7uHvsQ20EaGrz+YVoDuImqI+2pKQk8vPdA7doqKqqorS0lJycHFJ9RaNuAktG503//hbKy7s7fcmXl9cCarB85JFHuqyPGti5zzzT0nDM7mRl/RZqcT0aOtSi65VTKzHtfI3X9yspVFPdkNt2FfmcwUN8SyGVNCZh1I9OCKTyMz5n+Nhsof4dhZ86KkJ9T/r0yTN8T2L9Gvwh1xAb4ukakpKk6hYCghte7mtIvDWpFqW+b2Pw/tMH0KIF5OX5fQ7jTPSNQ/pjveddlqETIv7EzZ1BZmYmALt27SJLNzZq165d9OihBmTt27dnt9pV7FBbW8vevXsdrw+WxWIhLS0tpGOYLTU1NeAyeZozFiwtEC0rK8BqTSQtrbHFPC0tFUXRAtzgK4K0tFSv68mqLCGtJ61/HxWlTrc9lbS0RKoWbCHluv/jz2ffpuPpamD/4LqL2L37dzp27Obo9c/MtAZ1rUbnjJRg/o4iIZD3JFavIRByDbEhHq7BEoZM20KEmxn3H1rPvBY0mx5kbtgA550HF18Mkyer2446ytxzCCFEGMTNOJqOHTuSmZnJ999/79hWWVnJ2rVr6du3LwB9+/Zl3759FBc3ZkL94YcfqK+v5yj5Ugb02VTNvSnMzi4mPX2tU2Ctz36/efMBw9ctXdqJ4uIeTttKSnpRUtLT8dh5aTznLLBZWSlkZaWE1LPd2GBgkO11l52aKyfR8rxzSPjrTzKeftDn8YxWFvC2r2SYNRZqFn0hhBCxw8z7j8rKQqe6wZ+61Os+lbXwwgvQrx+sWcO26+4l1fJdwPVwPNTdgdyjSD0sRPyIqZ56m83G1q1bHY+3bdvG+vXrycjIoEOHDowbN46nnnqKzp0707FjRx555BGysrIc2fC7du3K0KFDuf3225k5cyY1NTXMmjWLUaNGSeb7Bo2VW72PPc3lKdPtsGHq77usrMCxLI1rC76+ocCfZVnUZef877nXKirX4XI92MxfnceQ1TCdYC4XMe3DSY7n1cR8FmCT01C6QCp0yTArhBCiKXId5t64Pfj7D/29hH7ovD91qad9WrOfp5jNBXwKQF3RCQxccjMHaBlw+XzlDTBjWT8hhDASU0F9cXEx48aNczyePXs2AGeffTZz5szh8ssvp6qqijvuuIN9+/Zx9NFH89xzz9GiRQvHa+bOncusWbMYP348CQkJjBgxgunTp0f8WmJVJNaMDydPCWBct+sDa21qgH7ovn67O4UJvMuj3E8aBymjLeOZyacMMdi3kVGDifMoA2nlFkII0TS4Lofra8m2WLz/GEAxC5hGLttREhOpuX0meyZO5c8OauOBax0e6hJ14bgP8LdMco8iRNMWU0H9oEGD2LDBc4Zwi8XC5MmTmazNczJwyCGH8MADD4SjeCKsLA1rzDZmjNX32JeU9MRqTXA8H0ilarQ2vNHrtBb0mjff5pBL7gagumg4rZ5/kZfTM90aBjZv7sa2bRvJa0ieE0yvu3bN2igFkAyzQggh4pev4NG88zQe059s7a77tOdvfky9EktVFfWdOnPs1hn8MOMomNE4GsBXHe4aUBuVQ6OOIoweGRkoRNMWU0G9CD+jCqekpKfH4fH+KinpBShBH8fXUPlAjxvski7p6Wux0IUPOJav6c+MD+7H2ioZo7RZVmsCqamBZbk3KqfRcaXFXAghRCyy2eqprKx2Wq4NoLy8BqvVuZFa4zxKrrfT/QcEXse7HtN4BJ9zXepar+6kDTW33k5K8RoSnn6aH9qUeD2f0Xz8xmS9xueA4Hr0/SE970IIPQnqmxmjL/msrGQUpZ/bULpA+Mpku3x5HgMHmr9Ou68KzLUV3TDQr6uDp5+Gf40FQCGB03kYhQRmJPgfsAe6rqun/AahDO2LhlCHIwohhIgfnpaY9Tcw19eJ3taYX748j/btE0PudHDy8cdY2h7qeFhz/Y2kWBPBYvHayw7uPd2u+0Q6V1GgPe+xtPa83DcIYT4J6oVhcLl8eXcGDjRvbfj27Ru/sMvKCrBYqlmzZgMjRlgatrlXLM6jCXoZNhz4MzRO/7NbxbF9O3UXXETi0q9J+GE1cBUAf5UVGlZ0+hEAdrvd7Tn3/T33usfi/EIhhBDCbN6CR6s1kcrKQrc60agjQH8vEFBAevAgTJsGDz5IWn4+im0luCxdGWpg6Xo/EmvD2WVkoBBNmwT1wnCoXCABvaeAW0/f0m61JmKxqEPXG7d5r1gCXdPW07A0bbvVmggffggXX0zirl1UksqkVw537BsL88xifRidDP0TQojmp7y8O4qS4jH3DbjfV7jW8a71qtZgXl5e7fZa53sMRfcaPwPSjRvVtedXrVIfDx8OXkbhGa1gU1LSC6vVgs1Wb+7IgRDEUs+7v+S+QYjwkaBehCyQgLuxl9u88+uT6Hlb3kariFOo5uC18+HRRwFYRR7ncy+/kWNKefydz68lyfN0kxALDQveSNIdIYRofqzWBNLSUtyCXy3INhqGbjhSzvDYiQ11Y2Ogqr/H8BRQewoWk15/hZTrJ2Gx2aBdO3Ut+tNP91oGo44Oo/sc1+VzIx1QB9vzHmzOITPIfYMQ4SNBfTNjVPGFuwW6pKQXWVnuf2qpqWCz9SAtzSgNXWPFo5W5vLzGsHz6bb4qhFz+YCE3w6PqsL6HuIBbuIY/yvoR6crZak0MaAi+zEETQggRq4yCYf1z/gRsgdSJ+jrQ9XUtOcCn2WcxlkXqhqIieO01OPxwzOJaB8tQdiFENElQ38wY92C7t0Drh7sVF+dTULBe91xPwOJ3D31WVpKjotMHpsuWBVp6S6AvcHOAFhzBX9C+PQf+M48p/+wIxG7lrA2vM1Nov4NG8Tj0TwghhDlce3wtllVe9zejYdrfOqaaZDpSRi2JzGAid3/xGCT6dz5fdZu+3EZD9SMtmj3vgZL7BiHCR4J6YchqbQyg9QE9BLf0TCBcK35/Wu4bRxvUOYbvAZSX19IjdzXVpDSMGCik+st3sOd3o7L1ocDPDed0X5omEnytaasOZazzsJSOKlqND5J0Rwghmjd9fd1YZwUfsGnT0vS9/vrEvZ7qmMrKQqivx7a3muwjNlBPIr3XLKSmYiu3Dj7W74BePYf/dVs8BdSBCNfIQLlvECJ8JKhvZnytU699eQfS+lxWVuCUMEc/3F7fQ6+dV1NVpT5WlDqMevIDoR81oCj9HMfL2PADvzCGqVyP1arecKSfkQFUNPxTRWtOl7eKzFt+gGDK6+/vQAghhAiU1ZpoOOpN461hWl/3a2vXB3Tuyp1w8cWkHNEFuAyA1G5HkFqYE/CxhBAiHklQ38x4aiU12q+srMDrHDnQt8zX6La693gbBabqcnZq67s2d961McFmq3dqdPBbfT3MnUub226jLbXcznNY0yYHdowoCdd8eX9+B8Foqj0VQgghnFVVgdX6K9CYKE6jBequ9bg/DdP617jW91ovvXa/4eazz2DsWCgrIyk1lSMYxR8cFtiFGYiFui3SuXQilZ0+3O+t5CASzZEE9QKbTdH9XK+rXH3PYTfOEut/4rrG8xr30LsOSdeoGe8TjYf4/fUXjBsHn32mXsG553L0009Duvrn7mnIu8cbhgjwVsHJHDQhhBCxxrX+D3bEm9qg73v6m1uyvZoamD4d7rtPfdyrF5Y33mBrr15+n1s4k+z0QsQvCeqbKX3wqh+67imIDpVRYLp4sUKfPnmkpaUGPOTetSXfMSfrk0/UgL6iQk2v/+ijMGECWCy6fbXpBa43EZaGMsbWUHSz5qD5+h0IIYQQRmy2Ouz2eqqqAn+tt4bp9PS1QU25o6QEzj8fli9XH195JTz4oFrvNwGynntwfL1vltDzLQsRsySoF6Zbvrw7nTunOG0zqoBSU7X1bk2qnNatg1NOUX8+6ihYsADy8w13bY6t0RH5HQghhGhyGutMz1GRpxFkoTZMFxfnk5mp27emBv7xDygthUMOgXnz4JxzPL4+HodiR+seJd5HBvp632y2HpEsjhARJUF9M6bOh4MtW2oYOFBdt33JkiNp1y6RXbtqKSraFNRxtflv4H/F42lIvJYwR+uZV4fdJzgl5isr662+NqcH1quuUrPc3n8/tGwZVPljVSzM7xNCCCGMhCuLeWZmIllZuo6C5GS1V/7BB9W15zt1Mv2czZVkpxcifklQ34wZzYcvKtoY1nNqgandbmf9+vVO241kZSU7PXYddn8+H9Mnu4I/yQRAqXscEny3KMd7a3QoPP0OYlU89rIIIURToA1nNkpYqy0lq7+X8PZ9bdQw3bj8bI1T4z241PerV8OuXTB8uPr47LPhzDO91vfxPIS9Od+jhML3+3YwSiUTIvwkqBcxy9vyeunYeJI5jGURX9Kfk3iSehL9CuhBWqODJQG2EEI0H97mu+fmrkNR+jkF6oEshwuNdbHV6vw6xzK7+4/C+tzjcPPN0KoV/PQTdOig7pSgXy7PvW7yN/luLNZl0b5HideRgb7eN7s90iUSInIkqBcxxagi0W+z2epIWLWS5PGXkrR5E3UkMPDmUeybVqgOuxdNRjz3sgghRHMS6ve1c4++Gqy3529a/OtM+GSR+sRxxzW5aXVCCGEWCeqbgGB7T42GvQVDHSpnccxxLynpRVZWGP606uux/udhuPVWqKlhC4dyAfew+PbxQQd4WoNBNNaCjace72gE2M0xmaEQQsSSsrICt6l6mzd3IzPT6rQt1O9rqzXRaej0CSznVW4n6ZOdKC1aUD17Li2u+z+39OVa3VReXuvYVl5eS1ZW4zK1+qHYxcU9KCj41eUYsdtYHK895tEm75tojiSob8aMhr0ZVXi+j+M8JCwrK8n8inHXLrjoInXJOqD2zHPo89417KG1uedpAvQNBmBOo4EE2EII0fxEchi4Ws8o3MMTfM6LJKDwC10Yc3A2xVOORLnePfO+Ud2kX6bXtW4yur+RukwI0RRIUB/HbLZ6FKUu5N5T/X5GS5stX97dKaP98uXdSUtLpKBAS7JmCXgeXcBatlSXr2nZEh5+mKSJE/nbhAVHG1v5axzbystryMpSfzb7xkWGlPtPEgUJIUR0GNVVjc/VoyjVjh78srICjyvYaM/7z0Imf5OAwjOczXVMpQp17XmLZVVcjGwTQohokKA+jmVl/ea2LZgWZ30FqW/h1ugDeqPHYWvlrqlR58knJIDVCm++qQ6969ULMB7CHuiwduNW/sapCGa32oezx9tmq2v4pzhtLy+vwWqtw2pNDPpmKBoBdrQTBQkhRHPlLUFely6b3AJ1b9/Lfn1nHzzYWM9UvMjpXV7gQ4b5V1gf/Dm/dm4RfvE2/VCIeCFBfTPmOkw7UueqrCx0nRbnrqQEzj8f/vlPuPFGdVtBIK39zY+n36UZjRQSYAshhNBUVNS5/FztcV+vo9FsNrjuOti6FevHHzdktE/3GNCHa2Sb1GVCiHgnQX0cKy/vTlpaqim9p8YJZfIBxXAO2vLleQwcuCGkc3o0fz5ccQXs368Oub/qKkhPdzxtNCywvLwWqzX0qQjhJkPKAycJb4QQInJstjrKygqw2eo9JtFtnH7n/LMRj6PRfvoJxoyBX39VR+F98w0MG+Z1Op/rsbQ6tbT0oONepbi4Bzk5LZxe5216gJrst2mKpV5xmX4oRHhJUB/HrNYEtznw/vSeGs+V07rOG4due6uotYDe1zk9fYlbLPVUVbnsXFkJ114LL7ygPj7uOHjtNaeAHnwnxtHEYvKbcPZ4V1YWOobf69+PkpKepp1DAmwhhGhaXAO/sI/gUxR48kmYOhUOHoTDDoNXX4Vhau+8a7Z9f+jvhYxyA3mr/7KykgM+nwicJNwVIrziLqg/8cQT2b59u9v2Cy64gDvvvJOxY8eyfPlyp+fGjBnDXXfdFakixjxfX6yRO5cFm63hx9Wr1eH2Gzaow++mT4fbb4ckc/5ELZZVgHtLdeOyfrXhX5IvzLQ58669HFlZydICLoQQIiyKi/PJzNRW01H/9zgabdcuuPRSeP999fFpp6kN+e3b+30+/fz3QLPfG40CaIq9xdIrLkTzE3eRy8KFC6mra/xS3rhxI5dccgknn3yyY9u5557Ltdde63icmpoa0TJGmq+11l23+6Io/RxBsL/nD8nff0NRkTrc/vDD1d75oiKPuxsNoysp6YXVanEaLqjdSNhsdR5b/rWya9nu1Z/DsCSfwXmlVVoIIUS0eAr8tCR4/vaYZ2YmkpWV4vF5p5FiZ46BL76AlBS47z51dJ5Lkh1fmfRDqZ+Nrqkp9hbHYq+4TD8UIrziLqhv27at0+NnnnmGTp06MXDgQMe2li1bkpmZGemixRxPifC8fbFqGdRLSnoZDmkPVGNPeI0j2C4p6Ul6ei0bNjQM4W/TBu66C77+GubNg3btvB7TqELXAnHnVnhtKkHjDUNzaKmOZINBLM3XE0II4T9fgV9ZWYFbELx4sUKfPnlUViZ5nG/v1f33w/jx8NJL0Lev4S6BZNL3dI8hQ+pjjyTcFSK84i6o16uurub999/nkksuwaJr6f3ggw94//33yczM5IQTTuDqq69ukr31Nls9Vqvao662rDsHr56GmWmtovrWUe2L1d+5dIG3rlqcfk5etgTrnj3QL1/dNHmy+s+Etec1gbTIS8+5EEII0cgo2EpNVe8XMjNbeq0zHXXqli2w6G3417/UJ/r2hTVrGrLc+893o7HFw88qfQO0mhjPYph7xmaraxJBpvSKC9H8xHVQ//nnn7N//37OPvtsx7bTTjuNDh06kJWVxYYNG5g7dy6bN2/m8ccfD+lciqJgt9tDLbIpqhoyzFXpMs25BrCe5sjrt5eXd3f8bLdXYbH4/2Wv7W+1JuDtbUlPd86cn0QN83Ov4hZexMoRVP3jOGxp7cjK+s1RJn8rHYsFbLYeDY8OYrc7b7Na3bP2O19DaL9Po99DPAml/NqIB/3Ih4oKG3a7e4NROMX77wDkGmJFPF2Doii+dxLCB1+Bn9HUvoC89RZcdpm6bF3XrtCvoRHAz4Den8b2QOfUq8+7jzAwY+nXWBLLveLSiSJEeMR1UP/WW28xbNgwsrOzHdvGjBnj+DkvL4/MzEwuvvhitm7dSqdOnYI+V21tLevXe1+2JVK0e84NG7Zi1CLtr61bN7ByZePPAMuWNZ5jxAjPx+7SZRMAK1f6urlsPEZndjCfaQxGvXlYQj+O3rYNu7LTsd+GDRswa1CF0bUsXqw4jm/W77O0tNSU40RLMOXv39/9b0P7mwB//i7MFe+/A5BriBXxcA21tbXRLoJoAvwN/LQgzG63+1dvVlXB9dfD00+rjwcOhEMOMaHEqvLyar/n+xuv9iOEEE1P3Ab127dv57vvvuOxxx7zul9hodoSvWXLlpCC+qSkJPLz84N+vZl89UD7sm5dLmlpCQ2Vt3GLuVoB/ubzWP37W7z2rm/eXEuXLpv4J5/xLHdzCJXUt8pg95y55BzZl/ZHdKK+vgWgBoQdOx5pOD0gFPpr6dMnz7TjVlVVUVpaSk5OjmN6h81WH9Sog2gwKr//vP8NRuqzEto1xAa5htgQT9eQZNKqIEKYrrgYzjsP1jX0lt98M8yaBcnhmeOuzZ/3NNogfFMK44P0igvRfMTtncHbb79Nu3btOP74473up7Uqh5o4z2KxkJaWFtIxIqm4uAdpaYmGye569Spx/Ozpy15R3Ofje5KWlmq4LixAZms7zzCLy3kXgO/pTeEP75CWcxgjrL8Cfzjtr+/tNasi0l+Lt7IGKzU11fG3Ee5zhYO+/P4ySqCkvymK9HUHcw2xRq4hNsTDNVhMzD0ihGmB33PPwTXXwIEDkJ0Nr7wCJ53k82X+JlwtL68GoKKisZ6125WGBL/6JLiBDzOPlaHpQggRrLgM6uvr63n77bc566yznHostm7dygcffEBRURGHHHIIGzZsYPbs2QwYMIAePXp4OWLs01d6mzd3Y9u2jXTseKRTEKxXUBBab77VmkhlZaFfrdxGGeUdQ96qE+nMn9RjYTaXMIOJbG9/BOlEbvhoJFqqzV4TNtazysfyfD0hhBBR8PffakB/8slqdnv9WrEmMBpyX1DgfTqAr9V+/B3GL4QQsS4ug/rvvvuOHTt2MHr0aKftycnJfP/997z88svY7XYOO+wwRowYwdVXXx2lkoaHGshb2LzZ/9fol6gze5iZW0Z5RaFN+kpqUIfbZXMXPSnhKwY27F+MzdaDZcsU8vLyUJQWcZ+dNRbXhA0Hb/MTm0rWYCGEaI6CakyursZWo66cY+EE7C/Np+VF5/qVDM/sxnCjetZbA7QMTRdCNCVxGdQfd9xxjWuc6xx22GG8+uqrUShR+HgLonbudO7tLi7Od7Rau2aw1S9v56tHNaTEMrt2wYQJPAlczh1qWWhPGe3ddtWmreqDX9d5cLHYSx1OZt/kmM3byI3s7GK5QRJCmOKxxx5zW7WmS5cufPLJJwAcPHiQOXPmsGjRIqqrqznuuOO48847ad/eva4RYVBXB/fcA2++CV98C4BCAnWj/+V3dvtAG8PLygqw2eqdMtUXF+eTmdl87hGEEMKTuAzqmxNvQdSAAaVOj/XD0EIZCu3PkPslS46kqGgj0FipJn+/DPqcCdu2MSElhQtW/JvKQ3M99MIfDPrcscisNWGbS4+/EEL4cuSRR/LCCy84HicmNtZp9957L0uWLOHhhx+mVatWzJo1i0mTJrFgwYJoFDXu6Hvly8oKAOfh7d4aky3bt6tL1S1dCsCk7AeBM3y+LlRZWSlOHRQAmZmJZGWl+Hyt9MoLIZo6CeqbCbMrNC2gBygs+JnbeY7pzAPqoXt3LAsWkHZUHoqHEQIVFfVUVTnfABQX93DLBRBLvdTeNJc55mY1XgghhC+JiYmGSW7379/PW2+9xdy5cxk8eDCgBvmnnnoqa9asoU+fPhEuaXwzmlfuqTE54+uvaXnvvbB7N/tJ4ypu5TVO9fk6I1p9Ul5e65bUt6SkpyOA1482dB1BaLPVy9QvIYRAgvqY4Wkum1bp+dOD7TrkPlieAjdQ3Cr/I/iT15jOUNaoGy65BB59FNLT3Y6bnr7WcW3qsm8WtKXswDi5X3PrpY71oLm5NF4IIaJvy5YtHHfccbRo0YI+ffowdepUOnToQHFxMTU1NQwZMsSxb9euXenQoUPIQb2iKNjtdhNKH5u0oDiQ6XV2ux0OHCDhppvoNm8eADWFfem79k5+5wjvr/NCW8QhN9e97tcPsfdG289mi+9kyKAuq6n/X5hP3uPwk/fYPIqiBLS/BPVxwHW4mWbdulzat09zBNrZ2T+bMgfdU+CmV1LSk265P/MZ/0ceW1BateLgI0/R8pIL3Y7lbxb9piDUERESNAshBBx11FHMnj2bLl26UFFRwRNPPMGFF17IBx98wM6dO0lOTqZ169ZOr2nXrh0VFRUhnbe2ttaxFG5T1L9/YMshLlumsH79eo6YM4eshQsBmMtFTFs7yZEM1+g1QADvY+hLNDal31lpaWm0i9DkyXscfvIeh662NrCVwiSojzJfidG8BcO9epU4ena9HT8cSees1gTqSWQK1/N+/9dIXDCfll27up1b/d/92vxZlk/j6xpF5Mn8RCFEOBUVFTl+7tGjB4WFhZxwwgl8/PHHtGzZMmznTUpKIj8/P2zHj77Alrvt1099Lyxz5lBbXMzmq67ixsnH+fUaf5WXN44ecL0fWLq0E8OGbfX42s2buzU0fMfGaLZQVFVVUVpaSk5ODqlaJmFhKnmPw0/eY/Pol233a/8wlUP4yVdiNH+UlfV2vMbMOeha4KYPznvyO4dTjs3WC4BFDOXAl1djbeXeYu/r2laudB4BoF92z/U4zS2wl6BZCCEatW7dmpycHLZu3cqQIUOoqalh3759Tr31u3btMpyDHwiLxUJaWlqoxY1ZRlO8Skp6Ahan+jeD/Wx9+DfS0hrqoa5dsa9Ywb4NGygv705aWqrTMTRlZQWkpaUE1KGgvd2KUu32nLeAXn1tKmlpCShKbOfdCURqamqT/huMBfIeh5+8x6GzWAIbxSRBfZxzDZz1FWxlZaEpS6Op51CYyNus5AEOkEJhbg5wmHqsVsmUl1c7pgGUlRX4lY3WldUa+hA8IYQQTY/NZuOPP/4gMzOTgoICkpOT+f777xk5ciQAJSUl7NixQ5Lk+WBU92dlJTtN8zuGn3id22h93Q4OZLZh3/AzHPX74sXQv/9vQGPWfP6/vXuPi6Lc/wD+2QVE2AUMBI781DCVJUER9RxTMfOWlXZR0+zYxbIyS6k0s6xE0kSz1KSblZF1KvOknbKLp4tl2eWoJ6RQM32t10x2wUO4C8qyzO+PcYdddvYGy+4OfN6vly93Z2dmn2GU5/nO8zzfB/4ZCSiXsM/zMW0r7w4RkSsM6oPMXWK05s5Ddxfw+1L5dUAVXsESXI8vAQDb0Q9nESl9rlL9JHucuzVlq6vPoqLiIDQatVQWV7kDxM+UkQWfiIiab/ny5Rg+fDhSUlJgMBhQWFgItVqNcePGISYmBhMnTsSyZcsQFxcHrVaLJUuWIDs7m0G9F+x70W2Sk0uhhhUPYT0W4yWEwwo9/g9TplZjF+SDbbkg3NOUQtbfREQtg0F9kLlLjCYX8AMN89F1Op3TEDh/PRCQ7NiBis63QH3iOISICDxouRerMBUC1NDrM1BebsHf/vabwyFGoxVArWyFn5nZkMxm9+7G1y0OOZd7SMCn8UREbcepU6cwZ84cVFZWIj4+Hv3798fGjRsRHx8PAFiwYAHUajVyc3NRW1uLnJwc5OXlBbnUymPrYe8EI97E4xiJXQCAtzEGM/EIqhDjsP8ffzgeX1aWCY0mTGrLeJp2567+dtXmcUev74WkJPmEfUREbQmD+hAmF/CbTFlQqc6hokIM/qOjwxod4/qBgE9LowkC8OSTQF4e1PX1OIguuNGyFP9FL2kXufnvgGPg7gt3PfVERNR2rFq1yu3nkZGRyMvLYyDvA1e96GGfb8WJhGlQV5RDiIrGbTXzsB5XQy4r/a23Om6zPbxvqZV3PLnoon1+TQJMRKRUDOpDhL8TozV7aTSVSnwkX18P3HQT+v3jLpig8Vv5DIY0HDt2wGGbp9EFbS1ZHhERkb+46kW/BgfwAcqBvn1x+vk3sH6IpUnnFoR+ze5QMJutfMBPRNQEDOpDkFzWWPuAv7racX+/PhCorQXanU9y9/TTwMiRwIQJOPVSwxN+X7Pzy2nK8jN8Ek9ERNR8EbBI68x/iMswEU9h04+56NhefgSet+Tq6eTkXzz2psvN83entPRiaVQg5+wTETGob/W8DvjPngXmzQP27gU+/xwICwOiooAJE6TzNCZmvlU5BfmlpelITRUT6TV+CGCbfwecczqfu/l09ll2iYiIyDcmUxYgCLCuex2n71+IIXgNxWUjzz9kzwIimx4QN2ckna8BPeA4zY85d4iIGNSHlKBljd2/H7jhBuCX8xXjV18Bo0Z5PMxVeaKj5Yf52z+pbzzawNX5OFeOiIio+TR1JmDmTOCddxALIBcboNGMdqhj5dexz5By6GzcKGDy5IZ59Y0T5YnHWs9/1ls6h6u2jNxwe72+FwCV9J224ftms7VJy94REbUFDOqDqPEw++ZkjW0SQQDWrQNyc4GaGiApCVi/3m1Ab0vCp9WWQKstOV/5Ou/DOXFEREQhYudOYMoU4PBhCGFhWGC9G0/hVsxqtJv8OvbhEIR+qK6uxk8/7Xfa33aMux53ubaMq/3tl8EVv0MtfU+zkwATEbVSDOpbGbn5+HLbUFkJzJgBbNwoHjh6NPDGG8Bf/uLT9zWufAHnytvXhxH+ThpIRETUJtXXi/lxHn0UqKsDLrwQqnfeQcGgQSjw8hS29oPBkOawvbkj6Xwdcm/flrGfkudTEmAiolaKQX0QuBpmr9f3cgqS9foMJCW1wG2aOhX45BMgPFxcuu7BBwG1+yfdcuUmIiKiEFVYCMyfL76ePBlYuxbo0MHjYbaH641706OiALM5HdHR0dI2ubaBXp8BQJDaNE3pTef0OyIi7zGoDwJPw+ztVVdb4ek22Ve6YkUqMhjqoNFYZefoqxY+iegjR4DXXgMGDvR4XlfTA+RwKBwREVEIuPNO4K23xJF5t98uLlfrBVedDzU14t92Mb2LIfSOWfTletNdJcdtPE9fvkNBJR3PwJ+IiEF9yMvM/FV6bT8kvaYG0GjEz+yHodlXpPavO8GIHBQjObnh3IL1F4+98za+zJH3ZvkaIiIi8rPaWvFh/V13ifV7dDTw448u63rZ6XmQD9S7dTsEQAXgN79MkXPVRmiceC/g+YaIiBSIQX0QmExZfs3i6mk4/FX4Fq9jETrgDI6iE3ait/iBm0q+cfnMZkF6bZ8J11VWWq22hIE9ERFRoBw6JCbD++9/gT//bBh27+XD+6bylLzOl3YA2w1ERE3DoD4IXK35bjYLTkPW9PpeSEqKkN6bzVZUV4tD4GzkktUBgH5/DySvegzRLxcCAIqhwyff9Uf7rIvdls/zULqGAN++0rZfvsZWVttnRERE1EL+8Q9xuTqTCYiPB9LT3e7uaQlduUD98OEeOHHiIHQ6ncO55Op4X5LXeUqOy4z3RESeMagPMHfJ5jQa57luSUkRLoahuZ8X1xNH0XXKHQgrKQYArMaNmI9c1A6pBVAiVZKuyueO/UMEg8Hi8qGCreeeT96JiIhawJkzwKxZ4uo1AHDppeIc+s6d3R7WlCHtGo0aUVEIeDDt7qGB2WyFSvUTALY1iKhtY1AfYK7XcPXPUHy9vhcWXrQCL6IAYSU1QEICzr60Dg9M6tKs8rniTeWu1ZZwzhsREZE/7dkDTJokDrtXq4FFi4AFC4Cw4AS2XI6WiCh4OHYpxNjWdbf9afzUuawsE4cP98C77zYMgd+5s2EoXFJSBN5cHQstarANA5BS8RaqLr0SJlMWysp6S/uZzfXS3HlflZY2DN83Gn0/noiIiPzg2DGgSxdg+3bg8ce9DuhNpiyYTFkOK+bY6PW9pPaBLVAX2yPBbTLalwWw5f9xnD7Q1HYNEZHSsac+wJo7N6yhR79h+P3f/nYAEbDAgvNz73NzcTYuEaNv64l6hMmOAnA1zM7VEjN6fS9pmH1m5n5pu/3rxjjnjYiIyI9qa4F27cTXffsC778PXHKJOI/eB7YOg4suksuh0zClzl3Pu6vM+f7a3x1mxCcicqSoiKuwsBA6nc7hzxVXXCF9fu7cOeTn52PgwIHIzs7G7NmzUV5eHsQSO7Mt1eIY7ArQakug1Za4fcIs95kK9ZiH9diDG6GFWdyvuh5VV01CPbyrMFWqnxyS2jmXr2lz6Gxz3jjHjYiIqJk+/xzo0QPYvbth21VX+RzQExFR66O4nvqePXuiqKhIeh9mN9Rs6dKl2L59O1avXo2YmBgsXrwYs2bNwoYNG4JRVL+yf8INAB98IOCuayvwBhbicvwHAFC+sgTttRqvzicOxRe8nsuv0YTJ9uKXll4s9db7ek4iIiLywGIBHnsMeOop8f2SJcC//uWXUzdl9KDZXA9BcB76btP4Qb6nTPtNefDPjPhERI4UF9SHhYUhMTHRafuZM2ewadMmPP300xg0aBAAMci/6qqrsGfPHvTt2zfAJXWvcZBs0zgrvi2Q1+t7OWxP+ul7/Iw8JOF/qEYkwp5bg8h77gTmFHtZAgH2Q/gdy2B1CszN5nq75esaKs3ExIbKODn5F5hMWRz2RkRE5A96PXDjjcDOneL7u+8GVq702+mbshxdUtJvTtvcDX1vzlB5V0P2m7uMHhFRa6O4oP7o0aPIyclBZGQk+vbti7lz5yIlJQWlpaWwWCwYPHiwtG/37t2RkpLil6BeEARUV1c3s/SOtNpfnbbZV3QGQ5r02jbHLQIWLMVzuCT/HwCAEvTEFBTgm8ljoKmpkY4xm+vRrdshAOLashqN2mFb46Dd/nvluPq8uvpso/c1UKk8Pymvqalx+FuJlH4NSi8/wGsIFbyGwBIEwfNOpHzvvAPMmCEuW9ehA7BuHTBhQrBLRUREIUhRQX2fPn1QUFCAbt26wWg04vnnn8fUqVOxZcsWlJeXIyIiArGxsQ7HJCQkwGg0Nvu76+rqsH+/66RwTeN+rfk9ew447bMMhZiDtwAAhbgB83AfziESe/YcQFSUuE9UFCC2S8VjT5w4KH22ezcwYID77/XGt98K0rk/+wy4/HKVVGb7cnhy5MiRZpcl2JR+DUovP8BrCBW8hsCoq6sLdhGopW3dCvz97+LrnBxx7fmuXVvs63xZjs5gSIMgtJOdaldWlum0rWlD/L0bss9l9IiIRIoK6ocNGya9Tk9PR1ZWFoYPH45PP/0U7du3b9HvDg8Px8UXX+x5Rx8YDGIF1bhX3fbaFijbW45bMQY/YAHuxYe4TNpuv6/ZnH6+8hOHyOl0OofK09P3urJ370XIyNADADp37im7v1yZDYY0p8q7pqYGR44cQWpqKqK8if5DkNKvQenlB3gNoYLXEFjh4YqquqkpLr8cGDsWGDBAnE8fxHtuPwT+s8+AhIR6dOvmKneOyiGpr+PQ+YZ2gP1Qebkh9sxuT0TkG0W3DGJjY5Gamopjx45h8ODBsFgsqKqqcuitr6iokJ2D7yuVSoXo6Ohmn8ee7XTR0Q0VYGKiY6I7Lcy4Hl/idVwDADAgAb3xLgQ3CxdER0cjOtp1pefN98qxBfQAPD4AcPy+KERHy89zi4qK8vvPNdCUfg1KLz/AawgVvIbAUKmaP9qKQowgAEVFwA03ABoNoFYDH34o/h1k9kG6+ODedf1vH3jbeuiJiKjlBb+2aAaz2Yzjx48jMTERmZmZiIiIwA8//CB9rtfrcfLkyZBLkueJyZQFkykLFZ9Z8F/chCLko+zZvdLnAtT47DMBhw/3kLaVlfWWjmvu94pZ7L1nv79e3wtlZZnQ6zOkbWZzPcxmq9vl+oiIiNokoxG4+mpg+nQgN7dhe5ADelu93TiBr/fHOw+dtyXT1WjCZM9vay+UlWU6tUf80c4hImqtFNVTv3z5cgwfPhwpKSkwGAwoLCyEWq3GuHHjEBMTg4kTJ2LZsmWIi4uDVqvFkiVLkJ2dHfJBvdOcsPp6YPVqRD/8MOJhwTEkI6ZbZ4djoqLgcihbk79Xhn3l6c18OFtCP3scMkdERCTjq6+AqVOBP/4AIiOBfv3EXvsQGI0hNwTeF/Z1v1w7wNch9sxuT0TkmqKC+lOnTmHOnDmorKxEfHw8+vfvj40bNyI+Ph4AsGDBAqjVauTm5qK2thY5OTnIy8sLcql9ZDAA06YBn34KFYDNGI478DiOj7gUJlNDJTh0qAqHDzc83ZZb8sVfPC0dwx54IiIiH1gsQH4+sHSpGMSnpwMbNgBZ7IUmIiLfKSqoX7VqldvPIyMjkZeXp7xA3uarr8Rst6dOAe3bA6tWYcKMGRhT3ZDYrjFbT3pzn6jb8zWbrP3+9hlrvc1yS0RE1GYcPy7OnbdNF7zjDmD1anEufSsl1w7wJis+s9sTEXlHUUF9a3f2fya0P3UKpeiOi7ZvQvTf3AfscsnqbPuWlWUiKamdtF0uu6yvvKlcPfXqExERtWnh4cChQ0BcHPDyy8DkycEukSyTKcvrDgOTKcspOAcEadk7uXYA2wtERP7DoD7YamuBdmLwbR1zFa7HcnyCITBmOK/16ovk5FI+3SYiIgoFdnU9OnUCNm0CunQBUlODWix3NJowmExZMBgssvlyGu/r+J6j84iIAom/dYPpnXeAnj1RvV8vZYDdhFGoQZRDxvimZno1m60wGGpdZpdt6lx4s9kKleonqFQ/uTyHrVffluWWiIioTfr5Z6BvX+Cf/2zYNnRoSAf0NhpNGJKSItzuo9f3km1TeNsOYHuBiKj52FMfDCaTuGxNUREA4JVej+J+zHPYpXEGWHFom1UayuYNV8PmmI2eiIiohQkC8MILwNy5wLlzwKJFwIQJQJiyAldbj72rNoV9L74vbQr7aYFlZZlS+6YlEv4SEbV27KkPtOJiYMAAMaBXq4GFCzEXD3g8TKMJC2glJ9cb725NWWbAJyIiOq+iAhg/Hpg1Swzox40Dtm9XXEBvI64rn+71/t6M6CMiIv9hT32gCAKwZg3w0EPi3Lr/+z/grbeAYcPw50OeM8bbP9H2hl6fgYsu2nv+XJkAVM3ORu/rmrJERERtzvbt4trzv/8uzqNfsQKYPTsk1p5vrm+/FaDT6SAIkU1uU9ivkmNjNFrtPm/Yzh57IiLvMKgPlJdfBu6/X3x97bXAunVAQgKAlsoAK9i9Vjm8T07+xeXwNoOh1mmIv8FgQVJSM4pCRETUFhw8CIwYAdTXA2lp4trz2dnBLpXfREWJ7RNBsF92rqG9IhewNw7S5ToIMjP3S6/ZWUBE5DsG9YFy663ikPubbwbuucfrJ/ZyFeSuXan461+PuD3Ofo6bfQXpidycfftzyS1bwyy3REREAHr2BO69V8yds2YNoNUGu0QBxRF9RETBwaC+pVgsYhA/fbo4h659e+C779zOp5NbB16ugvQU0Huj8ZNzb+e8yS1bw+FxRETUZr3/vpgrp0sX8f2qVYqdO+8tufaKt2wr+th3EJSWXiz11rOzgIjIdwzqW8KRI8Df/w788ANw6hSwcKG4vYUr+bKy3mgYZq9y20Pf+Mm5L/P1iYiI2ryaGmDOHOCll4BLLwW2bRPr+VYe0LsjF7A3DtLlOgISE8PsPmdnARGRrxjU+9s//wnceSfw559AbCyQ7n22WDlyFeThwz1w4sRB6HQ6REdHSQG53Ly2ltCcJ/RERESKV1oKTJkC7BUT0mLQIHEefRsO6IGWyhFERESeMKj3l+pqMRHeK6+I7y+5BHj7baBbt2ad1lUF2ZCsxvM5ysoyzw+xd/3k3PbwwGCwOMyhB8Rhcamp7ZpxFURERK2AIABr1wIPPACcPQskJwNvvgmMHh3skilO4w4CdhYQETUdg3p/2LsXmDQJ2L9fTID3yCPAokVARESLf7WrXnNPvemNn5zbXstluU9Nbcen7ERE1Lb9+aeYJ2fTJvH9FVcA69fLV5xtHEf0EREFFoN6fxAE4PBhoFMn8Yn9yJF+/wr7CrK6utpv5zWbrdLwfVtvPRERETXSrh3w66/iA/tly8TReWomdCMiouBjUN9UFktDT3xmJrB5s5j9NjExuOVyw5sn53y6TkREdJ71fH6asDBxkfZ33xUT5A0YENxyERER2eEj5qbYvh1ISxOz29tceWVIB/SNmc3W83/q7bbVS9uJiIjatBMnxJF3y5c3bMvIYEDfDGazFSrVT1CpfmJbg4jIjxjU+6KuDsjLA0aMEJetW7Qo2CVqMq22BFpticPSdsnJv0jbiYiI2qwPPgCyssSH+CtWAJWVwS5Rq6PVljCwJyLyEw6/95bVCgwfDuzYIb6fNg0oLAxqkYiIiMiPBAGYPRt47jnxff/+wDvvAB06BLVYSmcL3u1HB9pvZzJeIqLmUQmCN4uitU29evWC9fx8OpUgIN5qFbPbx8YC7dsHrVyCIKCurg7h4eFQqVRNPId4HkEAysvrpO0dO4ZDpQJUKhWaeGovv7/51xBsSr8GpZcf4DWECl5DYJ0+fRq2qjssLAz79u3zcAS541DXA4ivO18nRkcDWi1atDJUkOb8Hykrs7j9PCkpos3/mJX0O0ip+DNuefwZ+4+vdT176t2or294oiyoVKgIP//jMpvFP61EuN2/Ao4wJCJSDvt6iprGoa4HGur62lrg9OngFKqVCffQ2uSPmYjINW/qes6pJyIiIiIiIlIo9tS7ERERAYtFHDKmVqvRgXPqiIgoyCorK6Wn9hG2pVWpyVjXExFRqPG1rueceiIiIiIiIiKF4vB7IiIiIiIiIoViUE9ERERERESkUAzqiYiIiIiIiBSKQT0RERERERGRQjGoJyIiIiIiIlIoBvVERERERERECsWgnoiIiIiIiEihGNQTERERERERKRSDeiIiIiIiIiKFYlBPREREREREpFAM6omIiIiIiIgUikE9ERERERERkUIxqA9RhYWF0Ol0Dn+uuOIK6fNz584hPz8fAwcORHZ2NmbPno3y8vIgltjZiBEjnK5Bp9MhPz8fAHDzzTc7fbZw4cKglnnXrl24++67kZOTA51Ohy+++MLhc0EQ8OyzzyInJwd9+vTBtGnTcOTIEYd9KisrMXfuXPTr1w8DBgzAggULYDabQ+IaLBYLVqxYgauvvhp9+/ZFTk4OHnroIZSVlTmcQ+7evfzyyyFxDQDw8MMPO5Vv+vTpDvsE8z54Kr/c/wudTodXX31V2ifY92Dt2rWYOHEisrOzMWjQINxzzz3Q6/UO+3jze+jkyZO46667kJWVhUGDBmH58uWoq6sLevkrKyuxePFijBkzBn369MFll12GJUuW4MyZMw7nkbtPH3/8cYuXnygYWkPbI9S0hnZFKFN6eyHUKb0t0JaEB7sA5FrPnj1RVFQkvQ8LC5NeL126FNu3b8fq1asRExODxYsXY9asWdiwYUMwiirrvffeg9Vqld4fPHgQt912m0MDYfLkycjNzZXeR0VFBbSMjVVXV0On02HixImYNWuW0+evvPIK3nzzTSxbtgydO3fGs88+i+nTp+OTTz5BZGQkAODBBx+E0WhEUVERLBYLFixYgIULF+KZZ54J+jWcPXsW+/btw8yZM5Geno6qqio8+eSTmDlzJjZv3uywb25uLiZPniy912g0ASk/4Pk+AMDQoUNRUFAgvW/Xrp3D58G8D57Kv2PHDof333zzDR599FGMGTPGYXsw78HOnTsxdepU9O7dG1arFStXrsT06dPx8ccfIzo6GoDn30NWqxUzZsxAx44dsWHDBhgMBsyfPx8RERGYM2dOUMtvMBik8vTo0QO///47Fi1aBIPBgDVr1jicq6CgAEOHDpXex8bGtmjZiYJJ6W2PUNMa2hWhTOnthVCn9LZAmyJQSFqzZo1wzTXXyH5WVVUlZGRkCJ9++qm07dChQ0JaWppQXFwcoBL6bsmSJcKoUaOE+vp6QRAE4aabbhKWLFkS5FK5lpaWJnz++efS+/r6emHIkCHCq6++Km2rqqoSMjMzhY8++kgQhIb78PPPP0v7bN++XdDpdMKpU6cCV/jzGl+DnJKSEiEtLU34/fffpW3Dhw8XioqKWrh03pG7hvnz5wszZ850eUwo3Qdv7sHMmTOFW265xWFbKN0DQRCEiooKIS0tTdi5c6cgCN79Hvr666+F9PR0wWg0Svu8/fbbQr9+/YRz584FtfxyPvnkEyEjI0OwWCzSNm/uH1Fr0RrbHqGkNbQrQpnS2wtKoPS2QGvG4fch7OjRo8jJycHIkSMxd+5cnDx5EgBQWloKi8WCwYMHS/t2794dKSkp2LNnT5BK615tbS0+/PBDTJw4ESqVStq+ZcsWDBw4EOPGjcMzzzyDmpqaIJbSvRMnTsBoNDr83GNiYpCVlYXi4mIAQHFxMWJjY9G7d29pn8GDB0OtVuPnn38OeJm9YTKZoFKpnHofX3nlFQwcOBDXXXcdXn311ZAbJrVz504MGjQIY8aMQV5eHv73v/9JnynpPpSXl2P79u24/vrrnT4LpXtgG5YeFxcHwLvfQ3v27EFaWho6duwo7ZOTkwOTyYRDhw4FrvBwLr8ck8kErVaL8HDHQWy2YYXXX3893nvvPQiC0KJlJQqm1tT2CHWttV0RalpLeyEUKL0t0Jpx+H2I6tOnDwoKCtCtWzcYjUY8//zzmDp1KrZs2YLy8nJEREQ4BWEJCQkwGo1BKrF7X3zxBc6cOYPx48dL28aNG4eUlBQkJSXhwIEDePrpp3H48GE899xzQSypa7afbUJCgsP2hIQEae5QeXk54uPjHT4PDw9HXFxcSN6bc+fO4emnn8bYsWOh1Wql7TfffDN69eqFuLg4FBcXY+XKlTAajXjkkUeCWNoGQ4cOxejRo9G5c2ccP34cK1euxJ133ol3330XYWFhiroP77//PjQaDS6//HKH7aF0D+rr67F06VL069cPaWlpAODV76Hy8nKHShyA9D6Q90Gu/I2dPn0aL7zwAm644QaH7bm5ubjkkksQFRWFHTt2ID8/H9XV1bjlllsCUXSigGptbY9Q1xrbFaGmNbUXgk3pbYHWjkF9iBo2bJj0Oj09HVlZWRg+fDg+/fRTtG/fPogla5pNmzbh0ksvRXJysrTNvvGs0+mQmJiIadOm4dixY+jatWswitmmWCwW3HfffRAEQUpeaHPbbbdJr9PT0xEREYG8vDzMnTvXaS5aMIwdO1Z6bUt8M2rUKOlpvJJs2rQJV199tTR30iaU7kF+fj4OHjyIt99+O6Df6y+eym8ymTBjxgx0797daU7mvffeK73u1asXampqsG7dOgb11Cq1trYHUWtqLwSb0tsCrR2H3ytEbGwsUlNTcezYMXTs2BEWiwVVVVUO+1RUVCAxMTFIJXTt999/x/fffy87vNheVlYWAHHoXyiy/WwrKioctldUVEhPHDt27IjTp087fF5XV4c///wzpO6NxWLB/fffj5MnT+K1115z6KWXk5WVhbq6Opw4cSJAJfRNly5dcMEFF0j/dpRyH3bv3o3Dhw9j0qRJHvcN1j144okn8PXXX2P9+vX4y1/+Im335vdQx44dnTLg2t4H6j64Kr+NyWTCHXfcAY1Gg+effx4RERFuz5eVlYVTp06htra2pYpMFDKU3PZQgtbUrlAKpbYXgk3pbYG2gEG9QpjNZhw/fhyJiYnIzMxEREQEfvjhB+lzvV6PkydPom/fvsErpAubN29GQkICLrvsMrf77d+/H0Do/gfv3LkzEhMTHX7uJpMJJSUlyM7OBgBkZ2ejqqoKpaWl0j4//vgj6uvr0adPn4CXWY4toD969Chef/11XHDBBR6P2b9/P9RqtdMQwVBx6tQpVFZWSv92lHAfAHGFiIyMDKSnp3vcN9D3QBAEPPHEE/j888+xfv16dOnSxeFzb34P9e3bF7/99ptDg/X777+HVqtFjx49glp+QPz/O336dERERODFF190Gi0hZ//+/YiLiwuJEStELU3JbQ8laC3tCiVRanshWJTeFmhLOPw+RC1fvhzDhw9HSkoKDAYDCgsLoVarMW7cOMTExGDixIlYtmwZ4uLioNVqsWTJEmRnZ4dcxVpfX4/Nmzfjuuuuc0g+dezYMWzZsgXDhg1Dhw4dcODAARQUFOCvf/2rVwFOSzGbzTh27Jj0/sSJE1IjPiUlBbfccgtefPFFXHjhhdLSM0lJSRg1ahQAMTnI0KFD8fjjjyM/Px8WiwWLFy/G2LFjHaYeBOsaEhMTkZubi3379mHt2rWwWq3SfCZboFJcXIySkhJccskl0Gg0KC4uRkFBAa655hq3ScYCdQ1xcXF47rnnMGbMGHTs2BHHjx/HihUrcOGFF0rLjgX7Pnj6dwSIDbetW7di/vz5TseHwj3Iz8/HRx99hBdeeAEajUb6dxITE4P27dt79XsoJycHPXr0wEMPPYR58+bBaDRi9erVmDp1aosHxZ7KbzKZcPvtt6OmpgYrVqyAyWSCyWQCAMTHxyMsLAzbtm1DRUUFsrKyEBkZie+++w5r167F7bff3qJlJwqW1tL2CCWtoV0RypTeXgh1Sm8LtCUqgWl8Q9IDDzyAXbt2obKyEvHx8ejfvz8eeOABaa75uXPnsGzZMnz88ceora1FTk4O8vLyQq6Xe8eOHZg+fTq2bt2Kbt26Sdv/+OMPzJs3DwcPHkR1dTU6deqEUaNG4Z577vE4FLwl/ec//5GdKzt+/HgsW7YMgiBgzZo12LhxI6qqqtC/f3/k5eU5XFtlZSUWL16Mbdu2Qa1W4/LLL8djjz0WsDXG3V3DrFmzMHLkSNnj3njjDQwcOBB79+5Ffn4+9Ho9amtr0blzZ1x77bW47bbbAvbL1901LFq0CPfeey/27duHM2fOICkpCUOGDMF9993nkIglmPfB078jAHj33XexdOlS7NixAzExMQ77hcI90Ol0stsLCgowYcIEAN79HrKt/75z505ERUVh/PjxmDt3rlOG+UCX39U9AoAvv/wSnTt3xjfffIOVK1dKwzS7du2KG2+8EZMnT4ZazYFu1Pq0lrZHKGkN7YpQpvT2QqhTelugLWFQT0RERERERKRQ7GogIiIiIiIiUigG9UREREREREQKxaCeiIiIiIiISKEY1BMREREREREpFIN6IiIiIiIiIoViUE9ERERERESkUAzqiYiIiIiIiBSKQT0RERERERGRQoUHuwBEpAw6nc6r/d544w0MHDiwhUtDRERE/sa6nkiZGNQTkVeeeuoph/cffPABvvvuO6ft3bt3D2SxiIiIyE9Y1xMpk0oQBCHYhSAi5XniiSfw1ltv4cCBA273q6mpQVRUVIBKRURERP7Cup5IGTinnoj85uabb8a4ceNQWlqKqVOnIisrCytXrgQgDukrLCx0OmbEiBF4+OGHHbZVVVXhySefxLBhw5CZmYnRo0fj5ZdfRn19fUCug4iIiOSxricKPRx+T0R+VVlZiTvvvBNjx47FNddcg4SEBJ+Or6mpwU033YSysjJMmTIFnTp1QnFxMVauXAmj0YhHH320hUpORERE3mBdTxRaGNQTkV8ZjUbk5+djypQpTTq+qKgIx48fx/vvv4/U1FQAwJQpU5CUlIR169bh9ttvR6dOnfxYYiIiIvIF63qi0MLh90TkV+3atcOECROafPzWrVvRv39/xMbG4vTp09KfwYMHw2q1YteuXX4sLREREfmKdT1RaGFPPRH5VXJyMtq1a9fk448ePYoDBw5g0KBBsp+fPn26yecmIiKi5mNdTxRaGNQTkV+1b9/ep/2tVqvD+/r6egwZMgR33HGH7P62YXpEREQUHKzriUILg3oiCoi4uDhUVVU5bKutrYXRaHTY1rVrV1RXV2Pw4MGBLB4RERE1E+t6ouDgnHoiCoguXbpg9+7dDts2btzo9PT+yiuvRHFxMb799lunc1RVVaGurq5Fy0lERERNw7qeKDjYU09EATFp0iTk5eVh9uzZGDx4MH799Vfs2LEDF1xwgcN+06dPx7Zt23D33Xdj/PjxyMjIQE1NDX777Tf8+9//xpdffon4+PggXQURERG5wrqeKDgY1BNRQEyePBknTpzAe++9h2+//Rb9+/dHUVERpk2b5rBfVFQU3nzzTaxduxZbt27Fv/71L2i1WqSmpmL27NmIiYkJzgUQERGRW6zriYJDJQiCEOxCEBEREREREZHvOKeeiIiIiIiISKEY1BMREREREREpFIN6IiIiIiIiIoViUE9ERERERESkUAzqiYiIiIiIiBSKQT0RERERERGRQjGoJyIiIiIiIlIoBvVERERERERECsWgnoiIiIiIiEihGNQTERERERERKRSDeiIiIiIiIiKFYlBPREREREREpFAM6omIiIiIiIgU6v8BfpqPXRmiQ+8AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# true vs  predicted\n",
        "best_model_true_vs_prediction_plot(y_train.iloc[:,1],\n",
        "                                   y_test.iloc[:,1],\n",
        "                                   lstm_train_pred.iloc[:,1],\n",
        "                                   lstm_test_pred.iloc[:,1],\n",
        "                                   gru_train_pred.iloc[:,1],\n",
        "                                   gru_test_pred.iloc[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ezC2_3oK1go"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUPHG9geK1QN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLv-WD4l4TAn"
      },
      "source": [
        "### **Plot 4: Prediction Plots Given by Best LSTM and GRU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7xwhrUXUC79"
      },
      "outputs": [],
      "source": [
        "def best_model_prediction_plot(time_step,\n",
        "                               data,\n",
        "                               y_train,\n",
        "                               y_test,\n",
        "                               lstm_train_pred,\n",
        "                               lstm_test_pred,\n",
        "                               gru_train_pred,\n",
        "                               gru_test_pred):\n",
        "\n",
        "    # Plot for LSTM and GRU (Train Data Only)\n",
        "    fig_train = plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # LSTM Train Plot\n",
        "    plt.subplot(121)\n",
        "\n",
        "    # # Initialize arrays to plot train predictions\n",
        "    # train_predict_plot_data = np.empty_like(y_train)\n",
        "    # train_predict_plot_data[:] = np.nan\n",
        "\n",
        "    # # Assign train predictions for LSTM\n",
        "    # train_predict_plot_data = lstm_train_pred\n",
        "\n",
        "    # Plot true values and LSTM train predictions\n",
        "    plt.plot(y_train, 'k', linewidth=1.5)\n",
        "    plt.plot(lstm_train_pred, 'mediumblue', linewidth=1.5)\n",
        "    plt.xlabel('')\n",
        "    plt.ylabel('Number of Passengers')\n",
        "    plt.title(\"LSTM\")\n",
        "\n",
        "    plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "    plt.rcParams[\"axes.linewidth\"] = 2.75\n",
        "    plt.rc('xtick', labelsize=10)\n",
        "    plt.rc('ytick', labelsize=10)\n",
        "\n",
        "    plt.legend(['True value', 'Predicted value (Train set)'], loc='best')\n",
        "\n",
        "    # GRU Train Plot\n",
        "    plt.subplot(122)\n",
        "\n",
        "    # # Reinitialize the arrays for GRU\n",
        "    # train_predict_plot_data = np.empty_like(y_train)\n",
        "    # train_predict_plot_data[:] = np.nan\n",
        "\n",
        "    # # Assign train predictions for GRU\n",
        "    # train_predict_plot_data[time_step:len(gru_train_pred) + time_step] = gru_train_pred\n",
        "\n",
        "    # Plot true values and GRU train predictions\n",
        "    plt.plot(y_train, 'k', linewidth=1.5)\n",
        "    plt.plot(gru_train_pred, 'mediumblue', linewidth=1.5)\n",
        "    plt.xlabel('')\n",
        "    plt.ylabel('Number of Passengers')\n",
        "    plt.title(\"GRU\")\n",
        "\n",
        "    plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "    plt.rcParams[\"axes.linewidth\"] = 2.75\n",
        "    plt.rc('xtick', labelsize=10)\n",
        "    plt.rc('ytick', labelsize=10)\n",
        "\n",
        "    plt.legend(['True value', 'Predicted value (Train set)'], loc='best')\n",
        "\n",
        "    # Save the train-only plot\n",
        "    fig_train.savefig(output_dir_path + \"best_model_predictions_train_data.png\", dpi=600)\n",
        "\n",
        "    # Plot for LSTM and GRU (Test Data Only)\n",
        "    fig_test = plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # LSTM Test Plot\n",
        "    plt.subplot(121)\n",
        "\n",
        "    # Plot true values for the test data portion and LSTM test predictions\n",
        "    plt.plot(y_test, linewidth=1.5)\n",
        "    plt.plot(lstm_test_pred, 'darkgreen', linewidth=1.5)\n",
        "    plt.xlabel('')\n",
        "    plt.ylabel('Number of Passengers')\n",
        "    plt.title(\"LSTM\")\n",
        "\n",
        "    plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "    plt.rcParams[\"axes.linewidth\"] = 2.75\n",
        "    plt.rc('xtick', labelsize=10)\n",
        "    plt.rc('ytick', labelsize=10)\n",
        "\n",
        "    plt.legend(['True value', 'Predicted value (Test set)'], loc='best')\n",
        "\n",
        "    # GRU Test Plot\n",
        "    plt.subplot(122)\n",
        "\n",
        "    # Plot true values for the test data portion and GRU test predictions\n",
        "    plt.plot(y_test, 'k', linewidth=1.5)\n",
        "    plt.plot(gru_test_pred, 'darkgreen', linewidth=1.5)\n",
        "    plt.xlabel('')\n",
        "    plt.ylabel('Number of Passengers')\n",
        "    plt.title(\"GRU\")\n",
        "\n",
        "    plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "    plt.rcParams[\"axes.linewidth\"] = 2.75\n",
        "    plt.rc('xtick', labelsize=10)\n",
        "    plt.rc('ytick', labelsize=10)\n",
        "\n",
        "    plt.legend(['True value', 'Predicted value (Test set)'], loc='best')\n",
        "\n",
        "    # Save the test-only plot\n",
        "    fig_test.savefig(output_dir_path + \"best_model_predictions_test_data.png\", dpi=600)\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8sctUNhBR07S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "outputId": "d9eb277f-26f7-48b7-d023-b8d49d20a5fb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "best_model_prediction_plot(5, data1,\n",
        "                                   y_train.iloc[:,1],\n",
        "                                   y_test.iloc[:,1],\n",
        "                                   lstm_train_pred.iloc[:,1],\n",
        "                                   lstm_test_pred.iloc[:,1],\n",
        "                                   gru_train_pred.iloc[:,1],\n",
        "                                   gru_test_pred.iloc[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfEtvqiBR021"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "farUjPq1R0yb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hss4liqPR0vQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88lrEIHV46kd"
      },
      "source": [
        "### **Plot 5: Comparative RMSE Boxplots of Best LSTM and GRU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nylHN4UK5A-X"
      },
      "outputs": [],
      "source": [
        "#Read best rmse files\n",
        "\n",
        "best_lstm_rmse = read_df_from_file(output_dir_path+ 'best_lstm_model_all_rmse.csv')\n",
        "best_gru_rmse = read_df_from_file(output_dir_path+ 'best_gru_model_all_rmse.csv')\n",
        "\n",
        "def best_model_comparative_rmse_boxplots(lstm_rmse, gru_rmse):\n",
        "  data = pd.DataFrame()\n",
        "  data['LSTM'] = lstm_rmse\n",
        "  data['GRU'] = gru_rmse\n",
        "\n",
        "  fig = plt.figure(figsize = (8,4))\n",
        "  p = plt.boxplot(data, patch_artist= True)\n",
        "  colors = ['mediumblue', 'darkgreen']\n",
        "  for i, box in enumerate(p['boxes']):\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = colors[i])\n",
        "  plt.xticks([1,2], ['LSTM','GRU'])\n",
        "  plt.ylabel('RMSE')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "  fig.savefig(output_dir_path+\"comparative_rmse_boxplots.png\",dpi=600)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZBukXq-q5OYL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "fdb6a93f-a74b-41dc-d9b2-8c7770459ebb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "best_model_comparative_rmse_boxplots(best_lstm_rmse.iloc[:,1], best_gru_rmse.iloc[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqD5ngHV5Wil"
      },
      "source": [
        "### **Plot6: All score boxplots**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sdSM6QIW0BO"
      },
      "outputs": [],
      "source": [
        "# Read all scores files\n",
        "lstm_all_rmse = read_df_from_file(output_dir_path +'multiple_lstm_models_all_rmse.csv')\n",
        "lstm_all_mape = read_df_from_file(output_dir_path+'multiple_lstm_models_all_mape.csv')\n",
        "lstm_all_R = read_df_from_file(output_dir_path+'multiple_lstm_models_all_R.csv')\n",
        "\n",
        "gru_all_rmse = read_df_from_file(output_dir_path+'multiple_gru_models_all_rmse.csv')\n",
        "gru_all_mape = read_df_from_file(output_dir_path+'multiple_gru_models_all_mape.csv')\n",
        "gru_all_R = read_df_from_file(output_dir_path+'multiple_gru_models_all_R.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6LjMaq0Wqv4r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUTd2m0D5Xna"
      },
      "outputs": [],
      "source": [
        "def all_scores_boxplot(lstm_rmse, lstm_mape, lstm_R,  gru_rmse, gru_mape, gru_R):\n",
        "\n",
        "  neurons = [8, 16, 32,  64,  128, 256]\n",
        "\n",
        "\n",
        "\n",
        "  fig = plt.figure(figsize = (19,4))\n",
        "  plt.subplot(131)\n",
        "  p1 = plt.boxplot(lstm_rmse.T, patch_artist=True)\n",
        "  for i, box in enumerate(p1['boxes']):\n",
        "    # change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'mediumblue')\n",
        "  plt.xticks([1,2,3,4,5,6], neurons)\n",
        "  plt.title(\"RMSE\")\n",
        "  plt.xlabel('Number of LSTM neurons')\n",
        "  plt.ylabel('RMSE')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "\n",
        "\n",
        "  plt.subplot(132)\n",
        "  p2 = plt.boxplot(lstm_mape.T, patch_artist=True)\n",
        "  for i, box in enumerate(p2['boxes']):\n",
        "    # change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'indigo')\n",
        "  plt.xticks([1,2,3,4,5,6], neurons)\n",
        "  plt.title(\"MAPE\")\n",
        "  plt.xlabel('Number of LSTM neurons')\n",
        "  plt.ylabel('MAPE')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "  plt.subplot(133)\n",
        "  p3 = plt.boxplot(lstm_R.T, patch_artist=True)\n",
        "  for i, box in enumerate(p3['boxes']):\n",
        "    # change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'darkgreen')\n",
        "  plt.xticks([1,2,3,4,5,6], neurons)\n",
        "  plt.title(\"R\")\n",
        "  plt.xlabel('Number of LSTM neurons')\n",
        "  plt.ylabel('R')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "  fig.savefig(output_dir_path+\"lstm_all_scores_boxplots.png\",dpi=600)\n",
        "\n",
        "\n",
        "  fig = plt.figure(figsize = (19,4))\n",
        "  plt.subplot(131)\n",
        "  p4 = plt.boxplot(gru_rmse.T, patch_artist=True)\n",
        "  for i, box in enumerate(p4['boxes']):\n",
        "    # change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'mediumblue')\n",
        "  plt.xticks([1,2,3,4,5,6], neurons)\n",
        "  plt.title(\"RMSE\")\n",
        "  plt.xlabel('Number of GRU neurons')\n",
        "  plt.ylabel('RMSE')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "\n",
        "  plt.subplot(132)\n",
        "  p5 = plt.boxplot(gru_mape.T, patch_artist=True)\n",
        "  for i, box in enumerate(p5['boxes']):\n",
        "    # change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'indigo')\n",
        "  plt.xticks([1,2,3,4,5,6], neurons)\n",
        "  plt.title(\"MAPE\")\n",
        "  plt.xlabel('Number of GRU neurons')\n",
        "  plt.ylabel('MAPE')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "\n",
        "  plt.subplot(133)\n",
        "  p6 = plt.boxplot(gru_R.T, patch_artist=True)\n",
        "  for i, box in enumerate(p6['boxes']):\n",
        "    # change outline color\n",
        "    box.set(color= 'blue', linewidth = 1.2)\n",
        "    # change fill color\n",
        "    box.set(facecolor = 'darkgreen')\n",
        "  plt.xticks([1,2,3,4,5,6], neurons)\n",
        "  plt.title(\"R\")\n",
        "  plt.xlabel('Number of GRU neurons')\n",
        "  plt.ylabel('R')\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "  fig.savefig(output_dir_path+\"gru_all_scores_boxplots.png\",dpi=600)\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYbtkxZd57y_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "86383a22-f1d6-47ee-abd2-dcd1e1aaebe5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1900x400 with 3 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABi0AAAGRCAYAAAAZ0PBjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACS+klEQVR4nOzde1xU5fr///cAgiAKKujGPJCmSCoetoWiRrrVLLVSKz/1MbXM0g5qYbUpD9tT7F3qtq1uTVNTY1dG6lfELA+dy7LSFCUyFU8hAeKRkeP8/vDnfPbEeZhhFvB6Ph4+hlnrXvdc62LAm3XNum+TxWKxCAAAAAAAAAAAwMXcXB0AAAAAAAAAAACARNECAAAAAAAAAAAYBEULAAAAAAAAAABgCBQtAAAAAAAAAACAIVC0AAAAAAAAAAAAhkDRAgAAAAAAAAAAGAJFCwAAAAAAAAAAYAgULQAAAAAAAAAAgCFQtAAAAAAAAAAAAIZA0QIAAAAAAAAAABiCh6sDAFCzbdy4UdHR0dbn7u7uaty4sXr16qVnn31WTZs2te57+OGH9d1336lVq1b6+OOPi/T11Vdf6dFHH5Ukvf766xo0aJB1X3JyspYuXaqDBw8qIyND/v7+uummm9SvXz89/PDD1nb9+vXTmTNnio21d+/eWrVqVaXPGQAAlO6/xwexsbHq3r27zX6LxaLbb79dZ8+e1e2336433njDZv/FixfVq1cv5ebmatu2bWrTpk2R1/jrX/+qTZs2WZ/Xq1dPzZs317333qtRo0bJ09NTkrR48WItWbKkxFi//PJLBQYG2n2uAACg6lTkGgQA46JoAaBKTJo0Sc2bN1dubq7279+vTZs26YcfftDWrVvl5eVlbefl5aUTJ07owIEDCgsLs+kjPj5eXl5eysnJsdn+448/avTo0WrWrJnuv/9+BQYGKjU1VT/99JPWrVtnU7SQpNDQUD3yyCNFYmzSpIkDzxgAAJTFy8tLW7duLVK0+O6773T27FlrYeGPtm/fLpPJpMDAQG3ZskXPPvtsse08PT01d+5cSdKlS5f00Ucf6R//+IcOHjyof/7znzZt//a3v8nHx6dIHw0aNLDn1AAAgAuV9xoEAGOiaAGgStx2223q1KmTJOn+++9Xw4YNtXLlSu3atUt33XWXtV3Lli2Vn5+vrVu32hQtcnJytGPHDt1+++366KOPbPpevny56tevr7i4uCIXFjIzM4vE0rRpU91zzz2OPD0AAGCHyMhIbd++XdOmTZOHx//9abJ161Z16NBB58+fL/a4LVu2KDIyUs2aNdPWrVtLLFp4eHjY/J//0EMP6f7779e2bdv017/+1ebTlnfccYcaNWrkmBMDAAAuVd5rEACMiTUtALjE9U9Unjp1qsi+IUOGaNu2bSosLLRu2717t65evWozJdR1J0+e1E033VTsJyEbN27swKgBAIAjDR48WOfPn9dXX31l3Zabm6uPPvpIQ4cOLfaY3377Td9//73uuusuDR48WKdPn9aPP/5Yrtdzc3PTrbfeKkklThcJAABqntKuQQAwHooWAFzi+oWC4goNQ4YMUXp6ur799lvrtq1bt6pHjx7FFiFuuOEGHTp0SL/88ku5Xjs/P1/nzp0r8u/q1at2ng0AALDHDTfcoC5duighIcG67fPPP9elS5dK/BTk1q1b5e3trb59+yosLEwtW7ZUfHx8uV/z+sUKf39/m+0XLlwoMja4ePFixU8KAAAYTmnXIAAYD9NDAagSly9f1rlz55Sbm6uffvpJS5Yskaenp/r27VukbXBwsDp27KitW7eqZ8+eunjxoj777DPrnNR/9Oijj2r8+PG69957FRYWpj//+c/q2bOnwsPDVadOnSLtv/zyS/Xs2bPI9qioKD3++OOVP1kAAFBuQ4cO1YIFC3T16lXVrVtX8fHxuuWWW0pcKDM+Pl5/+ctfVLduXUnSXXfdpffee08vv/yyzRRT1507d07StbHIhx9+qJ07dyokJEStW7e2aVfc3Zw33nijtm/fXtlTBAAAVawi1yAAGA9FCwBVYuzYsTbPb7jhBr322mv605/+VGz7oUOH6t///rdmzpypjz76SO7u7urfv78OHTpUpG2vXr307rvvasWKFfryyy+1b98+vfnmm2rUqJHmzp2rv/zlLzbtO3furClTphTpp1WrVnafHwAAsM+dd96pV155RZ988on69OmjTz/9VNOmTSu27c8//6xffvlFUVFR1m2DBw/W8uXL9eWXX+r222+3aZ+dnV3kgwpdu3bVa6+9VqTvxYsXy9fX12abt7e3nWcFAABcqaLXIAAYC0ULAFVixowZuvHGG3Xp0iV98MEH2rt3rzw9PUtsf9ddd+kf//iHPv/8c23ZskW33357kQsJ/y0sLExLlixRbm6ufv75Z+3cuVNvvfWWJk+erM2bN+umm26ytm3YsKEiIiIcen4AAMA+jRo1Us+ePbV161ZdvXpVBQUFuuOOO4ptu2XLFvn4+KhFixY6ceKEJMnLy0s33HCD4uPjixQtvLy8tHz5ckmSp6enmjdvXuLFiu7du7MQNwAANURFr0EAMBaKFgCqRFhYmDp16iRJ6t+/vx566CFFRUVp+/btqlevXpH2TZo00a233qo1a9boxx9/1OLFi8v1Op6engoLC1NYWJiCg4MVHR2t7du36+mnn3bo+QAAAMcZMmSIpk+froyMDN12223FzjdtsViUkJCg7OzsYte7OHfunK5cuWIzrnB3d+eDCgAA1EIVvQYBwFhYiBtAlXN3d9dzzz2n33//XbGxsSW2GzJkiL7//nv5+vrqtttuq/DrdOzYUZL0+++/2x0rAABwvgEDBsjNzU379+/XkCFDim3z3Xff6ezZs5o0aZJef/11m39z5syR2WzWzp07qzhyAABgdOW9BgHAOLjTAoBLhIeHKywsTGvXrtWYMWPk5eVVpM2gQYN09uxZ3XjjjaXexrlnzx6Fh4fLZDLZbP/ss88kqchCmwAAwFjq1aunv/3tbzpz5oz69etXbJvrU0M99thjxY4bVq1apfj4eN1zzz3ODhcAAFQz5bkGAcA4KFoAcJlx48Zp8uTJ2rhxox588MEi++vXr69nnnmmzH7mzp0rs9msAQMGqHXr1srLy9OPP/6oDz/8UDfccIOGDx9u0z4tLU3/7//9vyL91KtXT/3797f/hAAAgN2GDRtW4r7c3Fx9/PHHioiIKPEiQ79+/bRu3TplZmaqcePGFX79jz76SD4+PkW29+rVSwEBARXuDwAAGEtZ1yAAGAdFCwAuM3DgQLVs2VKrV6/WAw88YHc/L7zwgrZv367PPvtM7733nvLy8tSsWTM99NBDmjhxYpF5sZOSkvTCCy8U6eeGG26gaAEAgAF9+umnunjxovr27Vtim759+2r16tVKSEjQ6NGjK/waf/vb34rdvm7dOooWAADUAH+8BuHu7u7qkACUwGSxWCyuDgIAAAAAAAAAAICFuAEAAAAAAAAAgCFQtAAAAAAAAAAAAIZA0QIAAAAAAAAAABgCRQsAAAAAAAAAAGAIFC0AAAAAAAAAAIAheLg6gJqmU6dOysvLkyS5ubnJ39/ftQEBAFBO58+fV2FhoSSpTp06OnjwoIsjqjkYHwAAqivGB87D+AAAUF05e3xA0cLB8vLyZLFYJEkFBQXKzMx0cUQAAFTc9T+g4RiMDwAANQHjA8difAAAqAmcMT5geigAAAAAAAAAAGAI3GnhYG5ubiooKJAkmUwmNWrUyMUR2bJYLMrPz5eHh4dMJpOrw6lWyJ39yJ39yJ19yJt9zp07Z/20n5sbn2twJMYHNRe5sx+5sw95sx+5sw/jA+dhfFBzkTv7kDf7kTv7kTv7OHt8YNiixYoVK7RgwQKNHj1aL7/8siTp4Ycf1nfffWfTbuTIkZo9e3aJ/fz1r3/Vpk2bbLb17t1bq1atsj4/f/685syZo08++URubm4aOHCgXn75ZdWrV6/Ccfv7+1tv6WzUqJG+/vrrCvfhTNnZ2UpKSlJoaKh8fHxcHU61Qu7sR+7sR+7sQ97sExERYf0/jDmVHYvxQc1F7uxH7uxD3uxH7uzD+MB5GB/UXOTOPuTNfuTOfuTOPs4eHxiyaHHgwAG9++67CgkJKbLvgQce0KRJk6zPvb29y+yvT58+iomJsT739PS02T916lSlp6drzZo1ysvL00svvaQZM2ZowYIFlTgLAAAAAAAAAABQEYa7t/PKlSt6/vnnNXfuXPn5+RXZX7duXQUGBlr/+fr6ltmnp6enzTH/3e/Ro0f1xRdfaO7cuercubO6d++uadOmKSEhQWlpaQ49NwAAAAAAAAAAUDLD3Wkxe/ZsRUZGKiIiQsuWLSuyPz4+Xlu2bFFgYKD69u2rJ598ssy7Lb777jv17NlTDRo0UI8ePTRlyhQ1bNhQkrRv3z41aNBAnTp1sraPiIiQm5ubDhw4oAEDBth9LhaLRdnZ2XYf7wxms9nmEeVH7uxH7uxH7uxD3uxzfT5KAAAAAAAAVzFU0SIhIUGHDx9WXFxcsfuHDBmiZs2aqUmTJkpOTtb8+fN1/PhxLVmypMQ++/TpowEDBqh58+Y6deqUFi5cqPHjx+u9996Tu7u7MjIyiix25eHhIT8/P6Wnp1fqfPLz85WUlFSpPpwlJSXF1SFUW+TOfuTOfuTOPuStYvLz810dAgAAAAAAqOUMU7RITU3VvHnztHr1anl5eRXbZuTIkdavQ0JCFBgYqLFjx+rkyZNq2bJlsccMHjzY5piQkBD179/feveFM3l4eCg0NNSpr1FRZrNZKSkpCg4OLtd6IPg/5M5+5M5+5M4+5M0+Hh6GGRYAAAAAAIBayjBXJw4dOqTMzEwNHz7cuq2goEB79+5VbGysDh48KHd3d5tjOnfuLEk6ceJEiUWLP2rRooUaNmyoEydOqGfPngoICNC5c+ds2uTn5+vChQsKDAys1DmZTCbDrjrv7e1t2NiMjtzZj9zZj9zZh7xVjMlkcnUIAAAAAACgljNM0aJHjx6Kj4+32RYdHa3WrVtr/PjxRQoWkqxTL1WkuHD27FmdP3/eekzXrl118eJFJSYmqmPHjpKkPXv2qLCwUGFhYfaeDgAAAAAAAAAAqCDDFC18fX3Vrl07m20+Pj7y9/dXu3btdPLkScXHxysyMlL+/v5KTk5WTEyMbrnlFrVv3956zKBBgxQVFaUBAwboypUrWrJkie644w4FBATo1KlTeu2119SqVSv16dNHktSmTRv16dNH06dP16xZs5SXl6c5c+Zo8ODBatq0aZXmAAAAAAAAAACA2swwRYuy1KlTR998843WrVun7OxsBQUFaeDAgXryySdt2h0/flyXLl2SJLm7u+uXX37R5s2bdenSJTVp0kS9evXS5MmT5enpaT1m/vz5mjNnjsaMGSM3NzcNHDhQ06ZNq9LzAwAAAAAAAACgtjN00WL9+vXWr4OCgvT222+XeUxycrL167p162rVqlVlHuPv768FCxbYFyQAAAAAAAAAAHAIQxctgKpy7NgxnT9/vtQ2ZrNZBw8e1NWrV+Xt7V1qW39/f7Vu3dqBEQIAgKrG+AAAAAAAqh5FC9R6GRkZatu2rQoLCx3Wp7u7u86ePauAgACH9QkAAKoO4wMAAAAAcA2KFqj1AgICdOTIkTI/Sbl//36NGzdOq1atUpcuXUpt6+/vzwUJAACqMcYHAAAAAOAaFC0AqVxTNZjNZklSSEiIunXr5uyQAADltHfvXq1atUqJiYlKT0/X0qVL1b9/f+v+xYsXKyEhQWfPnlWdOnXUoUMHPfvss+rcuXOJffbr109nzpwpsv2hhx7SzJkznXIeMB7GBwAAAABQ9ShaAACAai07O1shISEaMWKEnn766SL7g4ODNWPGDLVo0UJXr17VW2+9pUcffVQ7duxQo0aNiu0zLi5OBQUF1udHjhzRI488okGDBjntPAAAAAAAAEULAABQzUVGRioyMrLE/UOHDrV5Hh0drbi4OCUnJ6tnz57FHvPHYsaKFSvUsmVL3XrrrZUPGAAAAAAAlMjN1QEAAABUldzcXL333nuqX7++QkJCyn3Mli1bNGLECJlMJidHCAAAAABA7cadFgAAoMb75JNP9Nxzz8lsNiswMFCrV68ucWqoP9q5c6cuXbqkYcOGOSQWi8Wi7Oxsh/TlKNfXZbj+iPLLycmxPhrt+2p0vO/sQ97sR+7sY7FYXB0CAACoZShaAACAGi88PFybN29WVlaWNmzYoClTpuj9999X48aNyzz2gw8+0G233aamTZs6JJb8/HwlJSU5pC9HS0lJcXUI1U5qaqr10ajfV6PjfWcf8mY/clcx+fn5rg4BAADUMhQtAABAjefj46NWrVqpVatW6tKliwYOHKi4uDg98cQTpR535swZff3111q8eLHDYvHw8FBoaKjD+nMEs9mslJQUBQcHy9vb29XhVCsXLlyQJAUFBRnu+2p0vO/sQ97sR+7s4+HBZQMAAFC1GH0AAIBap7CwULm5uWW227hxoxo3bqzbb7/dYa9tMpnk4+PjsP4cydvb27CxGZWXl5f1kdzZh/edfcib/chdxbCeEwAAqGoULQAAQLV25coVnTx50vr89OnTSkpKkp+fn/z9/bV8+XL169dPgYGBysrKUmxsrNLS0jRo0CDrMWPGjNGAAQM0atQo67bCwkJt3LhR9957L58yBQAAAACgivAXOAAAqNYSExM1evRo6/OYmBhJ0rBhwzRr1iwdO3ZMmzZtUlZWlvz9/dWpUyfFxsaqbdu21mNOnTqlrKwsm36//vpr/fbbbxoxYkTVnAgAAAAAAKBoAQAAqrfw8HAlJyeXuH/JkiVl9rF79+4i23r37l1qvwAAAAAAwPHcXB0AAAAAAAAAAACARNECAAAAAAAAAAAYBEULAAAAAAAAAABgCBQtAAAAAAAAAACAIVC0AAAAAAAAAAAAhkDRAgAAAAAAAAAAGAJFCwAAAAAAAAAAYAgULQAAAAAAAAAAgCFQtAAAAAAAAAAAAIZA0QIAAAAAAAAAABgCRQsAAAAAAAAAAGAIFC0AAAAAAECNFBsbq379+qlTp066//77deDAgVLbf/jhhxo0aJA6deqkoUOH6rPPPiux7YwZMxQSEqK33nrLwVEDAFC7UbQAAAAAAAA1zrZt2xQTE6OnnnpKmzZtUvv27TVu3DhlZmYW2/7HH39UVFSU7rvvPm3evFl/+ctf9NRTT+mXX34p0nbHjh366aef1KRJE2efBgAAtQ5FCwAAAAAAUOOsWbNGDzzwgEaMGKGbbrpJs2bNUt26dfXBBx8U237dunXq06ePHnvsMbVp00ZTpkzRzTffrLffftumXVpamubMmaP58+erTp06VXEqAADUKh6uDgAAAAAAAMCRcnNzdejQIT3xxBPWbW5uboqIiNC+ffuKPWb//v0aO3aszbbevXtr586d1ueFhYV6/vnnNW7cOLVt29Zh8VosFmVnZzusP0cwm802jyg/cmcf8mY/cmc/cmcfi8Xi1P4pWgAAAAAAgBolKytLBQUFaty4sc32xo0b69ixY8Uek5GRoYCAgCLtMzIyrM9XrlwpDw8PjR492qHx5ufnKykpyaF9OkpKSoqrQ6i2yJ19yJv9yJ39yF3F5OfnO7V/ihYAAAAAAABlSExM1Lp167Rx40aZTCaH9u3h4aHQ0FCH9llZZrNZKSkpCg4Olre3t6vDqVbInX3Im/3Inf3InX08PJxbVjBs0WLFihVasGCBRo8erZdfflmS9PDDD+u7776zaTdy5EjNnj272D7y8vK0aNEiff755zp16pR8fX0VERGhqKgoNW3a1NquX79+OnPmjM2xUVFRevzxxx18VgAAAAAAwNkaNmwod3f3IotuZ2ZmFrmb4rqAgACbuyr+2P77779XZmam+vbta91fUFCgf/zjH1q3bp12795td7wmk0k+Pj52H+9M3t7eho3N6Midfcib/cid/chdxTi6eP9HhixaHDhwQO+++65CQkKK7HvggQc0adIk6/PSKmBXr17V4cOHNXHiRLVv314XL17UvHnzNHHiRG3cuNGm7aRJk/TAAw9Yn9erV88BZwIAAAAAAKqap6enOnTooG+++Ub9+/eXdG09im+++UajRo0q9pguXbpoz549NutafP311+rSpYsk6Z577lFERITNMePGjdM999yj4cOHO+U8AACojQxXtLhy5Yqef/55zZ07V8uWLSuyv27dugoMDCxXX/Xr19eaNWtstk2fPl3333+/fvvtNzVr1sy6vV69euXuFwAAAAAAGNsjjzyiF198UR07dlRYWJjWrl0rs9lsLTC88MILatq0qaKioiRJo0eP1sMPP6zVq1crMjJS27ZtU2JionV2h4YNG6phw4Y2r1GnTh0FBASodevWVXtyAADUYG6uDuCPZs+ercjIyCKfXrguPj5e4eHhGjJkiBYsWFDhld0vX74sk8mkBg0a2GxfuXKlwsPDde+99+rNN990+mIiAAAAAADAee666y69+OKL+te//qV77rlHSUlJevPNN63TPaWmpio9Pd3avlu3bpo/f77ee+893XPPPfroo4+0dOlStWvXzlWnAABArWSoOy0SEhJ0+PBhxcXFFbt/yJAhatasmZo0aaLk5GTNnz9fx48f15IlS8rVf05OjubPn6/BgwfL19fXuv3hhx/WzTffLD8/P+3bt08LFy5Uenq6oqOjK3U+FotF2dnZlerD0a4XeSpa7MG198/1R6N9X42O9539yJ19yJt9LBaLq0MAAABwqFGjRpU4HdT69euLbLvzzjt15513lrv/yqxjAQAAimeYokVqaqrmzZun1atXy8vLq9g2I0eOtH4dEhKiwMBAjR07VidPnlTLli1L7T8vL0+TJ0+WxWLRrFmzbPY98sgj1q/bt2+vOnXqaObMmYqKipKnp6fd55Sfn6+kpCS7j3emlJQUV4dQ7aSmplofjfp9NTred/Yjd/YhbxXDXYYAAAAAAMDVDFO0OHTokDIzM20WryooKNDevXsVGxurgwcPyt3d3eaYzp07S5JOnDhRatEiLy9PU6ZM0W+//aa1a9fa3GVRnM6dOys/P1+nT5+u1LyUHh4eCg0Ntft4ZzCbzUpJSVFwcHCpi5ijqAsXLkiSgoKCDPd9NTred/Yjd/Yhb/bx8DDMsAAAAAAAANRShrk60aNHD8XHx9tsi46OVuvWrTV+/PgiBQtJ1k+7l7aA9vWCxYkTJ7Ru3boii2YVJykpSW5ubmrcuHEFz8KWyWSSj49PpfpwFm9vb8PGZlTX7wDy8vIid3bifWc/cmcf8lYxJpPJ1SEAAAAAAIBazjBFC19f3yKLW/n4+Mjf31/t2rXTyZMnFR8fr8jISPn7+ys5OVkxMTG65ZZb1L59e+sxgwYNUlRUlAYMGKC8vDxNmjRJhw8f1htvvKGCggLrIlt+fn7y9PTUvn379NNPP6lHjx6qV6+e9u3bp5iYGN19993y8/Or0hwAAAAAAAAAAFCbGaZoUZY6derom2++0bp165Sdna2goCANHDhQTz75pE2748eP69KlS5KktLQ066JY99xzj027devWKTw8XJ6entq2bZuWLFmi3NxcNW/eXGPHjrVZ5wIAAAAAAAAAADifoYsW69evt34dFBSkt99+u8xjkpOTrV83b97c5nlxOnTooA0bNtgfJAAAAAAAAAAAcAg3VwcAAAAAAAAAAAAgUbQAAAAAAAAAAAAGQdECAAAAAAAAAAAYAkULAABQre3du1cTJkxQ7969FRISop07d9rsX7x4sQYNGqQuXbrolltu0dixY/XTTz+V2W9aWpqmTp2q8PBwhYWFaejQoTp48KCzTgMAAAAAAMjgC3EDAACUJTs7WyEhIRoxYoSefvrpIvuDg4M1Y8YMtWjRQlevXtVbb72lRx99VDt27FCjRo2K7fPChQt68MEHFR4erpUrV6phw4Y6ceKE/Pz8nH06AAAAAADUahQtAABAtRYZGanIyMgS9w8dOtTmeXR0tOLi4pScnKyePXsWe8zKlSv1pz/9STExMdZtLVq0cEzAAAAAAACgRBQtAABArZGbm6v33ntP9evXV0hISIntdu/erd69e2vSpEnau3evmjZtqoceekgPPPBApWOwWCzKzs6udD+OZDabbR5Rfjk5OdZHo31fjY73nX3Im/3InX0sFourQwAAALUMRQsAAFDjffLJJ3ruuedkNpsVGBio1atXlzg1lCSdOnVK77zzjh555BFNmDBBBw8e1Ny5c1WnTh0NGzasUrHk5+crKSmpUn04S0pKiqtDqHZSU1Otj0b9vhod7zv7kDf7kbuKyc/Pd3UIAACglqFoAQAAarzw8HBt3rxZWVlZ2rBhg6ZMmaL3339fjRs3Lra9xWJRx44d9dxzz0mSbr75Zh05ckTvvvtupYsWHh4eCg0NrVQfjmY2m5WSkqLg4GB5e3u7Opxq5cKFC5KkoKAgw31fjY73nX3Im/3InX08PLhsAAAAqhajDwAAUOP5+PioVatWatWqlbp06aKBAwcqLi5OTzzxRLHtAwMD1aZNG5ttrVu31kcffVTpWEwmk3x8fCrdjzN4e3sbNjaj8vLysj6SO/vwvrMPebMfuasYk8nk6hAAAEAt4+bqAAAAAKpaYWGhcnNzS9zfrVs3HT9+3GZbSkqKbrjhBmeHBgAAAABArUbRAgAAVGtXrlxRUlKSdT2B06dPKykpSb/99puys7O1cOFC7d+/X2fOnFFiYqKio6OVlpamQYMGWfsYM2aM3n77bZvnP/30k5YvX64TJ04oPj5eGzZs0EMPPVTl5wcAAAAAQG3C9FAAAKBaS0xM1OjRo63PY2JiJEnDhg3TrFmzdOzYMW3atElZWVny9/dXp06dFBsbq7Zt21qPOXXqlLKysqzPw8LCtGTJEi1cuFBLly5V8+bN9dJLL+nuu++uuhMDAAAAAKAWomgBAACqtfDwcCUnJ5e4f8mSJWX2sXv37iLb+vbtq759+1YqNgAAAAAAUDEULWqYY8eO6fz58yXuN5vNOnjwoK5evSpvb+9S+/L391fr1q0dHCEAAAAAAAAAAMWjaFGDZGRkqG3btiosLHRIf+7u7jp79qwCAgIc0h8AAAAAAAAAAKWhaFGDBAQE6MiRI6XeabF//36NGzdOq1atUpcuXUrtz9/fn4IFAAAAAAAAAKDKULSoYcqazslsNkuSQkJC1K1bt6oICYCdCgoK9Pnnn+uHH35Qenq6BgwYIHd3d1eHBQAAAAAAADgNRQsAlVLWOioSa6nYY+PGjYqKilJKSop1W3BwsBYsWKDhw4e7LjAA1Q6/pwEAAAAA1QlFCwB2c/Q6KhJrqUjXChb33XefhgwZojVr1sjd3V0FBQVauHCh7rvvPsXFxVG4AFAu/J4GAAAAAFQ3FC0A2K0866hIrKVSEQUFBYqKitKQIUO0efNmXb16VUlJSQoNDdXmzZt17733aurUqbrnnnuYKgpAmfg9DQAAAACobihaAKiU8kwRwloq5ffFF18oJSVF77zzjtzc3Gz2ubm5KTo6WhEREfriiy90++23uyZIANUKv6cBAAAAANWJW9lNAABVJTU1VZLUsWPHYvdf3369HQAAAAAAAFCTULQAAAMJCgqSJCUmJha7//r26+0AAAAAAACAmoTpoQDAQPr06aPg4GC98sor2rx5s82+wsJCxcTE6MYbb1SfPn1cEyAAAOVw7NixMtdSMZvNOnjwoK5evSpvb+9S2/r7+5drqjMAAAAA1R9FCwAwEHd3dy1YsED33Xef7r33Xj377LNyd3fXt99+q3/+85/aunWr4uLiav0i3GVdDONCGAC4TkZGhtq2bavCwkKH9enu7q6zZ8+yCDwAAABQC1C0AAAXKenCe3BwsF599VX985//VL9+/azbb7jhBr366qsKDg7Wjz/+WOS42nLx3dEXw7gQBgCOFRAQoCNHjpR5p8X+/fs1btw4rVq1Sl26dCm1rb+/P7+nAQAAgFqCogUAuIA9F97PnDmj559/vsT9teXie3kuhnEhDABcqzxFdLPZLEkKCQlRt27dnB0SAAAAgGqCogUAuACfQq2csi6GcSEMAAAAAACgeqJoAQAuwqdQAQAAAAAAAFturg4AAAAAAAAAAABAomgBAAAAAAAAAAAMwrBFixUrVigkJETz5s2zbnv44YcVEhJi82/GjBml9mOxWPT666+rd+/eCgsL09ixY5WSkmLT5vz584qKilK3bt3UvXt3vfTSS7py5YozTgsAAAAAAAAAAJTAkEWLAwcO6N1331VISEiRfQ888IC+/PJL678XXnih1L5Wrlyp9evX629/+5s2bNggb29vjRs3Tjk5OdY2U6dO1a+//qo1a9Zo+fLl+v7778sshgAAAAAAAAAAAMcyXNHiypUrev755zV37lz5+fkV2V+3bl0FBgZa//n6+pbYl8Vi0bp16zRx4kT1799f7du316uvvqrff/9dO3fulCQdPXpUX3zxhebOnavOnTure/fumjZtmhISEpSWlua08wQAAAAAAAAAALY8XB3AH82ePVuRkZGKiIjQsmXLiuyPj4/Xli1bFBgYqL59++rJJ5+Ut7d3sX2dPn1a6enpioiIsG6rX7++OnfurH379mnw4MHat2+fGjRooE6dOlnbREREyM3NTQcOHNCAAQPsPheLxaLs7Gy7j3eG63eY5OTkGC42oyN39iN39iN39iFv9rFYLK4OAQAAAAAA1HKGKlokJCTo8OHDiouLK3b/kCFD1KxZMzVp0kTJycmaP3++jh8/riVLlhTbPj09XZLUuHFjm+2NGzdWRkaGJCkjI0ONGjWy2e/h4SE/Pz/r8fbKz89XUlJSpfpwtNTUVOuj0WIzOnJnP3JnP3JnH/Jmn/z8fFeHAAAoRUFBgT7//HP98MMPSk9P14ABA+Tu7u7qsAAAAACHMkzRIjU1VfPmzdPq1avl5eVVbJuRI0davw4JCVFgYKDGjh2rkydPqmXLllUVarl5eHgoNDTU1WHYuHDhgiQpKCjIcLEZHbmzH7mzX23K3f33e+r4ccfMWpidXSBJevnltvLx6eqQPm+8sVDvv5/rkL6MysPDMMMCAMAfbNy4UVFRUUpJSbFuCw4O1oIFCzR8+HDXBQYAAAA4mGGuThw6dEiZmZk2A+6CggLt3btXsbGxOnjwYJFPEXXu3FmSdOLEiWKLFoGBgZKkzMxMNWnSxLo9MzNT7du3lyQFBATo3LlzNsfl5+frwoUL1uPtZTKZ5OPjU6k+HO16QcjLy8twsRkdubMfubNfbcpdSoqUlFQoKccBvflKctOJE74O6s9LJpOHfHwM89+mU5hMJleHAAAoxsaNG3XfffdpyJAhWrNmjdzd3VVQUKCFCxfqvvvuU1xcHIULAAAA1BiGufrSo0cPxcfH22yLjo5W69atNX78+GJve74+5UdJxYXmzZsrMDBQ33zzjfUTypcvX9ZPP/2kBx98UJLUtWtXXbx4UYmJierYsaMkac+ePSosLFRYWJjDzg8AUB45khw1ndPHkq46qL9QScWvnwQAgDMVFBQoKipKQ4YM0ebNm3X16lUlJSUpNDRUmzdv1r333qupU6fqnnvuYaoooBixsbFatWqV0tPT1b59e02fPr3Uv/U//PBDvf766zpz5oyCg4M1depURUZGSpLy8vK0aNEiff755zp16pR8fX0VERGhqKgoNW3atKpOCQCAGs8x83A4gK+vr9q1a2fzz8fHR/7+/mrXrp1OnjyppUuXKjExUadPn9auXbv04osv6pZbbrHeNSFJgwYN0o4dOyRd+8To6NGjtWzZMu3atUvJycl64YUX1KRJE/Xv31+S1KZNG/Xp00fTp0/XgQMH9MMPP2jOnDkaPHgwgw4AqNYaujoAAAAq7YsvvlBKSopeeuklubnZ/vnm5uam6OhoHT9+XF988YWLIgSMa9u2bYqJidFTTz2lTZs2qX379ho3bpwyMzOLbf/jjz8qKipK9913nzZv3qy//OUveuqpp/TLL79Ikq5evarDhw9r4sSJ2rhxo5YsWaLjx49r4sSJVXlaAADUeIa506IsderU0TfffKN169YpOztbQUFBGjhwoJ588kmbdsePH9elS5esz8ePHy+z2awZM2bo4sWL+vOf/6w333zTZt2M+fPna86cORozZozc3Nw0cOBATZs2rcrODQAAAACKk5qaKknWu8L/6Pr26+0A/J81a9bogQce0IgRIyRJs2bN0qeffqoPPvhAjz/+eJH269atU58+ffTYY49JkqZMmaKvv/5ab7/9tmbPnq369etrzZo1NsdMnz5d999/v3777Tc1a9bM+ScFAEAtYOiixfr1661fBwUF6e233y7zmOTkZJvnJpNJkydP1uTJk0s8xt/fXwsWLLA/UAAAAABwgqCgIElSYmKievToUWR/YmKiTTsA1+Tm5urQoUN64oknrNvc3NwUERGhffv2FXvM/v37NXbsWJttvXv31s6dO0t8ncuXL8tkMqlBgwaVitdisSg7O7tSfTia2Wy2eUT5kTv7kDf7kTv7kTv7WCwWp/Zv6KIFAAAAANRmffr0UXBwsF555RVt3rzZZl9hYaFiYmJ04403qk+fPq4JEDCorKwsFRQUqHHjxjbbGzdurGPHjhV7TEZGhgICAoq0z8jIKLZ9Tk6O5s+fr8GDB8vX17dS8ebn51vX7TSalJQUV4dQbZE7+5A3+5E7+5G7isnPz3dq/xQtAMCB7r5bOnrUcf1lZ1+bym7UKC/5+FS+vzZtpC1bKt8PYCR79+7VqlWrlJiYqPT0dC1dutS6dpUkLV68WAkJCTp79qzq1KmjDh066Nlnn1Xnzp1L7HPx4sVasmSJzbYbb7xR27dvd9p5oGoY/fe0xO9q2HJ3d9eCBQt033336d5779Wzzz4rd3d3ffvtt/rnP/+prVu3Ki4ujkW4gSqWl5enyZMny2KxaNasWZXuz8PDQ6GhoQ6IzHHMZrNSUlIUHBwsb29vV4dTrZA7+5A3+5E7+5E7+3h4OLesQNECABzo6FHp8OFCSTkO6tFHkptSUnwkVfZWRS9JbmW2Aqqb7OxshYSEaMSIEXr66aeL7A8ODtaMGTPUokULXb16VW+99ZYeffRR7dixQ40aNSqx37Zt29rMW80FwZrh6FHp58P58lGWQ/orlEWSm35PschN6ZXuL1sNxRC9djt27JjOnz9vsy04OFivvvqq/vnPf6pfv37W7TfccINeffVVBQcH68cffyzSl7+/v1q3bu3skA2huLz9kdls1sGDB3X16tUyL0rUptzVVA0bNpS7u3uRRbczMzOL3E1xXUBAQJG7Koprn5eXpylTpui3337T2rVrK32XhXRtamsfR1W/Hczb29uwsRkdubMPebMfubMfuasYk8nk1P75iwgAHC5HkiNv7f5Y0lUH9BkqiU8NoOaJjIxUZGRkifuHDh1q8zw6OlpxcXFKTk5Wz549SzzO3d1dgYGBDosTxuGjLEVqucP6y9Xz8pRj7sL5TBMk8b6rrTIyMtS2bVsVFhaWq/2ZM2f0/PPPl7jf3d1dZ8+eLfECbU1R0byVR23JXU3m6empDh066JtvvrHegVlYWKhvvvlGo0aNKvaYLl26aM+ePTbrWnz99dfq0qWL9fn1gsWJEye0bt06NWzY0JmnAQBArUTRAgAMjz+EAEfJzc3Ve++9p/r16yskJKTUtidOnFDv3r3l5eWlLl26KCoqSs2aNat0DEZcaDMnJ8f6aLTYHM1iqevwPj1Vz6H9WSyFys6+6tA+jag2ve/Ky8fHRwcOHCj1joGDBw9q4sSJWrZsmTp16lRqf/7+/vLx8anx+S1P3iRyZy9nL7TpTI888ohefPFFdezYUWFhYVq7dq3MZrOGDx8uSXrhhRfUtGlTRUVFSZJGjx6thx9+WKtXr1ZkZKS2bdumxMREzZ49W9K1gsWkSZN0+PBhvfHGGyooKFB6+rW77Pz8/OTp6emaEwUAoIahaAEAMIxA3yw1qZ/q6jCKUVf+dYNEAan6+uSTT/Tcc8/JbDYrMDBQq1evLnVqqLCwMOvittfXyfjf//1fxcfH18iFNlNTU62PRovN0XJybnZ1CGXKycmp8d8HqXa97yqqbt2Si2v169e3PpbWTpKuXr1aq3JbVj7InX2cvdCmM9111106d+6c/vWvfyk9PV2hoaF68803rXfQpKamys3t/6ZP7datm+bPn69FixZp4cKFCg4O1tKlS9WuXTtJUlpamnbv3i1Juueee2xea926dQoPD6+iMwMAoGajaAEAMIwHb92tyf02uTqMYv3n4AOSRro6DNgpPDxcmzdvVlZWljZs2KApU6bo/fffV+PGjYtt/9/TTbVv316dO3dW37599eGHH+r++++vVCxGXGjzwoULkqSgoCDDxeZoXl5eki67OoxSeXl51fjvg1S73neORN7sR+7s4+yFNp1t1KhRJU4HtX79+iLb7rzzTt15553Ftm/evLmSk5MdGh8AACiqeo8+AAA1yjvf9dOuJCPezXCj/IOCNM3VYcBuPj4+atWqlVq1aqUuXbpo4MCBiouL0xNPPFGu4xs0aKDg4GCdPHmy0rEYcaHNaxfyrz0aLTZHc/J6cQ5hMrnV+O+DVLved45E3uxH7uzj7IU2AQAA/oiiBQDAMNIvN1T65SBXh1GMG3VzQxYxr0kKCwuVm5tb7vZXrlzRqVOnWJgbAAAAAAAno2iBGu3uu6WjRx3TV3b2tU9mjRrlJUd9MKtNG2nLFsf0BeNgXQagal25csXmDojTp08rKSlJfn5+8vf31/Lly9WvXz8FBgYqKytLsbGxSktL06BBg6zHjBkzRgMGDLBOH/GPf/xDffv2VbNmzfT7779r8eLFcnNz05AhQ6r8/AAAAAAAqE0oWqBGO3pUOny4UFKOA3rzkeSmlBQfSWYH9Oclya3MVqh+WJcBqFqJiYkaPXq09XlMTIwkadiwYZo1a5aOHTumTZs2KSsrS/7+/urUqZNiY2PVtm1b6zGnTp1SVlaW9fnZs2f13HPP6fz582rUqJH+/Oc/a8OGDaUu3g0AAAAAACqPogVqgRxJSQ7q62NJVx3UX6gkppupiViXAaha4eHhpS6KuWTJkjL72L17t83zf/7zn5WOC6hpHHkHq+T4u1i5gxUAAACoGShaABVixAvRMBrWZQAA1ERHj0o/H86Xj7LKblwOhbJIctPvKRa5Kb1SfWWrofjTBgAAAKgZGNkDAAAAKBcfZSlSyx3WX66el6e2V7qfzzRBUmDlAwIAAADgchQtAAAAqiFHTtXj6Gl6JKbqQfl4qp6rQ4CBGX1KMonfdQAAAM5A0QIAHM5L19YscZQMSQEO6MfLAX0AMApHTtXjyGl6JKbqAeAYRp6STOJ3HQAAgLMwwgIAB2rTRpLc5KhF1nNyftXRoyFq0yZZXl43Vbq/a/EBqCkcOVWPo6bpkZiqB4DjGHVKMonfdQAAAM5C0QIAHMjR0wN89VWaevcu1Nq1aerVq/JFCwAoCdP0AKgN+F0HAABgfBQtAAAAAMCJWIMGAAAAKD+KFgAAAADgRKxBAwAAAJQfo9NqgE9mAQAAANUba9AAAAAA5UPRoho4elQ6fLhQUo4DevOR5KaUFB9JZgf056Vriw6jJnFkoUyiWAYAAOBItWldhgDfC2peP9vVYRSrvU7Kq66HpIauDgUAAKBGoWhRbeRISnJQXx9Luuqg/kIleTugHxiJYwtlEsUyAAAA2OO+Wz/XxH6/uDqMEryi/xx8QNJIVwcCAABQo1C0qJX4JBDKw5GFMoliGQAAACoq7rvbdCnpiKvDKNYPuk9eQa01zdWBAAAA1DAULQBUEYplAAAAqJiMy346fdlB84s62M9qqZYNGeMCAAA4GkULAICBeOnanTSOkCEpwEF9eTmoHwBAbWXUtRlYlwEAAABGQ9ECAFzk2LFjOn/+fKltkpOTrY/e3qVPieXv76/WrVs7Krwq16aNdG2tkspP/ZWT86uOHg1RmzbJ8vK6qdL9SdfjAwDAPsZdm4F1GQAAAGAsFC0AwAUyMjLUtm1bFRYWlqv9uHHjymzj7u6us2fPKiDAUXcXVK0tWxzX11dfpal370KtXZumXr0cU7QAAKAyjLo2A+syAAAAwGgoWgCACwQEBOjIkSNl3mlhNpt18OBBderUqVx3WlTXggUAADWdUddmYF0GAAAAGA1FCwBwkfJM5ZSdna26desqNDRUPj7Gu9ABAAAAAAAAOJKbqwMAAAAAAAAAAACQDFy0WLFihUJCQjRv3rwi+ywWix577DGFhIRo586dpfYTEhJS7L8333zT2qZfv35F9q9YscLh5wQAAAAAAAAAAEpmyOmhDhw4oHfffVchISHF7l+7dq1MJlO5+vryyy9tnn/++ed6+eWXdccdd9hsnzRpkh544AHr83r16lUwagAAAAAoXrYa6jNNcEhfFmXKpMYO6StbrGcBAAAAYzFc0eLKlSt6/vnnNXfuXC1btqzI/qSkJK1evVoffPCBevfuXWZ/gYGBNs937dql8PBwtWjRwmZ7vXr1irQFAAAAgMpq00a69qdX5f/eyMn5VUePdlCbNsny8rqp0v1J1+MDAAAAjMFwRYvZs2crMjJSERERRYoWZrNZUVFRmjFjhl0FhoyMDH322Wf6+9//XmTfypUrtWzZMgUFBWnIkCEaO3asPDwqlx6LxaLs7OxK9XGtn7qV7sOZLJZCZWdfdXUYxSJ39jF63iTj5s7RzGazzSPKJycnx/roiN/DtYXFYnF1CECVCPC9oOb1jfm7ob1Oyquuh8Sn32uULVsc19dXX6Wpd+9CrV2bpl69HFO0AAAAAIzEUEWLhIQEHT58WHFxccXuj4mJUdeuXdW/f3+7+t+0aZPq1aungQMH2mx/+OGHdfPNN8vPz0/79u3TwoULlZ6erujoaLte57r8/HwlJSVVqg9Jysm5udJ9OFNOTo5DztMZyJ19jJ43ybi5c5aUlBRXh1CtpKamWh9r0/uksvLz810dAirIqBffjX7h/b5bP9fEfr+4OowSvKL/HHxA0khXBwIAAAAALmGYokVqaqrmzZun1atXy8vLq8j+Xbt2ac+ePdq0aZPdr/HBBx9o6NChRfp/5JFHrF+3b99ederU0cyZMxUVFSVPT0+7X8/Dw0OhoaF2H3/dtXhzKt2Ps3h5eTnkPJ2B3NnH6HmTjJs7RzObzUpJSVFwcLC8vb1dHU61ceHCBUlSUFBQrXifOEpl7zAsTWZmpurXr1+u/1fPnTuno0eP6pZbbnFaPDWFcS++G/vCe9x3t+lS0hFXh1GsH3SfvIJaa5qrAwEAAAAAF6nw1Ynx48frscceU3h4uKRrn3Zet26dhgwZoqCgIJu2O3fuVExMjHbt2lVmv4cOHVJmZqaGDx9u3VZQUKC9e/cqNjZWDz74oE6ePFnkAsYzzzyj7t27a/369aX2//333+v48eNatGhRmbF07txZ+fn5On36tFq3bl1m+5KYTCb5+PjYffz/9VPpLpzKZHJzyHk6A7mzj9HzJhk3d87i7e1dq863sq4Xp728vMhbBZic+MPfu3dvvfrqqxo6dKgk6dKlSxo5cqRiYmLUuXNnm7ZffvmlXnzxRe6SKQejXnw3+oX3jMt+On3ZmL8bflZLtWxozDtUAAAAAKAqVLho8cUXX+juu++2Ps/OztbChQvVsWPHIkWL7Oxs/fbbb+Xqt0ePHoqPj7fZFh0drdatW2v8+PFq2LChRo60/bTe0KFDFR0drb59+5bZf1xcnDp06KD27duX2TYpKUlubm5q3LhxuWIHAACl++N6Gfn5+Tp27BhrjlSSUS++c+EdAAAAAGAvh8wD4YiFO319fdWuXTubbT4+PvL397duL27x7WbNmqlFixbW54MGDVJUVJQGDBhg3Xb58mVt375dL774YpHj9+3bp59++kk9evRQvXr1tG/fPsXExOjuu++Wn59fpc/LUQJ9s9SkfqqrwyhGXfnXDZJR56yWyB0AAAAAAAAAVBeGWdPCUY4fP65Lly7ZbEtISJDFYtGQIUOKtPf09NS2bdu0ZMkS5ebmqnnz5ho7dqzNOhdG8OCtuzW5n/3reTiTkeeslsgdAAAAUF1lq6E+0wSH9WdRpkxyzB312Xz4CAAAwCkMXbQoa52K5OTkcm0bOXJkkamlruvQoYM2bNhgX4BV6J3v+mlXkhEHxTfKPyjIsHNWS+QOAAAA1cexY8d0/vz5Evdf/3snOTlZ3t7epfbl7+9fqTX6XK1NG+nan6xF77i3R07Orzp6tIPatEmWl9dNDunzWowAAABwJLuKFsUt1OnMxTshpV9uqPTLQWU3rHI36uaGpf+x5GrkDgCMwWw2Wy/EXbhwQZJ05cqVIhfnKrrOxd69e7Vq1SolJiYqPT1dS5cuVf/+/a37Fy9erISEBJ09e1Z16tRRhw4d9OyzzxZZALwkK1as0IIFCzR69Gi9/PLLFYoNqGkCfC+oeX3jrUXTXiflVddD1X3azYyMDLVt21aFhYVlth03blyZbdzd3XX27FkFBAQ4Irwqt2WLY/v76qs09e5dqLVr09Srl2OKFgAAAHA8u4oWq1ev1tatWyVdW0hTkhYtWiR/f3+bdr///nvlogMAADXGzJkzNXPmTJttzzzzTJF2FoulQh+GyM7OVkhIiEaMGKGnn366yP7g4GDNmDFDLVq00NWrV/XWW2/p0Ucf1Y4dO9SoUaNS+z5w4IDeffddhYSElDseoCa779bPNbHfL64Ooxiv1IhpNwMCAnTkyJFS77Qwm806ePCgOnXqVK47LaprwQIAAAC1V4WLFs2aNdP58+dtBtLNmjXT77//XmyRIijIiJ9wBwAAVam4YoKjREZGKjIyssT9Q4cOtXkeHR2tuLg4JScnq2fPniUed+XKFT3//POaO3euli1b5rB4geos7rvbdCnpiKvDKOIH3SevoNY1YtrNsqZzys7OVt26dRUaGiofH58qigoAAACoOhUuWuzevdsZcQAAgBrMmUWLisjNzdV7772n+vXrl3n3xOzZsxUZGamIiAiKFsD/L+Oyn05fNt6F8p/VUi0bVu+poQAAAABcY+iFuAEAQM2Snp6uM2fOyN/fX8HBwVX2up988omee+45mc1mBQYGavXq1aVODZWQkKDDhw8rLi7O4bFYLJYKr9tRfD91HRCN81gshcrOvurqMIowet4kcmcvo+bN0cxms80jyi8nJ8f66Ijfw7WFxWJxdQgAAKCWcWjR4ujRo9q+fbvS09N14403asSIEfL19XXkSwAAgGooNzdX0dHR2rZtm3Vb+/bttXjxYjVv3tzprx8eHq7NmzcrKytLGzZs0JQpU/T++++rcePGRdqmpqZq3rx5Wr16tby8vBweS35+vpKSkirdT07OzQ6IxnlycnIccp6OZvS8SeTOXkbNm7OkpKS4OoRqJzU11fpYm94rlXV9HUsAAICqUuGixdtvv63169frnXfesfmE4u7duzV58mTl5eXZtH3vvffKXOQSAADUbLGxsUpISFDHjh1166236uTJk9q1a5defPFFxcbGOv31fXx81KpVK7Vq1UpdunTRwIEDFRcXpyeeeKJI20OHDikzM1PDhw+3bisoKNDevXsVGxurgwcPyt3d3e5YPDw8FBoaavfx110rqFyudD/O4uXl5ZDzdDSj500id/Yyat4czWw2KyUlRcHBwWUuxA1bFy5ckHRt3cXa8F5xFA8PJmgAAABVy641LVq0aGFTiMjPz9e0adPk7u6u2bNnq2PHjvr000+1aNEiLV++XC+99JJDgwYAANXL5s2bFR4errfeeksmk0mS9MYbb2jRokVKS0tT06ZNqzSewsJC5ebmFruvR48eio+Pt9kWHR2t1q1ba/z48ZUqWEiSyWRyyOK5/38aDctkcjPkIsFGz5tE7uxl1Lw5i7e3d606X0e4fvecl5cXuasAk9F/+AEAQI3jVtEDfv31V3Xp0sVm27fffqtz585pzJgxGjZsmNq2bavx48dr0KBB+uyzzxwVKwAAqKZOnz6tgQMH2lz4uOuuu2SxWHT69OlK9X3lyhUlJSVZp/o4ffq0kpKS9Ntvvyk7O1sLFy7U/v37debMGSUmJio6OlppaWkaNGiQtY8xY8bo7bffliT5+vqqXbt2Nv98fHzk7++vdu3aVSpWAAAAAABQugrfaXH+/Hn96U9/stn2zTffyGQyacCAATbbu3Xrph07dlQuQgAAUO1duXJFDRo0sNl2fd2rku54KK/ExESNHj3a+jwmJkaSNGzYMM2aNUvHjh3Tpk2blJWVJX9/f3Xq1EmxsbFq27at9ZhTp04pKyurUnEAAAAAAIDKq3DRIiAgQBkZGTbbvv/+e9WtW1ft27e32e7p6ak6depULkIAAFAjlDS9RGWnnQgPD1dycnKJ+5csWVJmH7t37y51//r16yscFwAAKJ3FYnH69FOxsbFatWqV0tPT1b59e02fPl1hYWEltv/www/1+uuv68yZMwoODtbUqVMVGRlpE/O//vUvvf/++7p48aK6deumv/3tbwoODnbqeQAAUJtUuGjRsWNHbdq0SaNGjZKvr6+OHDmigwcP6i9/+UuRBbqOHTtW5K4MAABQO7388suaMWNGke0TJkyQm5vtjJUmk0k//PBDVYVWbWWroT7TBIf0ZVGmTGrskL6y1dAh/QAAaqbc3Fxt2rRJq1ev1kcffeS019m2bZtiYmI0a9Ysde7cWWvXrtW4ceO0fft2NW5c9P+8H3/8UVFRUXruuefUt29fxcfH66mnntLGjRutU0SuXLlS69ev19///nc1b95cr7/+usaNG6dt27ZZ100BAACVU+GixVNPPaX77rtPd9xxh2666SYdOnRIJpNJjz/+eJG2O3bsUI8ePRwSKICqFeibpSb1U10dRgnqyr9ukMRFMaDaGDZsmKtDqHHatJGuDeUCK91XTs6vOnq0g9q0SZaX102V7k+6Hh8AoLbJzc3V7t27dfLkSfn5+en2229X06ZNJUlms1lvv/221q5dq4yMDLVs2dKpsaxZs0YPPPCARowYIUmaNWuWPv30U33wwQfFXsNYt26d+vTpo8cee0ySNGXKFH399dd6++23NXv2bFksFq1bt04TJ05U//79JUmvvvqqIiIitHPnTg0ePNip5wMAQG1R4aJFSEiI1q5dq+XLl+vUqVPq3Lmzxo0bp44dO9q0+/bbb+Xt7W2zyCWA6uPBW3drcr9Nrg6jRP85+ICkka4OA0A5XV9nAo6zZYvj+vrqqzT17l2otWvT1KuXY4oWAIDaJy0tTaNHj9bJkydlsVgkSXXr1tWyZctUp04dRUVFKS0tTWFhYZo+fboGDhzotFhyc3N16NAhPfHEE9Ztbm5uioiI0L59+4o9Zv/+/Ro7dqzNtt69e2vnzp2SpNOnTys9PV0RERHW/fXr11fnzp21b9++ShUtLBaLsrOz7T7eGcxms80jyo/c2Ye82Y/c2Y/c2ef6//POUuGihXRtge0VK1aU2iY8PFzx8fF2BYXieEkKdVBfGZICHNQXt7/WVO9810+7kox6J8ON8g8K0jRXhwHAKc6dO6dt27Zp1KhRrg4FAABUwKJFi3T69Gk99thj6t69u06fPq2lS5dq+vTpysrKUtu2bfXaa6/p1ltvdXosWVlZKigoKDINVOPGjXXs2LFij8nIyFBAQECR9tfX9UxPT7duK6mNvfLz85WUlFSpPpwlJSXF1SFUW+TOPuTNfuTOfuSuYvLz853av11FC1Sta9MruEnyrnRf16Z/CGH6B5Qp/XJDpV8OcnUYJbhRNzes/M8DAOMwm83auXOn4uPj9fXXX6ugoICiBQAA1cxXX32l4cOHKyoqyrotICBAkydP1u23365///vfRdaxwjUeHh4KDXXUBxUdw2w2KyUlRcHBwfL25u+viiB39iFv9iN39iN39vnj2tYO77+iB3z88ccVfhFn3vJZGzD9AwCgJiosLNQXX3yh+Ph47dq1S1evXlXLli318MMPq1+/fq4ODwAAVFBmZqY6d+5ss61Lly6SpBEjRlRpwaJhw4Zyd3dXZmamzfbMzMwid1NcFxAQUOSOif9uHxgYaN3WpEkTmzbt27evVLwmk0k+Pj6V6sNZvL29DRub0ZE7+5A3+5E7+5G7ijGZTE7tv8JFi0mTJlmDKs/cVSaTybC3OAIAgKq3f/9+xcfH68MPP1RWVpaaNWumq1evavbs2br//vtdHR4AALBTQUGBvLxspxD29PSUJPn6+lZpLJ6enurQoYO++eYb66LZhYWF+uabb0q8m7NLly7as2ePzboWX3/9tbXw0rx5cwUGBuqbb76x3hVx+fJl/fTTT3rwwQedej4AANQmdt3H4eXlpcjISN15551q1KiRo2MCAAA1zLFjxxQfH6+tW7fq1KlTatmype6//34NGTJEnp6euuOOO+Tn5+fqMAEAQCWdOXNGhw4dsj6/dOmSJOnEiRNq0KBBkfYdOnRwWiyPPPKIXnzxRXXs2FFhYWFau3atzGazhg8fLkl64YUX1LRpU+t0VqNHj9bDDz+s1atXKzIyUtu2bVNiYqJmz54t6dqHMkePHq1ly5apVatWat68uV5//XU1adLEWhgBAACVV+GixerVqxUfH68dO3Zo165d6tmzp4YOHar+/ftzCw0AACjW4MGDFRAQoCFDhujOO+9UWFiYdd/JkyddGBkAAHCk119/Xa+//nqR7bNmzbJ5brFYnD4zw1133aVz587pX//6l9LT0xUaGqo333zTOt1TamqqzZRV3bp10/z587Vo0SItXLhQwcHBWrp0qdq1a2dtM378eJnNZs2YMUMXL17Un//8Z7355ptF7jABAAD2q3DRIiIiQhEREZo1a5Z27dqlhIQEvfzyy5o5c6Zuv/12DR06VLfddpvTF+MAAADVh4eHhy5evKgzZ87o7Nmzat++vXW6CAAAUDPExMS4OoQiRo0aVeJ0UOvXry+y7c4779Sdd95ZYn8mk0mTJ0/W5MmTHRYjAACwZXdlwdPT0/qf+aVLl7R9+3bFx8frmWeeka+vr2bOnKm77rrLkbECAIBq6uuvv9b27du1ZcsWTZ48WT4+PvrLX/6iIUOG6IYbbnB1eAAAwAGGDRvm6hAAAEAN4JDbIerXr69hw4apUaNGKiws1Pfff69jx445omsAAFAD1K9fX/fff7/uv/9+paamWte32LJli3x8fGQymXTs2DHl5uZyBwYAAAAAALVYpYsW3377rbZu3aqPP/5Yly9f1i233KK5c+dq0KBBjogPAADUMEFBQXr88cf1+OOP6+eff9aWLVu0bds2LVq0SCtWrFCvXr3Ur18/Pq0JAAAAAEAtZFfR4uDBg0pISNC2bdv0+++/q2PHjpo4caIGDx6swMBAR8cIAICNY8eO6fz58yXuT05Otj56e3uX2pe/v79at27tyPBQAe3bt1f79u31wgsv6Ntvv9WWLVu0Y8cO7dy5k6IFAAAAAAC1UIWLFnfccYdOnjypG2+8USNHjtTQoUPVsmVLZ8QGAEARGRkZatu2rQoLC8tsO27cuDLbuLu76+zZswoICHBEeKiE8PBwhYeHa+bMmfrss89cHQ4AAAAAAHCBChctTpw4obp168rd3V3bt2/X9u3bS21vMpm0ZcsWuwMEAOC/BQQE6MiRI6XeaWE2m3Xw4EF16tSpXHdaULBwvgkTJlSovclk0oABA5wUDQAAAAAAMKoKFy1uueUWZ8QBAEC5lTWdU3Z2turWravQ0FD5+PhUUVQozaeffiovLy8FBATIYrGU2d5kMlVBVLVDWdOpSUypBqD643cdAABAzVHhosX69esr1L48FyYAAEDN1rRpU6Wlpalhw4YaMmQI62BVkYpMpyYxpRqA6onfdQAAADWLXQtxl0dubq42bdqk1atX66OPPnLWywAAgGrgs88+03fffaetW7dq2bJleu2113TLLbdo6NChuuOOO+Tr6+vqEGuk8kynJjGlGoDqjd91AAAANYtdRYvc3Fzt3r1bJ0+elJ+fn26//XY1bdpU0rWB4Ntvv621a9cqIyODRboBAIAk6dZbb9Wtt96q6dOn67PPPtPWrVs1Z84czZo1S7fddpuGDBmifv36ydPT09Wh1ijlmd6EKdUAVHf8rgMAAKg5Kly0SEtL0+jRo3Xy5Enr1E9169bVsmXLVKdOHUVFRSktLU1hYWGaPn26Bg4caFdgK1as0IIFCzR69Gi9/PLLNvssFovGjx+vL774QkuXLlX//v1L7Oevf/2rNm3aZLOtd+/eWrVqlfX5+fPnNWfOHH3yySdyc3PTwIED9fLLL6tevXp2xQ4AAEpWp04d9e/fX/3799eVK1e0Y8cOvfvuu3r22Wf19NNP66mnnnJ1iAAAAAAAwEUqXLRYtGiRTp8+rccee0zdu3fX6dOntXTpUk2fPl1ZWVlq27atXnvtNd166612B3XgwAG9++67CgkJKXb/2rVrK7RAZ58+fRQTE2N9/sdPcE6dOlXp6elas2aN8vLy9NJLL2nGjBlasGCBfScAAADKlJubqy+//FK7du3S4cOH5eXlpRtuuMHVYQEAAAAAABeqcNHiq6++0vDhwxUVFWXdFhAQoMmTJ+v222/Xv//9b7m5udkd0JUrV/T8889r7ty5WrZsWZH9SUlJWr16tT744AP17t27XH16enqWuNjn0aNH9cUXXyguLk6dOnWSJE2bNk2PP/64XnjhBeu0VwAAoPIKCwv11VdfKSEhQTt37tTVq1fVs2dPzZkzRwMGDGC6DgAAAAAAarkKFy0yMzPVuXNnm21dunSRJI0YMaJSBQtJmj17tiIjIxUREVGkaGE2mxUVFaUZM2aUWIQoznfffaeePXuqQYMG6tGjh6ZMmaKGDRtKkvbt26cGDRpYCxaSFBERITc3Nx04cEADBgyo1PkAAADpxx9/1NatW7V9+3adP39enTt31rPPPqs777xTjRo1cnV4AAAAAADAICpctCgoKJCXl5fNtuvTLfn6+lYqmISEBB0+fFhxcXHF7o+JiVHXrl1LXcPij/r06aMBAwaoefPmOnXqlBYuXKjx48frvffek7u7uzIyMopcLPHw8JCfn5/S09MrdT4Wi0XZ2dmV6sPRcnJyrI9Gi80ZLJa6rg6hVBZLobKzr7o6jCKMnjfJuLlzNLPZbPOI8iFv9rm+VpUzPPTQQ6pbt651we3r00ClpqYqNTW12GM6dOjgtHgAAAAAAIAxVbhoIUlnzpzRoUOHrM8vXbokSTpx4oQaNGhQpH15LjqkpqZq3rx5Wr16dZGiiCTt2rVLe/bsKbKodlkGDx5s/TokJEQhISHq37+/9e4LZ8rPz1dSUpJTX6Oirl8YSk1NNVxszpCTc7OrQyhVTk6OIb8PRs+bZNzcOUtKSoqrQ6iWyFvF5OfnO7X/q1ev6uOPP9aOHTtKbWexWGQymWrVzzgAAAAAALjGrqLF66+/rtdff73I9lmzZtk8r8hFh0OHDikzM1PDhw+3bisoKNDevXsVGxurBx98UCdPntQtt9xic9wzzzyj7t27a/369eWKvUWLFmrYsKFOnDihnj17KiAgQOfOnbNpk5+frwsXLlRoCqrieHh4KDQ0tFJ9ONqFCxckSUFBQYaLzRmuFcByXB1Giby8vAz5fTB63iTj5s7RzGazUlJSFBwcLG9vb1eHU22QN/t4eNg1LCiXmJgYp/UNAAAAAABqjgpfnXDWRYcePXooPj7eZlt0dLRat26t8ePHq2HDhho5cqTN/qFDhyo6Olp9+/Yt9+ucPXtW58+ftxYkunbtqosXLyoxMVEdO3aUJO3Zs0eFhYUKCwur1DmZTCbDLSh6/S4WLy8vw8XmDCaTqyMoncnkZsjvg9HzJhk3d87i7e1dq87XUchbxZic+MM/bNgwp/UNAAAAAABqjgoXLZx10cHX11ft2rWz2ebj4yN/f3/r9uLufGjWrJlatGhhfT5o0CBFRUVpwIABunLlipYsWaI77rhDAQEBOnXqlF577TW1atVKffr0kSS1adNGffr00fTp0zVr1izl5eVpzpw5Gjx4sJo2beqUcwUAAAAAAAAAAEU5bx4IFzl+/Lh1jQ13d3f98ssv2rx5sy5duqQmTZqoV69emjx5snXxcEmaP3++5syZozFjxsjNzU0DBw7UtGnTXHUKAAAAAAAAAADUSoYuWpS1TkVycnKp2+rWratVq1aV+Tr+/v5asGBBxQMEAAAAAAAAAAAOY+iiBQAAQFn27t2rVatWKTExUenp6Vq6dKn69+9v3b948WIlJCTo7NmzqlOnjjp06KBnn31WnTt3LrHP//znP3rnnXd05swZSVLbtm315JNPKjIy0unnA+fLVkN9pgkO68+iTJnU2CF9ZauhQ/oBAAAAgOqKogUAAKjWsrOzFRISohEjRujpp58usj84OFgzZsxQixYtdPXqVb311lt69NFHtWPHDjVq1KjYPv/0pz9p6tSpatWqlSwWizZv3qynnnpKmzZtUtu2bZ19SnCiNm2ka0Pgomul2SMn51cdPdpBbdoky8vrJof0eS1GAAAAAKidKFqgFvCSFOqgvjIkBTioLy8H9QMAtVtkZGSpd0AMHTrU5nl0dLTi4uKUnJysnj17FntMv379bJ4/++yzeuedd7R//36KFtXcli2O7e+rr9LUu3eh1q5NU69ejilaAAAAAEBtRtECNdq1Tyq6SfKudF/XPkkZwicpAaAay83N1Xvvvaf69esrJCSkXMcUFBRo+/btys7OVteuXSsdg8ViUXZ2dqX7cSSz2WzziPLLycmxPhrt++poFktdV4dQKoulUNnZV10dhtPx82o/cmcfi8Xi6hAAAEAtQ9ECNZojP03JJykBoPr65JNP9Nxzz8lsNiswMFCrV68ucWqo65KTk/U///M/ysnJkY+Pj5YuXaqbbqr87//8/HwlJSVVuh9nSElJcXUI1U5qaqr10ajfV0fJybnZ1SGUKicnp8Z/D/4bP6/2I3cVk5+f7+oQAABALUPRAgAA1Hjh4eHavHmzsrKytGHDBk2ZMkXvv/++GjcuefHkG2+8UZs3b9alS5f00Ucf6cUXX9Tbb79d6cKFh4eHQkMdNW2hY5jNZqWkpCg4OFje3pW/O7E2uXDhgiQpKCjIcN9XR/Py8pJ02dVhlMjLy6vGfw8kfl4rg9zZx8ODywYAAKBqMfoAAAA1no+Pj1q1aqVWrVqpS5cuGjhwoOLi4vTEE0+UeIynp6datWolSerYsaMOHjyodevWafbs2ZWKxWQyycfHp1J9OIu3t7dhYzOqaxfyrz3W9NyZTK6OoHQmk1uN/x78N35e7UfuKsZk9B9+AABQ47i5OgAAAICqVlhYqNzcXKcfAwAAAAAAKoY7LWqYY8eO6fz58yXuT05Otj6WdUu0v7+/Wrdu7cjwAABwuCtXrujkyZPW56dPn1ZSUpL8/Pzk7++v5cuXq1+/fgoMDFRWVpZiY2OVlpamQYMGWY8ZM2aMBgwYoFGjRkmSFixYoNtuu01BQUG6cuWKtm7dqu+++06rVq2q8vMDAAAAAKA2oWhRg2RkZKht27YqLCwss+24cePKbOPu7q6zZ88qICDAEeEBAOAUiYmJGj16tPV5TEyMJGnYsGGaNWuWjh07pk2bNikrK0v+/v7q1KmTYmNj1bZtW+sxp06dUlZWlvV5ZmamXnzxRf3++++qX7++QkJCtGrVKvXq1avqTgwAAAAAgFqIokUNEhAQoCNHjpR6p4XZbNbBgwfVqVOnct1pQcECAGB04eHh1jsJi7NkyZIy+9i9e7fN81deeaXScQEAAAAAgIqjaFHDlDWdU3Z2turWravQ0FAWnwMAAAAAAAAAGAoLcQMAAAAAAAAAAEOgaAEAAAAAAAAAAAyBogUAAAAAAAAAADAEihYAAAAAAAAAAMAQKFoAAAAAAAAAAABDoGgBAAAAAAAAAAAMwcPVAQAwKi9JoQ7sL0NSgIP68nJQPwAAAAAAAACMhKIFgCLatJGu3Yjl7ZD+cnJ+1dGjIWrTJlleXjc5pM9rMQIAAAAAAACoSShaAChiyxbH9vfVV2nq3btQa9emqVcvxxQtAAAAAAAAANQ8rGkBAAAAAAAAAAAMgaIFAAAAAAAAAAAwBIoWAAAAAAAAAADAEChaAAAAAACAGuX8+fOKiopSt27d1L17d7300ku6cuVKqcfk5ORo1qxZCg8PV9euXfXMM88oIyPDuv/nn3/Wc889p8jISIWFhenOO+/U2rVrnX0qAADUOhQtAAAAAABAjTJ16lT9+uuvWrNmjZYvX67vv/9eM2bMKPWYV155RZ988okWLVqk9evX6/fff9fTTz9t3Z+YmKhGjRrptddeU0JCgiZMmKCFCxfq7bffdvbpAABQq3i4OgAAAAAAAABHOXr0qL744gvFxcWpU6dOkqRp06bp8ccf1wsvvKCmTZsWOebSpUv64IMPNH/+fPXs2VPStSLGXXfdpf3796tLly667777bI5p0aKF9u/fr48//lijRo1y/okBAFBLULQAAAAAUC7ZaqjPNMFh/VmUKZMaV7qfbDV0QDQAaop9+/apQYMG1oKFJEVERMjNzU0HDhzQgAEDihyTmJiovLw8RUREWLe1adNGzZo1sxYtinPp0iX5+/tXOmaLxaLs7OxK9+NIZrPZ5hHlR+7sQ97sR+7sR+7sY7FYnNo/RQsAAAAAZWrTRrr250OgQ/rLyflVR492UJs2yfLyuqnS/V2LDwCkjIwMNWrUyGabh4eH/Pz8lJ6eXuIxderUUYMGDWy2N27cuMRjfvzxR3344Yd64403Kh1zfn6+kpKSKt2PM6SkpLg6hGqL3NmHvNmP3NmP3FVMfn6+U/unaAEAAACgTFu2OLa/r75KU+/ehVq7Nk29elW+aAGg5ps/f75WrlxZaptt27ZVSSy//PKLnnzyST311FPq3bt3pfvz8PBQaGioAyJzHLPZrJSUFAUHB8vb29vV4VQr5M4+5M1+5M5+5M4+Hh7OLStQtAAAAAAAAIb36KOPatiwYaW2adGihQICAnTu3Dmb7fn5+bpw4YICA4u/WywgIEB5eXm6ePGizd0WmZmZRY759ddfNXbsWI0cOVJPPvmknWdjy2QyycfHxyF9OZq3t7dhYzM6cmcf8mY/cmc/clcxJpPJqf1TtAAAAAAAAIbXqFGjItM+Fadr1666ePGiEhMT1bFjR0nSnj17VFhYqLCwsGKP6dixo+rUqaNvvvlGd9xxhyTp2LFj+u2332zWszhy5IjGjBmje++9V88++2zlTwoAABTh5uoASrJixQqFhIRo3rx5RfZZLBY99thjCgkJ0c6dO0vsIy8vT6+99pqGDh2qLl26qHfv3nrhhReUlpZm065fv34KCQmx+bdixQqHnxMAAAAAAHCuNm3aqE+fPpo+fboOHDigH374QXPmzNHgwYPVtGlTSVJaWpoGDRqkAwcOSJLq16+vESNG6O9//7v27NmjxMREvfTSS+ratau1aPHLL79o9OjR6tWrlx555BGlp6crPT29yF0dAACgcgx5p8WBAwf07rvvKiQkpNj9a9euLdctKFevXtXhw4c1ceJEtW/fXhcvXtS8efM0ceJEbdy40abtpEmT9MADD1if16tXr3InAQAAAAAAXGL+/PmaM2eOxowZIzc3Nw0cOFDTpk2z7s/Ly9Px48dlNput21566SW5ublp0qRJys3NVe/evTVz5kzr/o8++kjnzp3Tli1btOW/Fvq54YYbtHv37qo5MQAAagHDFS2uXLmi559/XnPnztWyZcuK7E9KStLq1av1wQcflLnYVf369bVmzRqbbdOnT9f999+v3377Tc2aNbNur1evXolzWwIAAAAAgOrD399fCxYsKHF/8+bNlZycbLPNy8tLM2fOtClU/LdnnnlGzzzzjEPjBAAARRmuaDF79mxFRkYqIiKiSNHCbDYrKipKM2bMsLvAcPnyZZlMJpuFtSRp5cqVWrZsmYKCgjRkyBCNHTu20qugWywWZWdnV6oPR7v+KZL//jQJyicnJ8f6aLTvq9GRO/vxM2sf8mYfi8Xi6hAAAAAAAEAtZ6iiRUJCgg4fPqy4uLhi98fExKhr167q37+/Xf3n5ORo/vz5Gjx4sHx9fa3bH374Yd18883y8/PTvn37tHDhQqWnpys6Otqu17kuPz9fSUlJlerDWVJSUlwdQrWTmppqfTTq99WoyF3l8TNrH/JWMfn5+a4OAQAAAAAA1HKGKVqkpqZq3rx5Wr16tby8vIrs37Vrl/bs2aNNmzbZ1X9eXp4mT54si8WiWbNm2ex75JFHrF+3b99ederU0cyZMxUVFSVPT0+7Xk+SPDw8FBoaavfxzmA2m5WSkqLg4GB5e3u7Opxq5cKFC5KkoKAgw31fjY7c2Y+fWfuQN/tU9g5DAAAAAACAyjLM1YlDhw4pMzNTw4cPt24rKCjQ3r17FRsbqwcffFAnT57ULbfcYnPcM888o+7du2v9+vUl9p2Xl6cpU6bot99+09q1a23usihO586dlZ+fr9OnT6t169Z2n5PJZJKPj4/dxzuTt7e3YWMzquvFNC8vL3JXQeSu8viZtQ95qxiTyeTqEAAAAAAAQC1nmKJFjx49FB8fb7MtOjparVu31vjx49WwYUONHDnSZv/QoUMVHR2tvn37ltjv9YLFiRMntG7dOjVs2LDMWJKSkuTm5qbGjRvbdzIAAAAAAAAAAKDCDFO08PX1Vbt27Wy2+fj4yN/f37q9uMW3mzVrphYtWlifDxo0SFFRURowYIDy8vI0adIkHT58WG+88YYKCgqUnp4uSfLz85Onp6f27dunn376ST169FC9evW0b98+xcTE6O6775afn58TzxgAAAAAAAAAAPw3wxQtHOX48eO6dOmSJCktLU27d++WJN1zzz027datW6fw8HB5enpq27ZtWrJkiXJzc9W8eXONHTvWZp0LAABgXHv37tWqVauUmJio9PR0LV26VP3797fuX7x4sRISEnT27FnVqVNHHTp00LPPPqvOnTuX2Ocbb7yhjz/+WMeOHVPdunXVtWtXTZ06tVLTRgIAAAAAgLIZumhR2joVkpScnFzqtubNmxfb5r916NBBGzZssC9AAADgctnZ2QoJCdGIESP09NNPF9kfHBysGTNmqEWLFrp69areeustPfroo9qxY4caNWpUbJ/fffed/vd//1edOnVSQUGBFi5cqHHjxikhIYF1UgAAAAAAcCJDFy0AAADKEhkZqcjIyBL3Dx061OZ5dHS04uLilJycrJ49exZ7zKpVq2ye//3vf1fPnj116NAh3XLLLZUPGgAAAAAAFIuiBQAAqDVyc3P13nvvqX79+goJCSn3cdennnTEelcWi0XZ2dmV7seRzGazzSPKLycnx/potO+r0ZE7+/Dzaj9yZx+LxeLqEAAAQC1D0QIAANR4n3zyiZ577jmZzWYFBgZq9erVJU4N9UeFhYV65ZVX1K1bN7Vr167SseTn5yspKanS/ThDSkqKq0OodlJTU62PRv2+GhW5qxx+Xu1H7iomPz/f1SEAAIBahqIFAACo8cLDw7V582ZlZWVpw4YNmjJlit5//301bty4zGNnzZqlI0eO6D//+Y9DYvHw8FBoaKhD+nIUs9mslJQUBQcHy9vb29XhVCsXLlyQJAUFBRnu+2p05M4+/Lzaj9zZx8ODywYAAKBqMfoAAAA1no+Pj1q1aqVWrVqpS5cuGjhwoOLi4vTEE0+Uetzs2bP16aef6u2339af/vQnh8RiMpkMu5i3t7e3YWMzKi8vL+sjuasYclc5/Lzaj9xVjMlkcnUIAACglqFoAQAAap3CwkLl5uaWuN9isWjOnDnasWOH1q9frxYtWlRhdAAAAAAA1F4ULQAAQLV25coVnTx50vr89OnTSkpKkp+fn/z9/bV8+XL169dPgYGBysrKUmxsrNLS0jRo0CDrMWPGjNGAAQM0atQoSdemhNq6dav+/e9/q169ekpPT5ck1a9fX3Xr1q3aEwQAAAAAoBahaAEAAKq1xMREjR492vo8JiZGkjRs2DDNmjVLx44d06ZNm5SVlSV/f3916tRJsbGxatu2rfWYU6dOKSsry/r8nXfekSQ9/PDDNq8VExOj4cOHO/N0AAAAAACo1ShaAACAai08PFzJyckl7l+yZEmZfezevdvmeWn9AQAAAAAA53FzdQAAAAAAAAAAAAASRQsAAAAAAAAAAGAQFC0AAAAAAAAAAIAhULQAAAAAAAAAAACGwELcgKRjx47p/Pnzpba5vihrcnKyvL29S23r7++v1q1bOyo8AAAAAAAAAKgVKFqg1svIyFDbtm1VWFhYrvbjxo0rs427u7vOnj2rgICAyoYHAAAAAAAAALUGRQvUegEBATpy5EiZd1qYzWYdPHhQnTp1KtedFhQsAAAAAAAAAKBiKFoAUrmmcsrOzlbdunUVGhoqHx+fKogKAAAAAAAAAGoXFuIGAAAAAAAAAACGQNECAAAAAAAAAAAYAkULAAAAAAAAAABgCBQtAAAAAAAAAACAIVC0AAAAAAAAAAAAhuDh6gAAAAAAIzp27JjOnz9fapvk5GTro7e3d6lt/f391bp1a0eFBwAAAAA1EkULAAAA4A8yMjLUtm1bFRYWlqv9uHHjymzj7u6us2fPKiAgoLLhAQAAAECNRdECAAAA+IOAgAAdOXKkzDstzGazDh48qE6dOpXrTgsKFgAAAABQOooWAAAAQDHKM5VTdna26tatq9DQUPn4+FRBVAAAAABQs7EQNwAAAAAAAAAAMASKFgAAAAAAAAAAwBAoWgAAAAAAAAAAAEOgaAEAAAAAAAAAAAyBogUAAAAAAAAAADAEwxYtVqxYoZCQEM2bN6/IPovFoscee0whISHauXNnqf1YLBa9/vrr6t27t8LCwjR27FilpKTYtDl//ryioqLUrVs3de/eXS+99JKuXLniyNMBAAAAAAAAAABlMGTR4sCBA3r33XcVEhJS7P61a9fKZDKVq6+VK1dq/fr1+tvf/qYNGzbI29tb48aNU05OjrXN1KlT9euvv2rNmjVavny5vv/+e82YMcMh5wIAAAAAAAAAAMrHcEWLK1eu6Pnnn9fcuXPl5+dXZH9SUpJWr16tV155pcy+LBaL1q1bp4kTJ6p///5q3769Xn31Vf3+++/WOzSOHj2qL774QnPnzlXnzp3VvXt3TZs2TQkJCUpLS3P4+QEAAAAAAAAAgOJ5uDqAP5o9e7YiIyMVERGhZcuW2ewzm82KiorSjBkzFBgYWGZfp0+fVnp6uiIiIqzb6tevr86dO2vfvn0aPHiw9u3bpwYNGqhTp07WNhEREXJzc9OBAwc0YMAAu8/FYrEoOzvb7uOdwWw22zyi/Mid/a7f2ZSTk2O4nwmj431nH/JmH4vF4uoQAAAAAABALWeookVCQoIOHz6suLi4YvfHxMSoa9eu6t+/f7n6S09PlyQ1btzYZnvjxo2VkZEhScrIyFCjRo1s9nt4eMjPz896vL3y8/OVlJRUqT6c5Y/reqD8yF3FpaamWh+N+jNhdLzv7EPeKiY/P9/VIQAAAAAAgFrOMEWL1NRUzZs3T6tXr5aXl1eR/bt27dKePXu0adMmF0RnHw8PD4WGhro6DBtms1kpKSkKDg6Wt7e3q8OpVsid/S5cuCBJCgoKMtzPhNHxvrMPebOPh4dhhgUAAAAAAKCWMszViUOHDikzM1PDhw+3bisoKNDevXsVGxurBx98UCdPntQtt9xic9wzzzyj7t27a/369UX6vD6FVGZmppo0aWLdnpmZqfbt20uSAgICdO7cOZvj8vPzdeHChXJNQVUak8kkHx+fSvXhLN7e3oaNzejIXcVdL0R6eXmROzvxvrMPeasYk8nk6hAAAAAc4vz585ozZ44++eQTubm5aeDAgXr55ZdVr169Eo/JycnR3//+d23btk25ubnq3bu3Zs6cqYCAgCJts7KydM899ygtLU179+5VgwYNnHk6AADUKoYpWvTo0UPx8fE226Kjo9W6dWuNHz9eDRs21MiRI232Dx06VNHR0erbt2+xfTZv3lyBgYH65ptvrJ/uvnz5sn766Sc9+OCDkqSuXbvq4sWLSkxMVMeOHSVJe/bsUWFhocLCwhx9mgAAAAAAwMmmTp2q9PR0rVmzRnl5eXrppZc0Y8YMLViwoMRjXnnlFX322WdatGiR6tevrzlz5ujpp5/Wu+++W6Ttyy+/rJCQEKWlpTnzNAAAqJXcXB3Adb6+vmrXrp3NPx8fH/n7+6tdu3YKDAwssl+SmjVrphYtWlj7GTRokHbs2CHp2idGR48erWXLlmnXrl1KTk7WCy+8oCZNmljXxWjTpo369Omj6dOn68CBA/rhhx80Z84cDR48WE2bNq36RAAAgArZu3evJkyYoN69eyskJEQ7d+602b948WINGjRIXbp00S233KKxY8fqp59+qlSfAADAuI4ePaovvvhCc+fOVefOndW9e3dNmzZNCQkJJRYZLl26pA8++EB//etf1bNnT3Xs2FGvvPKK9u3bp/3799u0/c9//qNLly7p0UcfrYKzAQCg9jHMnRaOcvz4cV26dMn6fPz48TKbzZoxY4YuXryoP//5z3rzzTdt1s2YP3++5syZozFjxlhvG502bZorwgcAABWUnZ2tkJAQjRgxQk8//XSR/cHBwZoxY4ZatGihq1ev6q233tKjjz6qHTt2qFGjRnb1CQAAjGvfvn1q0KCBOnXqZN0WEREhNzc3HThwQAMGDChyTGJiovLy8hQREWHd1qZNGzVr1kz79+9Xly5dJEm//vqr/v3vf2vDhg06deqUw2K2WCzKzs52WH+OYDabbR5RfuTOPuTNfuTOfuTOPhaLxan9G7poUdw6Ff8tOTm5zG0mk0mTJ0/W5MmTS+zH39+/1FtEAQCAcUVGRioyMrLE/UOHDrV5Hh0drbi4OCUnJ6tnz5529QkAAIwrIyOjyAcTPDw85Ofnp/T09BKPqVOnTpG1KRo3bmw9Jjc3V88995yef/55NWvWzKFFi/z8fCUlJTmsP0dKSUlxdQjVFrmzD3mzH7mzH7mrmPz8fKf2b+iiBQAAgCPl5ubqvffeU/369RUSEuLqcAAAQAXMnz9fK1euLLXNtm3bnPb6CxYsUJs2bXTPPfc4vG8PDw/rWpxGYTablZKSouDgYHl7e7s6nGqF3NmHvNmP3NmP3NnHw8O5ZQWKFgAAoMb75JNP9Nxzz8lsNiswMFCrV68ucWooZ2P6h5qF3NkvJyfH+mi0nwkj4z1nP3JnH2dP/1ARjz76qIYNG1ZqmxYtWiggIEDnzp2z2Z6fn68LFy4oMDCw2OMCAgKUl5enixcv2txtkZmZaT1mz549+uWXX/TRRx9J+r/c9OjRQxMmTNCkSZPsPjeTySQfHx+7j3cmb29vw8ZmdOTOPuTNfuTOfuSuYkwmk1P7p2gBAABqvPDwcG3evFlZWVnasGGDpkyZovfff1+NGzeu8liY/qFmIncVl5qaan006s+EkfGesx+5qxhnT/9QEY0aNSrXhw66du2qixcvKjExUR07dpR0reBQWFiosLCwYo/p2LGj6tSpo2+++UZ33HGHJOnYsWP67bffrOtZLF68WFevXrUec/DgQb300kuKjY1Vy5YtK3l2AADgOooWAACgxvPx8VGrVq3UqlUrdenSRQMHDlRcXJyeeOKJKo+F6R9qFnJnvwsXLkiSgoKCDPczYWS85+xH7uzj7OkfnKFNmzbq06ePpk+frlmzZikvL09z5szR4MGD1bRpU0lSWlqaxowZo1dffVVhYWGqX7++RowYob///e/y8/OTr6+v5s6dq65du1qLFn8sTGRlZVlf749rYQAAAPtVv9EHAABAJRUWFio3N9clr830DzUTuas4Ly8v6yO5qzjec/YjdxXj7OkfnGX+/PmaM2eOxowZIzc3Nw0cOFDTpk2z7s/Ly9Px48dtpgt76aWX5ObmpkmTJik3N1e9e/fWzJkzXRE+AAC1GkULAABQrV25ckUnT560Pj99+rSSkpLk5+cnf39/LV++XP369VNgYKCysrIUGxurtLQ0DRo0yHrMmDFjNGDAAI0aNarMPps1a1Z1JwcAAOzi7++vBQsWlLi/efPmSk5Ottnm5eWlmTNnlrtQER4eXqQPAABQeRQtAABAtZaYmKjRo0dbn8fExEiShg0bplmzZunYsWPatGmTsrKy5O/vr06dOik2NlZt27a1HnPq1CnrFA9l9fn3v//d2acEAAAAAECtRdECAABUa2V9ynHJkiVl9rF79+4K9QkAAAAAAJzDzdUBAAAAAAAAAAAASBQtAAAAAAAAAACAQVC0AAAAAAAAAAAAhkDRAgAAAAAAAAAAGAJFCwAAAAAAAAAAYAgULQAAAAAAAAAAgCFQtAAAAAAAAAAAAIZA0QIAAAAAAAAAABgCRQsAAAAAAAAAAGAIFC0AAAAAAAAAAIAhULQAAAAAAAAAAACGQNECAAAAAAAAAAAYAkULAAAAAAAAAABgCBQtAAAAAAAAAACAIVC0AAAAAAAAAAAAhkDRAgAAAAAAAAAAGAJFCwAAAAAAAAAAYAgULQAAAAAAAAAAgCF4uDoAANXbsWPHdP78+VLbJCcnWx+9vb1Lbevv76/WrVs7KjwAAOACjA8AAAAA2IuiBQC7ZWRkqG3btiosLCxX+3HjxpXZxt3dXWfPnlVAQEBlwwMAAC7A+AAAAABAZVC0AGC3gIAAHTlypMxPUprNZh08eFCdOnUq1ycpuSABAED1xfgAAAAAQGVQtABQKeWZqiE7O1t169ZVaGiofHx8qiAqAADgSowPAAAAANiLhbgBAAAAAAAAAIAhGLZosWLFCoWEhGjevHnWbTNmzFD//v0VFhamHj16aOLEiTp69Gip/YSEhBT7780337S26devX5H9K1ascNq5AQAAAAAAAACAogw5PdSBAwf07rvvKiQkxGZ7hw4dNHToUAUFBenChQtavHixxo0bp127dsnd3b3Yvr788kub559//rlefvll3XHHHTbbJ02apAceeMD6vF69eg46GwAAAAAAAAAAUB6GK1pcuXJFzz//vObOnatly5bZ7Bs5cqT16+bNm2vKlCm65557dObMGbVs2bLY/gIDA22e79q1S+Hh4WrRooXN9nr16hVpCwAAAAAAAAAAqo7hpoeaPXu2IiMjFRERUWq77Oxsbdy4Uc2bN9ef/vSncvWdkZGhzz77TPfdd1+RfStXrlR4eLjuvfdevfnmm8rPz7crfgAAAAAAAAAAYB9D3WmRkJCgw4cPKy4ursQ2sbGxmj9/vrKzs3XjjTdqzZo18vT0LFf/mzZtUr169TRw4ECb7Q8//LBuvvlm+fn5ad++fVq4cKHS09MVHR1dqfOxWCzKzs6uVB+OZjabbR5RfuTOfuTOfuTOPuTNPhaLxdUhAAAAAACAWs4wRYvU1FTNmzdPq1evlpeXV4nt7r77bvXq1Uvp6elatWqVpkyZonfeeafUY6774IMPNHTo0CJtH3nkEevX7du3V506dTRz5kxFRUWVuyBSnPz8fCUlJdl9vDOlpKS4OoRqi9zZj9zZj9zZh7xVDHcZAgAAAAAAVzNM0eLQoUPKzMzU8OHDrdsKCgq0d+9excbG6uDBg3J3d1f9+vVVv359BQcHq3Pnzrr11lu1Y8cODRkypNT+v//+ex0/flyLFi0qM5bOnTsrPz9fp0+fVuvWre0+Jw8PD4WGhtp9vDOYzWalpKQoODhY3t7erg6nWiF39iN39iN39iFv9vHwMMywAAAAAAAA1FKGuTrRo0cPxcfH22yLjo5W69atNX78eLm7uxd7nMViUW5ubpn9x8XFqUOHDmrfvn2ZbZOSkuTm5qbGjRuXL/gSmEwm+fj4VKoPZ/H29jZsbEZH7uxH7uxH7uxD3irGZDK5OgQAAAAAAFDLGaZo4evrq3bt2tls8/Hxkb+/v9q1a6dTp05p27Zt6tWrlxo1aqSzZ89qxYoVqlu3riIjI63HDBo0SFFRURowYIB12+XLl7V9+3a9+OKLRV533759+umnn9SjRw/Vq1dP+/btU0xMjO6++275+flV+DzOnz9v/frcuXNlLihe1SwWi/Lz8+Xh4cHFqQoid/Yjd/Yjd/Yhb/Y5d+6c9ev//v8Mlcf4oOYid/Yjd/Yhb/Yjd/ZhfOA8jA9qLnJnH/JmP3JnP3JnH2ePDwxTtCiLp6envv/+e61du1YXL15U48aN1b17d73zzjs2d0QcP35cly5dsjk2ISFBFoul2CmkPD09tW3bNi1ZskS5ublq3ry5xo4da7PORUUUFhZav7ZYLMrMzLSrHwAAXOm//z9D5TE+AADUBIwPHIvxAQCgJnDG+MBksVgsDu+1Fmvfvr1IKQCgujOZTPr5559dHUaNwfgAAFATMD5wLMYHAICawBnjg2pzp0V1UadOHeXl5UmS3Nzc5O/v79qAAAAop/Pnz1s/IVGnTh0XR1OzMD4AAFRXjA+ch/EBAKC6cvb4gDstAAAAAAAAAACAIbi5OgAAAAAAAAAAAACJogUAAAAAAAAAADAIihYAAAAAAAAAAMAQKFoAAAAAAAAAAABDoGgBAAAAAAAAAAAMgaIFAAAAAAAAAAAwBIoWAAAAAAAAAADAEChaAAAAAAAAAAAAQ6BoAQAAAAAAAAAADIGiBQAAAAAAAAAAMASKFgAAAAAAAAAAwBAoWgAAAAAAAAAAAEOgaFFLFBQUaNGiRerXr5/CwsLUv39/LV26VBaLxdWhGc7evXs1YcIE9e7dWyEhIdq5c2eRNkePHtWECRP05z//WV26dNGIESP022+/uSBa4/jPf/6joUOHqlu3burWrZtGjhypzz77TJJ0/vx5zZkzR3fccYfCwsJ0++23a+7cubp06ZKLozaOtLQ0TZ06VeHh4QoLC9PQoUN18ODBYtvOmDFDISEheuutt6o2SAMo7eczLy9Pr732moYOHaouXbqod+/eeuGFF5SWlmbTx/HjxzVx4kSFh4erW7duevDBB7Vnz56qPpUq9cYbb2jEiBHq2rWrevbsqSeffFLHjh2zafPwww8rJCTE5t+MGTOK9LVx40YNHTpUnTp1Us+ePTVr1qyqOg04AeOD8mN8YB/GB5XD+KBsjA3sx/gAxWFsUH6MDezH+MB+jA3Kh/GBfYw0NvCo1Jmg2li5cqXeeecd/eMf/9BNN92kxMRERUdHq379+ho9erSrwzOU7OxshYSEaMSIEXr66aeL7D958qQeeughjRgxQpMmTZKvr6+OHDkiLy8vF0RrHH/60580depUtWrVShaLRZs3b9ZTTz2lTZs2yWKx6Pfff9eLL76om266SWfOnNHf/vY3/f777/rXv/7l6tBd7sKFC3rwwQcVHh6ulStXqmHDhjpx4oT8/PyKtN2xY4d++uknNWnSxAWRul5pP59Xr17V4cOHNXHiRLVv314XL17UvHnzNHHiRG3cuNHabsKECWrVqpXWrl2runXrau3atZowYYJ27NihwMDAqj6lKvHdd9/pf//3f9WpUycVFBRo4cKFGjdunBISEuTj42Nt98ADD2jSpEnW597e3jb9rFmzRqtXr9YLL7ygzp07Kzs7W2fOnKmy84DjMT4oP8YH9mF8YD/GB+XD2MB+jA9QHMYG5cfYwH6MD+zD2KD8GB/Yx1BjAwtqhccff9wSHR1ts+3pp5+2REVFuSii6qFdu3aWHTt22GybMmWKZerUqS6KqHq55ZZbLBs2bCh237Zt2ywdOnSw5OXlVXFUxvPaa69ZHnzwwTLbnT171tKnTx/LL7/8Yunbt69lzZo1zg/OwIr7+fyjn376ydKuXTvLmTNnLBaLxZKZmWlp166dZe/evdY2ly5dsrRr187y1VdfOTVeI7meh++++866bdSoUZa5c+eWeMz58+ctYWFhlq+//roqQkQVYXxgH8YHlcP4oHwYH1QcY4PKYXwAi4Wxgb0YG1Qe44OyMTawD+MD+7lybMD0ULVE165dtWfPHh0/flyS9PPPP+uHH37Qbbfd5uLIqpfCwkJ9+umnCg4O1rhx49SzZ0/df//9xd4GWpsVFBQoISFB2dnZ6tq1a7FtLl++LF9fX3l4cMPX7t271bFjR02aNEk9e/bUvffeqw0bNti0KSws1PPPP69x48apbdu2Loq0+rl8+bJMJpMaNGggSWrYsKFuvPFGbd68WdnZ2crPz9d7772nxo0bq0OHDi6Otupcv7X6j5/IiY+PV3h4uIYMGaIFCxbIbDZb93311VcqLCxUWlqa7rzzTt12222aPHmyUlNTqzR2OBbjA8dgfFA+jA8qhvGBczA2KBnjA0iMDRyFsUH5MT4oP8YGzsP4oHiuHBvU7p/2WuTxxx/X5cuXdeedd8rd3V0FBQV69tlndffdd7s6tGolMzNT2dnZWrlypaZMmaKpU6fqiy++0NNPP61169bp1ltvdXWILpWcnKz/+Z//UU5Ojnx8fLR06VLddNNNRdqdO3dO//73vzVy5EgXRGk8p06d0jvvvKNHHnlEEyZM0MGDBzV37lzVqVNHw4YNk3TtNm0PDw9uya6AnJwczZ8/X4MHD5avr68kyWQy6a233tKTTz6pbt26yc3NTY0aNdKbb75Z7C21NVFhYaFeeeUVdevWTe3atbNuHzJkiJo1a6YmTZooOTlZ8+fP1/Hjx7VkyRJJ0unTp2WxWLR8+XK9/PLLql+/vhYtWqRHHnlEW7Zskaenp6tOCZXA+MAxGB+UjvGBfRgfOB5jg5IxPsB1jA0cg7FB2RgfVBxjA+dgfFA8V48NKFrUEh9++KHi4+O1YMEC3XTTTUpKSlJMTIyaNGli/cWGshUWFkqS/vKXv2js2LGSpNDQUP3444969913a/3A43oV+tKlS/roo4/04osv6u2337YZeFy+fFlPPPGE2rRpU+y8n7WRxWJRx44d9dxzz0mSbr75Zh05ckTvvvuuhg0bpsTERK1bt04bN26UyWRycbTVQ15eniZPniyLxWKz2NP1540bN1ZsbKzq1q2r999/XxMmTFBcXFytmO9z1qxZOnLkiP7zn//YbP/vPwJCQkIUGBiosWPH6uTJk2rZsqUKCwuVl5enadOmqXfv3pKkhQsXqlevXvr222/Vp0+fKj0POAbjA8dgfFA6xgf2YXzgWIwNSsf4ANcxNnAMxgZlY3xQcYwNHI/xQclcPTagaFFLvPrqq3r88cc1ePBgSdfeVL/99pveeOMNBh4V0LBhQ3l4eKhNmzY229u0aaMffvjBRVEZh6enp1q1aiVJ6tixow4ePKh169Zp9uzZkv6/9u4/qur6juP4ExjgFCX8RSo/kqZXNyaKAhrHHwHHxgx/MEXR0BppimagqGitmplGpbljKcMydcJRjjF/wNRhiZj5c+7oPHOdtSEGOENAHWDi5O4PDjfxosCF5EKvx198f32+7+/9XuHl+Xw+32914Hj++efp0KEDH3zwAfb29i1ZrtXo1q2b2XfKy8uLAwcOAHD69GmKi4t58sknTdvv3LlDYmIiW7du5bPPPnuo9Vq727dvExsbS2FhIVu2bDGNlAA4fvw42dnZnDp1yrT+Zz/7GV988QW7du1i1qxZLVX2Q7F8+XKys7PZtm0bjz766AP39fHxASAvLw8PDw/Ti8bu/k9E586dcXFx0SMgWjHlg+ahfPBgygeWUT5oPsoGD6Z8IHdTNmgeygb1Uz5oPGWD5qV8cH/WkA3UafED8e2335r1strZ2WE0GluootbJwcGBn//856bne9a4ePEivXr1aqGqrFdVVRWVlZVAdeCIjo7GwcGBDRs24Ojo2MLVWQ9fX98HfqfGjRvHE088UWt7dHQ048aNIzw8/KHV2RrUhI68vDy2bt2Ki4tLre01z1m89/ehjY2NaTRUW2Q0GnnjjTfIysriD3/4A+7u7vUec+HCBQBT4PD19QUgNzfXFFquXbtGaWkpPXv2/J4ql++b8kHzUD5oHOWDhlE+aB7KBvenfCB1UTZoHsoGjad8UD9lg+ajfFA3a8oG6rT4gXjyySdJSkqiZ8+epimeH3/8Mb/61a9aujSrU15ezqVLl0zL+fn5XLhwAWdnZ3r27El0dDRxcXH4+fkREBDAkSNHOHToEFu3bm3Bqlve6tWrGTFiBD169KC8vJyMjAxOnjzJRx99RFlZGb/+9a+5efMm77zzDmVlZZSVlQHVva12dnYtXH3LmjFjBpGRkSQlJREaGsq5c+dIS0szjTBxcXEx+wNqb29P165d8fLyaomSW8yD/n1269aN+fPn8/e//53f//733Llzh6KiIqD6pVEODg4MHDiQTp06kZCQwNy5c3F0dCQtLY2CggJGjRrVQlf1/fvtb39LRkYG69evp0OHDqbPpWPHjrRr145Lly6xd+9eRo4cySOPPMKXX37JqlWr8PPzo1+/fkD19O3g4GDefPNNli9fjpOTE2vWrMHLy4uAgICWvDxpAuWDhlM+sIzygeWUDxpG2cByygdSF2WDhlM2sJzygWWUDRpO+cAy1pQNbIzqLv9BKCsr43e/+x0HDx6kuLiY7t27M2bMGObOnauXo93jxIkTdb6waMKECbz11lsA7Ny5k+TkZP7zn//Qu3dvXnzxRUJCQh52qVZl2bJlHD9+nG+++YaOHTtiMBiYOXOm6Zl193sJ1Keffoqbm9tDrtb6HDp0iDVr1nDx4kXc3Nx47rnniIiIuO/+QUFBTJ8+3fR81B+KB/37nDdvHsHBwXUet3XrVtMfx7/97W+sXbuW8+fPc/v2bfr06UNMTAwjR478XmtvSQaDoc71q1atIjw8nMuXL7No0SL++c9/UlFRQY8ePQgJCSEmJqbWFNmysjJWrlxJVlYWtra2+Pn58fLLL9OjR4+HdSnSzJQPGk75wDLKB02jfFA/ZQPLKR9IXZQNGk7ZwHLKB5ZTNmgY5QPLWFM2UKeFiIiIiIiIiIiIiIhYBduWLkBERERERERERERERATUaSEiIiIiIiIiIiIiIlZCnRYiIiIiIiIiIiIiImIV1GkhIiIiIiIiIiIiIiJWQZ0WIiIiIiIiIiIiIiJiFdRpISIiIiIiIiIiIiIiVkGdFiIiIiIiIiIiIiIiYhXUaSHSCp04cQKDwcD+/ftbupQGuXr1KvPnzycgIACDwcDmzZtbuiQREZE2RdlARERE7qV8ICKt1Y9augARa5Wens7SpUtxcHDg4MGDuLq61toeFRVFaWkpGRkZLVRh67Fq1SqOHDnCvHnz6Nq1K97e3vfd12AwMG3aNF599dX77lNVVcWePXtISUkhLy+P27dv0717d3x8fJg6dSoDBw4kKCiIgoKCBtUWHh6OwWAAYOLEibz55ptm+7333nskJSUBcOzYMTp37lxv2yIi0rYoGzQfZQMREWkrlA+aj/KBiNRQp4VIPSorK0lOTuY3v/lNS5fSah0/fpzg4GCio6Obpb0VK1aQkpJCcHAwYWFh2NnZkZuby5EjR3B3d2fgwIEsW7aM8vJy0zE5OTlkZGSwdOlSXFxcTOt9fX1NPzs6OvLnP/+Z1157DQcHh1rnzMjIwNHRkVu3bjXLNYiISOulbNB0ygYiItLWKB80nfKBiNRQp4VIPfr3709aWhqzZs0yGzHR1lVUVNC+ffsmt1NcXEynTp2aoaLq6aKpqalERETwxhtv1NpmNBopKSkBICQkxOy4jIwMQkJCcHNzq7Pt4cOH89lnn5GTk1Pr+DNnzpCfn89TTz3FgQMHmuU6HqZbt25hb2+Pra2eCCgi0hyUDZQNlA1EROReygfKB8oHIs1H30KRerzwwgtUVVWxcePGB+6Xn5+PwWAgPT3dbJvBYGDdunWm5XXr1mEwGMjNzSU+Pp7BgwczdOhQ1q5di9Fo5PLly8yZMwdfX18CAwPZtGlTneesqqpizZo1BAYGMnDgQGbPns3ly5fN9jt79izR0dEMHjwYHx8fnnnmGf7yl7/U2qempq+++oqFCxfi5+fH1KlTH3jNX3/9NfPnz8ff3x8fHx8iIiLIzs42bU9PT8dgMGA0GklJScFgMJimUloqPz8fo9FYa5RDDRsbG7p06WJx266urgwZMsRs2u7evXvp27cvffr0aVA7NZ9lXl4eCQkJDBkyhMGDB7N06VJu3rxptv/u3bsJDw9nwIAB+Pv7ExcXZ3Yfg4KCSEhIMDs2KiqKqKgo03LNM0szMzN57733GD58OD4+PpSVlQGwb98+07kCAgKIj4/nypUrtdpMSEhg0KBBXLlyhZiYGAYNGsTQoUNJTEzkzp07tfbNzMwkPDycQYMG4evrS1hYGFu2bGnQ5yQi0lopG9yfskHdlA2UDUSk7VM+uD/lg7opHygfyP2p00KkHm5ubowbN460tDSzX9BNFRcXh9FoZOHChfj4+LBhwwa2bNnCc889h6urK/Hx8Xh4eJCYmMipU6fMjt+wYQPZ2dnMnDmTqKgovvjiC5599lm+/fZb0z7Hjh1j2rRplJeXM2/ePOLi4rhx4wYzZszg3LlzZm2+9NJL3Lx5k7i4OCZNmnTf2q9evcqUKVP4/PPPiYyMJC4ujlu3bjFnzhyysrIA8PPz4+233wYgMDCQt99+27RsqZ49ewKwf//+Ov+IN1VYWBiHDh0yTQ/93//+x/79+wkLC2t0W7GxsZSXl7NgwQJCQ0NJT0/n/fffr7XPhg0bWLJkCZ6eniQkJDB9+nTTPbtx44bF17F+/XoOHz5MdHQ0CxYswN7envT0dGJjY7G1tWXBggVERESQlZVFZGSk2bnu3LlDdHQ0jzzyCIsXL8bf359NmzaxY8cO0z5Hjx5lwYIFdOrUifj4eBYuXIi/vz9nzpyxuG4RkdZA2aBuygb1UzYQEWm7lA/qpnxQP+UDEXN6PJRIA8yZM4fdu3ezceNGXnnllWZrd8CAASxfvhyAyZMnExQUxFtvvcWCBQuYNWsWAE8//TTDhw/nk08+wc/Pr9bx169f509/+hNOTk4A/PSnPyU2Npa0tDSmT5+O0Wjk9ddfJyAggA8//BAbGxsApkyZwpgxY1i7dq3ZSIx+/fqxevXqemtPTk7m6tWrpKSkMGTIEAAmTZrE2LFjWbVqFcHBwbi7u+Pu7s7ixYt57LHHGDduXNM+MKB79+6MHz+eXbt2MXLkSPz9/fH19WXkyJE8/vjjTW7/qaeeYvny5Rw8eJBx48Zx9OhRSktLGTNmTJ0jYR6kf//+rFy50rR87do1du7cyaJFiwAoKChg3bp1xMbGMnv2bNN+o0ePZsKECaSmptZa3xi3bt3ik08+oV27dgDcvn2bd999l759+5KSkoKjoyMAgwcP5oUXXmDz5s3Mnz+/1vGhoaHMnTsXgMjISCZMmMDOnTtNo2iys7NxcnLio48+ws7OzqI6RURaK2UDc8oG9VM2EBFp25QPzCkf1E/5QMScZlqINIC7uztjx44lLS2Nb775ptnanThxoulnOzs7vL29MRqNtdZ36tSJ3r178/XXX5sdP378eFPoAPjFL35Bt27dOHz4MAAXLlzg4sWLhIWFUVpaSklJCSUlJVRUVDBs2DBOnTpFVVVVrTanTJnSoNoPHz7MgAEDTKEDoEOHDkyePJmCggK++uqrhn0IFli1ahWvvvoqbm5uZGVlkZiYyC9/+UtmzJjR5BEtzs7ODB8+nMzMTKB6euegQYPo1atXo9u697McMmQI165dM023zMrKoqqqitDQUNO9KSkpoWvXrnh6enLixAmLr2P8+PGm0AFw/vx5iouLiYyMNIUOgFGjRuHl5VVram6NyMjIWsuDBw8mPz/ftNypUydu3rzJ0aNHLa5TRKS1UjYwp2xQP2UDEZG2TfnAnPJB/ZQPRMxppoVIA8XExLBnzx6Sk5ObbcREzXTFGh07dsTR0ZHOnTubrb927ZrZ8Z6enrWWbWxs8PT0pKCgAICLFy8CsGTJkvvW8N///hdnZ2fT8v1eNHWvwsJCfHx8zNZ7eXmZtvft27dBbTWWra0t06ZNY9q0aZSWlnLmzBm2b99OTk4OcXFxpKamNqn9sLAwFi9eTGFhIZ9++inx8fEWtXPv/a15odj169dxcnLi4sWLGI1GRo8eXefxP/qR5b+i772PhYWFAPTu3dtsXy8vL7PnlNb1PXR2dub69eum5alTp7Jv3z5mzpyJq6srgYGBhIaGMmLECIvrFhFpTZQNalM2qJ+ygYhI26d8UJvyQf2UD0TMqdNCpIHuHjFRM/3ybjXTJ+9178uH7mZraz7Z6X5T5YxGYwMrNT9m8eLF9O/fv8592rdvX2v57p701sDFxYXg4GCCg4OJiori5MmTFBQUWDS6oUZQUBD29vYsWbKEyspKQkNDLWqnrvsL392XqqoqbGxs2LhxY533/d57U5c7d+7UeezdIyUs0ZApm126dGHXrl18/vnn5OTkkJOTQ3p6OuPHjycxMbFJ5xcRaQ2UDayTsoGygYhIS1I+sE7KB8oH0rqo00KkEebMmcOePXvYuHGj2baaEQf3vpSoppf6+5CXl1dr2Wg0kpeXh8FgAKrDEoCTkxNPPPFEs567Z8+e5Obmmq3/97//bdr+sHl7e3Py5EmKioqaFDzatWtHSEgIe/bsYcSIEWajBpqLh4cHRqMRNze3Okcx3M3Z2bnOl2sVFhaa7vOD1NyP3Nxchg0bVmtbbm6uxffLwcGBoKAggoKCqKqq4vXXX2fHjh3ExMSYjeYREWmLlA2+o2zQdMoGIiJtg/LBd5QPmk75QH6I9E4LkUbw8PBg7Nix7Nixg6KiolrbnJyccHFx4fTp07XWN3W64YPs2rXL9IxDgP3791NUVGSaYuft7Y2HhwebNm2ivLzc7PiSkhKLzz1y5EjOnTvHX//6V9O6iooK0tLS6NWrFz/5yU8sbvtBioqK6nzmZWVlJceOHcPW1hYPD48mnyc6Opp58+YRExPT5LbuZ/To0djZ2fH++++bjYYxGo2Ulpaalt3d3Tl79iyVlZWmdYcOHeLy5csNOpe3tzddunRh+/bttdo4fPgw//rXvxg1alSj67+7PqgeHVITeu8+h4hIW6Zs8B1lg6ZTNhARaRuUD76jfNB0ygfyQ6SZFiKNNHv2bHbv3k1ubi59+vSptW3SpEkkJyfz8ssv4+3tzenTp+scUdBcnJ2dmTp1KuHh4RQXF7NlyxY8PT2JiIgAqv8QrFixgpkzZ/L0008THh6Oq6srV65c4cSJEzg5OZGUlGTRuWfNmkVmZiYzZ84kKioKZ2dndu3aRX5+PuvWrbvv9MaGOH/+POvXrzdb7+/vj6OjI5MmTWLo0KEMGzaMrl27UlxcTGZmJv/4xz+YMWNGs4xu6NevH/369WtyOw/i4eFBbGwsq1evpqCggJCQEDp06EB+fj4HDx4kIiKC6OhooPq7deDAAZ5//nlCQ0O5dOkSe/fubXDIsre3Jz4+nqVLl/LMM88wZswYiouL2bp1K7169eLZZ59tdP2vvPIK169fZ+jQobi6ulJYWMi2bdvo378/jz/+eKPbExFprZQNqikbNJ2ygYhI26F8UE35oOmUD+SHSJ0WIo3k6enJ2LFj+eMf/2i2be7cuZSUlHDgwAH27dvHiBEj+PDDD82m1DWX2bNn8+WXX5KcnEx5eTnDhg3jtdde48c//rFpn4CAAHbs2MH69evZtm0bFRUVdOvWjQEDBjB58mSLz921a1e2b9/OO++8w7Zt27h16xYGg4GkpCSLet7vdvbsWc6ePWu2/qWXXmL69OksW7aMw4cPk5qaSnFxMQ4ODvTt25cVK1YwceLEJp37YZs1axaPPfYYmzdv5oMPPgDg0UcfJTAwkKCgINN+w4cPJyEhgY8//piVK1fi7e1NUlJSo57/GB4eTrt27di4cSPvvvsu7du3JyQkhEWLFple9NUYNc9pTU1N5caNG3Tr1o3Q0FBefPHFJgVPEZHWRtmgmrJB81A2EBFpG5QPqikfNA/lA/mhsTFa8oYeERERERERERERERGRZqbuLBERERERERERERERsQrqtBAREREREREREREREaugTgsREREREREREREREbEK6rQQERERERERERERERGroE4LERERERERERERERGxCuq0EBERERERERERERERq6BOCxERERERERERERERsQrqtBAREREREREREREREaugTgsREREREREREREREbEK6rQQERERERERERERERGroE4LERERERERERERERGxCuq0EBERERERERERERERq6BOCxERERERERERERERsQr/B1QNC6UgSgRnAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1900x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "all_scores_boxplot(lstm_all_rmse.iloc[:, 1:], lstm_all_mape.iloc[:, 1:],  lstm_all_R.iloc[:, 1:],\n",
        "                      gru_all_rmse.iloc[:, 1:], gru_all_mape.iloc[:, 1:], gru_all_R.iloc[:, 1:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19bq2C5Q6HjP"
      },
      "source": [
        "### **Plot 7: Statistical Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Bj5UvDE6H5Y"
      },
      "outputs": [],
      "source": [
        "\n",
        "def comparative_qq_plots(data1, data2):\n",
        "  fig = plt.figure(figsize = (16,5))\n",
        "  ax1= fig.add_subplot(121)\n",
        "  scipy.stats.probplot(data1, dist=scipy.stats.norm, sparams=(0,1), plot=ax1)\n",
        "  ax1.get_lines()[0].set_marker('o')\n",
        "  ax1.get_lines()[0].set_markerfacecolor('mediumblue')\n",
        "  ax1.get_lines()[0].set_markersize(8.0)\n",
        "  ax1.get_lines()[1].set_linewidth(3.0)\n",
        "  plt.title(\"(a)\")\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "\n",
        "  ax2= fig.add_subplot(122)\n",
        "  scipy.stats.probplot(data2, dist=scipy.stats.norm, sparams=(0,1), plot=ax2)\n",
        "  ax2.get_lines()[0].set_marker('o')\n",
        "  ax2.get_lines()[0].set_markerfacecolor('mediumblue')\n",
        "  ax2.get_lines()[0].set_markersize(8.0)\n",
        "  ax2.get_lines()[1].set_linewidth(3.0)\n",
        "  plt.title(\"(b)\")\n",
        "\n",
        "\n",
        "  plt.rcParams[\"axes.edgecolor\"] = \"0.15\"\n",
        "  plt.rcParams[\"axes.linewidth\"]  = 2.75\n",
        "  plt.rc('xtick',labelsize=10)\n",
        "  plt.rc('ytick',labelsize=10)\n",
        "\n",
        "\n",
        "  fig.savefig(output_dir_path+ \"best_model_rmse_qq_plots.png\",dpi=600)\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "\n",
        "import scipy\n",
        "\n",
        "def perform_normality_test(lstm_rmse, gru_rmse):\n",
        "  print(\"Performaing Normality Tests\\n\")\n",
        "  print(\"lstm_rmse: \")\n",
        "  print(scipy.stats.normaltest(lstm_rmse))\n",
        "  print(\"gru_rmse:\")\n",
        "  print(scipy.stats.normaltest(gru_rmse))\n",
        "\n",
        "def perform_pairwise_ttests(lstm_rmse, gru_rmse):\n",
        "\n",
        "  print(\"\\n Two-sample ttest between lstm_rmse and  gru_rmse\")\n",
        "  print(scipy.stats.ttest_ind(lstm_rmse, gru_rmse, equal_var = False))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwLLMZB36gPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 659
        },
        "outputId": "357ff816-6d83-4358-ed02-e3e3d455b22d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performaing Normality Tests\n",
            "\n",
            "lstm_rmse: \n",
            "NormaltestResult(statistic=2.799371810469947, pvalue=0.24667443092240185)\n",
            "gru_rmse:\n",
            "NormaltestResult(statistic=0.22255513266568677, pvalue=0.8946903785335959)\n",
            "\n",
            " Two-sample ttest between lstm_rmse and  gru_rmse\n",
            "TtestResult(statistic=13.551402680961557, pvalue=4.817277775468147e-19, df=54.18771093600343)\n"
          ]
        }
      ],
      "source": [
        "comparative_qq_plots(best_lstm_rmse.iloc[:,1], best_gru_rmse.iloc[:,1])\n",
        "perform_normality_test(best_lstm_rmse.iloc[:,1], best_gru_rmse.iloc[:,1])\n",
        "perform_pairwise_ttests(best_lstm_rmse.iloc[:,1], best_gru_rmse.iloc[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Summarry**"
      ],
      "metadata": {
        "id": "FfS2uirtyvdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Overall I think the GRU model would be the best model to use with this dataset. It preformed better with most different amounts of neurons than the LSTM model.We can see this in the box plots for RMSE and MAPE. The best model for GRU had signficantly lower RMSE than the LSTM. For neurons 8-32 GRU's MAPE and RMSE means were all lower than LSTM and also had a more compact IQR, however they did have outliers which we do not see in the other model. For neurons 64 and 128 LSTM actually had similar RMSE and MAPE as the GRU model. We can see in the true versus predicted plots that both models are clustered around the true values which means they are both performing well. The GRU model's clsuters appears tighter than the LSTM model however."
      ],
      "metadata": {
        "id": "64FY3Sgiywza"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}